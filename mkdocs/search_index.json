{
    "docs": [
        {
            "location": "/", 
            "text": "welcome", 
            "title": "Index"
        }, 
        {
            "location": "/#welcome", 
            "text": "", 
            "title": "welcome"
        }, 
        {
            "location": "/ci-cd-with-gitlab/", 
            "text": "CI/CD with Gitlab\n\n\nInstall Gitlab Repositories\n\n\ninstall dependencies:\n\n\nsudo yum install -y curl policycoreutils-python openssh-server\nsudo systemctl enable sshd\nsudo systemctl start sshd\nsudo firewall-cmd --permanent --add-service=http\nsudo firewall-cmd --permanent --add-service=https\nsudo systemctl reload firewalld\n\n\n\ninstall repo:\n\n\ncurl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\n\n\n\ninstall gitlab community edition\n\n\nEXTERNAL_URL=\"https://gt.doco.dgprasetya.net\" yum install -y gitlab-ce\n\n\n\nsetelah selesai, bisa diakses via url \nhttps://gt.doco.dgprasetya.net\n:\n\n\n\n\nInstall Gitlab Runner\n\n\ninstall dependencies:\n\n\nyum install -y yum-utils   device-mapper-persistent-data   lvm2\n\n\n\ninstall docker untuk gitlab runner:\n\n\nyum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo\nyum install docker-ce docker-ce-cli containerd.io\n\n\n\njalankan daemon docker:\n\n\nsystemctl start docker\n\n\n\ninstall runner gitlab:\n\n\ncurl -LJO https://gitlab-runner-downloads.s3.amazonaws.com/latest/rpm/gitlab-runner_amd64.rpm\nyum install git -y\nrpm -i gitlab-runner_amd64.rpm\n\n\n\nkonfiurasi/register gitlab-runner\n\n\njalan perintah berikut:\n\n\ngitlab-runner register\n\n\n\nlalu akan muncul questions seperti berikut:\n\n\nPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com)\nhttps://example.digitalocean.com\nEnter the token you obtained from your GitLab instance:\n\nPlease enter the gitlab-ci token for this runner\nsample-gitlab-ci-token\nEnter a description that will help you recognize it in the GitLab web interface. We recommend naming this instance something unique, like runner-bastion for clarity.\n\nPlease enter the gitlab-ci description for this runner\n[yourhostname] runner-bastion\nIf relevant, you may enter the tags for code you will build with your runner. However, we recommend this is left blank at this stage. This can easily be changed from the GitLab interface later.\n\nPlease enter the gitlab-ci tags for this runner (comma separated):\ncode-tag\nChoose whether or not your runner should be able to run untagged jobs. This setting allows you to choose whether your runner should build repositories with no tags at all, or require specific tags. Select true in this case, so your runner can execute all repositories.\n\nWhether to run untagged jobs [true/false]: true\nChoose if this runner should be shared among your projects, or locked to the current one, which blocks it from building any code other than those specified. Select false for now, as this can be changed later in GitLab\u2019s interface:\n\nWhether to lock Runner to current project [true/false]: false\nChoose the executor which will build your machines. Because we\u2019ll be creating new Droplets using Docker, we\u2019ll choose docker+machine here, but you can read more about the advantages of each approach in this compatibility chart:\n\nPlease enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:\ndocker+machine\nYou\u2019ll be asked which image to use for projects that don\u2019t explicitly define one. We\u2019ll choose a basic, secure default:\n\nPlease enter the Docker image (e.g. ruby:2.1):\nalpine:latest\n\n\n\nstatus runner yg sudah terkoneksi:\n\n\n\n\nContoh sederhana konsep ci/cd di gitlab:\n\n\n\n\nCreate Repo Test di Gitlab.\n\n\n\n\nCreate file .gitlab-ci.yml , isikan seperti berikut:\nUntuk memahami bagian ini, kita harus tahu dulu referensi pipeline yg digunakan di gitlab. dokumentasi lengkap bisa dibaca di \nhttps://docs.gitlab.com/ce/ci/yaml/\n\ndalam contoh ini define stages ke dalam kedua kelompok, \ncompile\n dan \ndeploy\n . \n\n\nstages:\n  - compile\n  - deploy\n\n\n\n\n\n\nsetelah itu dari masing-masing kelompok, berikan task dalam variable script dan masukkan kelompok \ncompile\n ke dalam stage:\n\n\ncompile:\n  stage: compile\n  script:\n    - pwd;uname -a;uptime\n\n\n\nuntuk kelompok yg lain (deploy) sama seperti berikut:\n\n\ndeploy:\n  stage: deploy\n  script:\n    - ls /;uname -a\n\n\n\nsesuaikan perintah task yg ada di script.\n\n\nhasil akhir \n.gitlab-ci.yml\n:\n\n\nstages:\n  - compile\n  - deploy\n\ncompile:\n  stage: compile\n  script:\n    - pwd;uname -a;uptime\n\ndeploy:\n  stage: deploy\n  script:\n    - ls /;uname -a\n\n\n\n\n\ncommit untuk memproses secara otomatis ci/cd\n\n\n\n\nhasil:\n\n\n\n\n\n\nNext, kita akan coba deployment, automation testing, deliver apps dg konsep tsb lewat ci/cd gitlab.", 
            "title": "CI/CD with Gitlab"
        }, 
        {
            "location": "/ci-cd-with-gitlab/#cicd-with-gitlab", 
            "text": "", 
            "title": "CI/CD with Gitlab"
        }, 
        {
            "location": "/ci-cd-with-gitlab/#install-gitlab-repositories", 
            "text": "install dependencies:  sudo yum install -y curl policycoreutils-python openssh-server\nsudo systemctl enable sshd\nsudo systemctl start sshd\nsudo firewall-cmd --permanent --add-service=http\nsudo firewall-cmd --permanent --add-service=https\nsudo systemctl reload firewalld  install repo:  curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash  install gitlab community edition  EXTERNAL_URL=\"https://gt.doco.dgprasetya.net\" yum install -y gitlab-ce  setelah selesai, bisa diakses via url  https://gt.doco.dgprasetya.net :", 
            "title": "Install Gitlab Repositories"
        }, 
        {
            "location": "/ci-cd-with-gitlab/#install-gitlab-runner", 
            "text": "install dependencies:  yum install -y yum-utils   device-mapper-persistent-data   lvm2  install docker untuk gitlab runner:  yum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo\nyum install docker-ce docker-ce-cli containerd.io  jalankan daemon docker:  systemctl start docker  install runner gitlab:  curl -LJO https://gitlab-runner-downloads.s3.amazonaws.com/latest/rpm/gitlab-runner_amd64.rpm\nyum install git -y\nrpm -i gitlab-runner_amd64.rpm", 
            "title": "Install Gitlab Runner"
        }, 
        {
            "location": "/ci-cd-with-gitlab/#konfiurasiregister-gitlab-runner", 
            "text": "jalan perintah berikut:  gitlab-runner register  lalu akan muncul questions seperti berikut:  Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com)\nhttps://example.digitalocean.com\nEnter the token you obtained from your GitLab instance:\n\nPlease enter the gitlab-ci token for this runner\nsample-gitlab-ci-token\nEnter a description that will help you recognize it in the GitLab web interface. We recommend naming this instance something unique, like runner-bastion for clarity.\n\nPlease enter the gitlab-ci description for this runner\n[yourhostname] runner-bastion\nIf relevant, you may enter the tags for code you will build with your runner. However, we recommend this is left blank at this stage. This can easily be changed from the GitLab interface later.\n\nPlease enter the gitlab-ci tags for this runner (comma separated):\ncode-tag\nChoose whether or not your runner should be able to run untagged jobs. This setting allows you to choose whether your runner should build repositories with no tags at all, or require specific tags. Select true in this case, so your runner can execute all repositories.\n\nWhether to run untagged jobs [true/false]: true\nChoose if this runner should be shared among your projects, or locked to the current one, which blocks it from building any code other than those specified. Select false for now, as this can be changed later in GitLab\u2019s interface:\n\nWhether to lock Runner to current project [true/false]: false\nChoose the executor which will build your machines. Because we\u2019ll be creating new Droplets using Docker, we\u2019ll choose docker+machine here, but you can read more about the advantages of each approach in this compatibility chart:\n\nPlease enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:\ndocker+machine\nYou\u2019ll be asked which image to use for projects that don\u2019t explicitly define one. We\u2019ll choose a basic, secure default:\n\nPlease enter the Docker image (e.g. ruby:2.1):\nalpine:latest  status runner yg sudah terkoneksi:   Contoh sederhana konsep ci/cd di gitlab:   Create Repo Test di Gitlab.   Create file .gitlab-ci.yml , isikan seperti berikut:\nUntuk memahami bagian ini, kita harus tahu dulu referensi pipeline yg digunakan di gitlab. dokumentasi lengkap bisa dibaca di  https://docs.gitlab.com/ce/ci/yaml/ \ndalam contoh ini define stages ke dalam kedua kelompok,  compile  dan  deploy  .   stages:\n  - compile\n  - deploy    setelah itu dari masing-masing kelompok, berikan task dalam variable script dan masukkan kelompok  compile  ke dalam stage:  compile:\n  stage: compile\n  script:\n    - pwd;uname -a;uptime  untuk kelompok yg lain (deploy) sama seperti berikut:  deploy:\n  stage: deploy\n  script:\n    - ls /;uname -a  sesuaikan perintah task yg ada di script.  hasil akhir  .gitlab-ci.yml :  stages:\n  - compile\n  - deploy\n\ncompile:\n  stage: compile\n  script:\n    - pwd;uname -a;uptime\n\ndeploy:\n  stage: deploy\n  script:\n    - ls /;uname -a   commit untuk memproses secara otomatis ci/cd   hasil:    Next, kita akan coba deployment, automation testing, deliver apps dg konsep tsb lewat ci/cd gitlab.", 
            "title": "konfiurasi/register gitlab-runner"
        }, 
        {
            "location": "/net-boot-ipxe-docker-tomcat-centos-coreos/", 
            "text": "Setup Net Boot / DHCP Server with IPXE boot enable\n\n\nassume ip address of this server 10.10.4.22.\n\n\ninstall dnsmasq and nginx package for enable ipxe boot \n\n\nyum install dnsmasq.x86_64 nginx -y\n\n\n\nconfiguration\n\n\nconfig \n/etc/dnsmasq.conf\n\n\ndhcp-range=10.10.4.100,10.10.4.200,30m\ndhcp-option=3,10.10.4.1\ndhcp-option=6,8.8.8.8\n\nenable-tftp\ntftp-root=/opt/tftp\n\n# iPXE - chainload to matchbox ipxe boot script\ndhcp-userclass=set:ipxe,iPXE\n#1\ndhcp-boot=centos6.ipxe\n#2\n#dhcp-boot=centos7.ipxe\n#3\n#dhcp-boot=coreos.ipxe\n\n# verbose\nlog-queries\nlog-dhcp\n\n\n\ncreate file \ncentos6.ipxe\n at /opt/tftp for \ncentos 6\n:\n\n\n#!ipxe\nset base-url http://10.10.4.22\nkernel -n img ${base-url}/centos6/vmlinuz ks=${base-url}/centos6/kickstart.desktop\ninitrd ${base-url}/centos6/initrd.img\nboot img\n\n\n\ncentos7.ipxe for \ncentos 7\n:\n\n\n#!ipxe\nset base-url http://10.10.4.22\nkernel -n img ${base-url}/centos7/vmlinuz ks=${base-url}/centos7/ks7.desktop\ninitrd ${base-url}/centos7/initrd.img\nboot img\n\n\n\ncoreos.ipxe for \ncore os\n:\n\n\n#!ipxe\nset base-url http://10.10.4.22\nkernel ${base-url}/coreos/coreos_production_pxe.vmlinuz initrd=coreos_production_pxe_image.cpio.gz rootfstype=btrfs console=tty0 console=ttyS0 coreos.autologin=tty1 coreos.autologin=ttyS0 coreos.first_boot=1 coreos.config.url=http://10.10.4.22/coreos/preconf.ign\ninitrd ${base-url}/coreos/coreos_production_pxe_image.cpio.gz\nboot\n\n\n\nmkdir \ncentos6,centos7,coreos\n for repositories file:\n\n\nmkdir -p /var/www/html/{centos6,centos7,coreos}\n\n\n\nRequierements\n\n\nDownload requiered files for \nkernel\n and \ninitrd\n:\n\n\nfor \ncentos 6\n:\n\n\ncd /var/www/html/centos6/\nwget -c \"http://mirror.centos.org/centos/6.9/os/x86_64/images/pxeboot/vmlinuz\"\nwget -c \"http://mirror.centos.org/centos/6.9/os/x86_64/images/pxeboot/initrd.img\"\n\n\n\nfor \ncentos 7\n:\n\n\ncd /var/www/html/centos7/\nwget -c \"http://mirror.centos.org/centos/7/os/x86_64/images/pxeboot/vmlinuz\"\nwget -c \"http://mirror.centos.org/centos/7/os/x86_64/images/pxeboot/initrd.img\"\n\n\n\nfor \ncore os\n:\n\n\ncd /var/www/html/coreos/\nwget https://stable.release.core-os.net/amd64-usr/current/coreos_production_pxe.vmlinuz\nwget https://stable.release.core-os.net/amd64-usr/current/coreos_production_pxe_image.cpio.gz\n\n\n\nKickstart\n\n\ncreate Kickstart files:\n\n\nfor \ncentos 6\n (no gui):\n\n\ntext\nskipx\ninstall\n\nurl --url http://mirror.cogentco.com/pub/linux/centos/6.9/os/x86_64/\nrepo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/6/x86_64/\nrepo --name=updates --baseurl=http://mirror.cogentco.com/pub/linux/centos/6.9/updates/x86_64/\n\nlang en_US.UTF-8\nkeyboard us\nrootpw 123456\nfirewall --disabled\nauthconfig --enableshadow --passalgo=sha512\nselinux --disabled\ntimezone Asia/Jakarta\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\npart /boot --fstype ext4 --fsoptions=\"noatime\" --size=200\npart pv.1 --size 1 --grow\nvolgroup vg0 --pesize=4096 pv.1\nlogvol / --fstype ext4 --fsoptions=\"noatime\" --name=root --vgname=vg0 --size=8192\nlogvol swap --fstype swap --name=swap --vgname=vg0 --size 2048\nlogvol /var --fstype ext4 --fsoptions=\"noatime,nodev\" --name=var --vgname=vg0 --size=4096\nlogvol /home --fstype ext4 --fsoptions=\"noatime,nodev\" --name=home --vgname=vg0 --size=2048\n\nservices --enabled=network,ntpd,ntpdate\n\nreboot\n%packages --nobase\nepel-release\nopenssh-clients\nopenssh-server\nyum\nat\nacpid\nvixie-cron\ncronie-noanacron\ncrontabs\nlogrotate\nntp\nntpdate\ntmpwatch\nrsync\nwhich\nwget\ncurl\n%end\n\n\n\nfor \ncentos 6\n kickstart.desktop (with gui):\n\n\ntext\nskipx\ninstall\n\n# Use NFS installation media\n##nfs --server=172.16.240.50 --dir=/work/admin/boot/centos6.5/\n\n#url --url http://mirror.centos.org/centos/6.9/os/x86_64/\n#repo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/6/x86_64/\n#repo --name=updates --baseurl=http://mirror.centos.org/centos/6.9/updates/x86_64/\n\nurl --url http://10.10.4.22/centos-mirror/6.9/os/x86_64/\nrepo --name=epel --baseurl=http://10.10.4.22/epel-mirror/6/x86_64/\nrepo --name=updates --baseurl=http://10.10.4.22/centos-mirror/6.9/updates/x86_64/\n\nlang en_US.UTF-8\nkeyboard us\nrootpw F5d9k2lg6\nuser --name=asd --password=1231213\nfirewall --disabled\nauthconfig --enableshadow --passalgo=sha512\nselinux --disabled\ntimezone Asia/Jakarta\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\nautopart\n\n\n#part /boot --fstype ext4 --fsoptions=\"noatime\" --size=200\n#part pv.1 --size 1 --grow\n#volgroup vg0 --pesize=4096 pv.1\n#logvol / --fstype ext4 --fsoptions=\"noatime\" --name=root --vgname=vg0 --size=0\n#logvol swap --fstype swap --name=swap --vgname=vg0 --size 2048\n#logvol /var --fstype ext4 --fsoptions=\"noatime,nodev\" --name=var --vgname=vg0 --size=4096\n\nxconfig --startxonboot\nservices --enabled=network,ntpd,ntpdate\n\nreboot\n\n%packages                                                                                                                                  \n@base                                                                                                                                      \n@core                                                                                                                                       \n@basic-desktop                                                                                                                              \n@desktop-platform    \n@fonts\n@general-desktop\n@internet-browser\n@legacy-x\n@network-file-system-client\n@perl-runtime\n@print-client\n@remote-desktop-clients\n@x11\ndevice-mapper-persistent-data\nsystemtap-client\njpackage-utils\nxorg-x11-xdm\nlibXmu\nperl-DBD-SQLite\nrdesktop\ncompat-libstdc++-33\nepel-release\nopenssh-clients\nopenssh-server\nyum\nat\nacpid\nvixie-cron\ncronie-noanacron\ncrontabs\nlogrotate\nntp\nntpdate\ntmpwatch\nrsync\nwhich\nwget\ncurl\n%end\n\n%post\nchmod a+x /etc/rc.d/rc.local\n\necho '\nif ! (which catalina.sh \n /dev/null 2\n1); then\n\n\n##install java\nexport JAVA_HOME=/opt/java\nexport JRE_HOME=$JAVA_HOME/jre\nmkdir -p $JAVA_HOME\ncd $JAVA_HOME\nwget -c \"http://ftp.heanet.ie/mirrors/funtoo/distfiles/oracle-java/jdk-7u80-linux-x64.tar.gz\" -O jdk.tar.gz\ntar -xvf jdk.tar.gz --strip-components=1\nalternatives --install /usr/bin/java java $JAVA_HOME/bin/java 2\nalternatives --install /usr/bin/jar jar $JAVA_HOME/bin/jar 2\nalternatives --install /usr/bin/javac javac $JAVA_HOME/bin/javac 2\nalternatives --set jar $JAVA_HOME/bin/jar\nalternatives --set javac $JAVA_HOME/bin/javac\nalternatives --set java $JAVA_HOME/bin/java\n\n        export CATALINA_HOME=/opt/tomcat\n        export PATH=$CATALINA_HOME/bin:$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n\n        mkdir -p \"$CATALINA_HOME\"\n        cd $CATALINA_HOME\n\n        export TOMCAT_MAJOR=7\n        export TOMCAT_VERSION=7.0.84\n        export TOMCAT_TGZ_URL=https://www.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz\n\n        curl -fSL \"$TOMCAT_TGZ_URL\" -o tomcat.tar.gz\n        tar -xvf tomcat.tar.gz --strip-components=1\n        $CATALINA_HOME/bin/catalina.sh start\nfi' \n /etc/rc.d/rc.local\necho '\nexport JAVA_HOME=/opt/java\nexport JRE_HOME=$JAVA_HOME/jre\nexport CATALINA_HOME=/opt/tomcat\n\nexport PATH=$CATALINA_HOME/bin:$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n\n\n' \n /etc/profile\n\n\n%end\n\n\n\nfor \ncentos 7\n (no gui):\n\n\ninstall\nlang en_GB.UTF-8\nkeyboard us\ntimezone Asia/Jakarta\nauth --useshadow --enablemd5\nselinux --disabled\nfirewall --disabled\nservices --enabled=NetworkManager,sshd\neula --agreed\nignoredisk --only-use=sda\nreboot\n\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\nautopart\n#part swap --asprimary --fstype=\"swap\" --size=1024\n#part /boot --fstype xfs --size=200\n#part pv.01 --size=1 --grow\n#volgroup rootvg01 pv.01\n#logvol / --fstype ext4 --name=lv01 --vgname=rootvg01 --size=1 --grow\n\nrootpw 123456\n\nrepo --name=base --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\nurl --url=\"http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\"\n\n#url --url http://mirror.centos.org/centos/7/os/x86_64/\n#repo --name=base --baseurl=http://mirror.centos.org/centos/7/os/x86_64/\nrepo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/7/x86_64/\nrepo --name=updates --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/updates/x86_64/\n\n%packages --nobase --ignoremissing\n@core\nepel-release\nopenssh-clients\nopenssh-server\nyum\nat\ncronie-noanacron\ncrontabs\nlogrotate\nntp\nntpdate\ntmpwatch\nrsync\nwhich\nwget\ncurl\n%end\n\n\n\nfor \ncentos 7\n ks7.desktop (with gui + docker + symmetricDS):\n\n\ninstall\nlang en_GB.UTF-8\nkeyboard us\ntimezone Asia/Jakarta\nauth --useshadow --enablemd5\nselinux --disabled   \nfirewall --disabled  \nservices --enabled=NetworkManager,sshd\n#services --disabled=initial-setup-text\n#initial-setup-text --disabled\nfirstboot --disable  \neula --agreed\nignoredisk --only-use=sda\nreboot\n\nxconfig  --startxonboot\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\nautopart\n#part swap --asprimary --fstype=\"swap\" --size=1024\n##part /boot --fstype ext4 --size=200\n#part pv.01 --size=1 --grow\n#volgroup rootvg01 pv.01\n#logvol / --fstype ext4 --name=lv01 --vgname=rootvg01 --size=1 --grow\n\nrootpw 123456\nuser --name=asd --password=123123\n\nrepo --name=base --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\nurl --url=\"http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\"\n\n#url --url http://mirror.centos.org/centos/7/os/x86_64/\n#repo --name=base --baseurl=http://mirror.centos.org/centos/7/os/x86_64/\nrepo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/7/x86_64/\nrepo --name=updates --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/updates/x86_64/\n\n\n%packages\n@^graphical-server-environment\n@base\n@core\n@desktop-debugging   \n@dial-up\n@fonts\n@gnome-desktop\n@guest-agents\n@guest-desktop-agents\n@input-methods\n@internet-browser\n@multimedia\n@print-client\n@x11\nchrony\nkexec-tools\n\n%end\n\n%addon com_redhat_kdump --enable --reserve-mb='auto'\n\n%end\n\n%post\n\nsystemctl disable initial-setup-graphical.service\nchmod a+x /etc/rc.d/rc.local\n\necho '\nif ! (which docker \n /dev/null 2\n1); then\n\n        curl \"https://gitlab.com/symmetric-ds.tar\" \n /opt/symmetric-ds.tar\n        cd /opt/;tar -xvf symmetric-ds.tar;\n        mkdir -p /opt/webapps/jspapps;\n        echo \"jspapps put here\" \n /opt/webapps/jspapps/index.jsp;\n        curl \"http://url/install-docker-centos7.sh\" \n /usr/src/install-docker.sh\n        /bin/bash -x /usr/src/install-docker.sh 2\n1 | tee /usr/src/debug-install.log\nfi\n' \n /etc/rc.d/rc.local\n\n%end\n\n\n\nfor \ncore os\n \npreconf.ign\n (with tomcat container): \n\n\n{\n  \"ignition\": {\n    \"config\": {},\n    \"timeouts\": {},\n    \"version\": \"2.1.0\"\n  },\n  \"networkd\": {},\n  \"passwd\": {},\n  \"storage\": {\n    \"disks\": [\n      {\n        \"device\": \"/dev/sda\",\n        \"partitions\": [\n          {\n            \"label\": \"ROOT\"\n          }\n        ],\n        \"wipeTable\": true\n      }\n    ],\n    \"filesystems\": [\n      {\n        \"mount\": {\n          \"device\": \"/dev/disk/by-partlabel/ROOT\",\n          \"format\": \"ext4\",\n          \"label\": \"ROOT\",\n          \"wipeFilesystem\": true\n        }\n      }\n    ],\n    \"files\": [\n      {\n        \"filesystem\": \"root\",\n        \"path\": \"/opt/installer\",\n        \"mode\": 755,\n        \"contents\": {\n          \"source\": \"http://10.10.4.22/coreos/installer.sh\"\n        }\n      },\n      {\n        \"filesystem\": \"root\",\n        \"path\": \"/etc/hostname\",\n        \"mode\": 420,\n        \"contents\": {\n          \"source\": \"data:,installer\"\n        }\n      }\n    ]\n  },\n  \"systemd\": {\n    \"units\": [\n      {\n        \"name\": \"installer.service\",\n        \"enabled\": true,\n        \"contents\": \"[Unit]\\nRequires=network-online.target\\nAfter=network-online.target\\n[Service]\\nType=simple\\nExecStart=/opt/installer\\n[Install]\\nWantedBy=multi-user.target\"\n      }\n    ]\n  }\n}\n\n\n\nput \ninstaller.sh\n to /var/www/coreos/:\n\n\n#!/bin/bash -ex\n\n#curl --retry 10 --fail \"{{.ignition_endpoint}}?{{.request.raw_query}}\nos=installed\" -o ignition.json\n\ncurl http://10.10.4.22/coreos/install.ign -o /tmp/install.ign\ncoreos-install -d /dev/sda -C stable -i /tmp/install.ign\n#{{.coreos_channel}} -V {{.coreos_version}} -i ignition.json {{if index . \"baseurl\"}}-b {{.baseurl}}{{end}}\nudevadm settle\nsystemctl reboot\n\n\n\nput \ninstall.ign\n to /var/www/coreos/:\n\n\n{\n  \"ignition\": {\n    \"config\": {},\n    \"timeouts\": {},\n    \"version\": \"2.1.0\"\n  },\n  \"networkd\": {},\n  \"passwd\": {\n    \"users\": [\n      {\n        \"groups\": [\n          \"sudo\",\n          \"docker\"\n        ],\n        \"name\": \"asd\",\n        \"passwordHash\": \"$6$pk78SVN.I$veAoRIG9GZkstvrVLY0aIRAvOoqOqz3r4YZdZoQ5aZTFD2jrDlF1.GCzLuU.h274MyYmu1KFnuss51SPARMQv.\"\n      }\n    ]\n  },\n  \"storage\": {\n    \"files\": [\n      {\n        \"filesystem\": \"root\",\n        \"path\": \"/etc/hostname\",\n        \"mode\": 420,\n        \"contents\": {\n          \"source\": \"data:,coreos-asd\"\n        }\n      },\n        {\n        \"filesystem\": \"root\",\n        \"path\": \"/opt/tomcat-install\",\n        \"mode\": 755,\n        \"contents\": {\n          \"source\": \"http://10.10.4.22/coreos/tomcat-install.sh\"\n         }\n        }\n    ]\n  },\n  \"systemd\": {    \"units\": [\n  {\n    \"name\": \"tomcat-install.service\",\n    \"enabled\": true,\n    \"contents\": \"[Unit]\\nRequires=network-online.target\\nAfter=network-online.target\\n[Service]\\nType=simple\\nExecStart=/opt/tomcat-install\\n[Install]\\nWantedBy=multi-user.target\"\n  }\n]}\n}\n\n\n\nput \ntomcat-install.sh\n to /var/www/html/coreos/:\n\n\n#!/bin/bash\n\ndocker run -id --rm -p 8888:8080 tomcat:7\n\n\n\nstart dnsmasq for turn on dhcp services plus ipxe:\n\n\n/etc/init.d/dnsmasq start\n\n\n\nDone\n\n\nand try boot with ipxe.", 
            "title": "Docker auto setup via IPXE for Centos and Core OS"
        }, 
        {
            "location": "/net-boot-ipxe-docker-tomcat-centos-coreos/#setup-net-boot-dhcp-server-with-ipxe-boot-enable", 
            "text": "assume ip address of this server 10.10.4.22.  install dnsmasq and nginx package for enable ipxe boot   yum install dnsmasq.x86_64 nginx -y", 
            "title": "Setup Net Boot / DHCP Server with IPXE boot enable"
        }, 
        {
            "location": "/net-boot-ipxe-docker-tomcat-centos-coreos/#configuration", 
            "text": "config  /etc/dnsmasq.conf  dhcp-range=10.10.4.100,10.10.4.200,30m\ndhcp-option=3,10.10.4.1\ndhcp-option=6,8.8.8.8\n\nenable-tftp\ntftp-root=/opt/tftp\n\n# iPXE - chainload to matchbox ipxe boot script\ndhcp-userclass=set:ipxe,iPXE\n#1\ndhcp-boot=centos6.ipxe\n#2\n#dhcp-boot=centos7.ipxe\n#3\n#dhcp-boot=coreos.ipxe\n\n# verbose\nlog-queries\nlog-dhcp  create file  centos6.ipxe  at /opt/tftp for  centos 6 :  #!ipxe\nset base-url http://10.10.4.22\nkernel -n img ${base-url}/centos6/vmlinuz ks=${base-url}/centos6/kickstart.desktop\ninitrd ${base-url}/centos6/initrd.img\nboot img  centos7.ipxe for  centos 7 :  #!ipxe\nset base-url http://10.10.4.22\nkernel -n img ${base-url}/centos7/vmlinuz ks=${base-url}/centos7/ks7.desktop\ninitrd ${base-url}/centos7/initrd.img\nboot img  coreos.ipxe for  core os :  #!ipxe\nset base-url http://10.10.4.22\nkernel ${base-url}/coreos/coreos_production_pxe.vmlinuz initrd=coreos_production_pxe_image.cpio.gz rootfstype=btrfs console=tty0 console=ttyS0 coreos.autologin=tty1 coreos.autologin=ttyS0 coreos.first_boot=1 coreos.config.url=http://10.10.4.22/coreos/preconf.ign\ninitrd ${base-url}/coreos/coreos_production_pxe_image.cpio.gz\nboot  mkdir  centos6,centos7,coreos  for repositories file:  mkdir -p /var/www/html/{centos6,centos7,coreos}", 
            "title": "configuration"
        }, 
        {
            "location": "/net-boot-ipxe-docker-tomcat-centos-coreos/#requierements", 
            "text": "Download requiered files for  kernel  and  initrd :  for  centos 6 :  cd /var/www/html/centos6/\nwget -c \"http://mirror.centos.org/centos/6.9/os/x86_64/images/pxeboot/vmlinuz\"\nwget -c \"http://mirror.centos.org/centos/6.9/os/x86_64/images/pxeboot/initrd.img\"  for  centos 7 :  cd /var/www/html/centos7/\nwget -c \"http://mirror.centos.org/centos/7/os/x86_64/images/pxeboot/vmlinuz\"\nwget -c \"http://mirror.centos.org/centos/7/os/x86_64/images/pxeboot/initrd.img\"  for  core os :  cd /var/www/html/coreos/\nwget https://stable.release.core-os.net/amd64-usr/current/coreos_production_pxe.vmlinuz\nwget https://stable.release.core-os.net/amd64-usr/current/coreos_production_pxe_image.cpio.gz", 
            "title": "Requierements"
        }, 
        {
            "location": "/net-boot-ipxe-docker-tomcat-centos-coreos/#kickstart", 
            "text": "create Kickstart files:  for  centos 6  (no gui):  text\nskipx\ninstall\n\nurl --url http://mirror.cogentco.com/pub/linux/centos/6.9/os/x86_64/\nrepo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/6/x86_64/\nrepo --name=updates --baseurl=http://mirror.cogentco.com/pub/linux/centos/6.9/updates/x86_64/\n\nlang en_US.UTF-8\nkeyboard us\nrootpw 123456\nfirewall --disabled\nauthconfig --enableshadow --passalgo=sha512\nselinux --disabled\ntimezone Asia/Jakarta\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\npart /boot --fstype ext4 --fsoptions=\"noatime\" --size=200\npart pv.1 --size 1 --grow\nvolgroup vg0 --pesize=4096 pv.1\nlogvol / --fstype ext4 --fsoptions=\"noatime\" --name=root --vgname=vg0 --size=8192\nlogvol swap --fstype swap --name=swap --vgname=vg0 --size 2048\nlogvol /var --fstype ext4 --fsoptions=\"noatime,nodev\" --name=var --vgname=vg0 --size=4096\nlogvol /home --fstype ext4 --fsoptions=\"noatime,nodev\" --name=home --vgname=vg0 --size=2048\n\nservices --enabled=network,ntpd,ntpdate\n\nreboot\n%packages --nobase\nepel-release\nopenssh-clients\nopenssh-server\nyum\nat\nacpid\nvixie-cron\ncronie-noanacron\ncrontabs\nlogrotate\nntp\nntpdate\ntmpwatch\nrsync\nwhich\nwget\ncurl\n%end  for  centos 6  kickstart.desktop (with gui):  text\nskipx\ninstall\n\n# Use NFS installation media\n##nfs --server=172.16.240.50 --dir=/work/admin/boot/centos6.5/\n\n#url --url http://mirror.centos.org/centos/6.9/os/x86_64/\n#repo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/6/x86_64/\n#repo --name=updates --baseurl=http://mirror.centos.org/centos/6.9/updates/x86_64/\n\nurl --url http://10.10.4.22/centos-mirror/6.9/os/x86_64/\nrepo --name=epel --baseurl=http://10.10.4.22/epel-mirror/6/x86_64/\nrepo --name=updates --baseurl=http://10.10.4.22/centos-mirror/6.9/updates/x86_64/\n\nlang en_US.UTF-8\nkeyboard us\nrootpw F5d9k2lg6\nuser --name=asd --password=1231213\nfirewall --disabled\nauthconfig --enableshadow --passalgo=sha512\nselinux --disabled\ntimezone Asia/Jakarta\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\nautopart\n\n\n#part /boot --fstype ext4 --fsoptions=\"noatime\" --size=200\n#part pv.1 --size 1 --grow\n#volgroup vg0 --pesize=4096 pv.1\n#logvol / --fstype ext4 --fsoptions=\"noatime\" --name=root --vgname=vg0 --size=0\n#logvol swap --fstype swap --name=swap --vgname=vg0 --size 2048\n#logvol /var --fstype ext4 --fsoptions=\"noatime,nodev\" --name=var --vgname=vg0 --size=4096\n\nxconfig --startxonboot\nservices --enabled=network,ntpd,ntpdate\n\nreboot\n\n%packages                                                                                                                                  \n@base                                                                                                                                      \n@core                                                                                                                                       \n@basic-desktop                                                                                                                              \n@desktop-platform    \n@fonts\n@general-desktop\n@internet-browser\n@legacy-x\n@network-file-system-client\n@perl-runtime\n@print-client\n@remote-desktop-clients\n@x11\ndevice-mapper-persistent-data\nsystemtap-client\njpackage-utils\nxorg-x11-xdm\nlibXmu\nperl-DBD-SQLite\nrdesktop\ncompat-libstdc++-33\nepel-release\nopenssh-clients\nopenssh-server\nyum\nat\nacpid\nvixie-cron\ncronie-noanacron\ncrontabs\nlogrotate\nntp\nntpdate\ntmpwatch\nrsync\nwhich\nwget\ncurl\n%end\n\n%post\nchmod a+x /etc/rc.d/rc.local\n\necho '\nif ! (which catalina.sh   /dev/null 2 1); then\n\n\n##install java\nexport JAVA_HOME=/opt/java\nexport JRE_HOME=$JAVA_HOME/jre\nmkdir -p $JAVA_HOME\ncd $JAVA_HOME\nwget -c \"http://ftp.heanet.ie/mirrors/funtoo/distfiles/oracle-java/jdk-7u80-linux-x64.tar.gz\" -O jdk.tar.gz\ntar -xvf jdk.tar.gz --strip-components=1\nalternatives --install /usr/bin/java java $JAVA_HOME/bin/java 2\nalternatives --install /usr/bin/jar jar $JAVA_HOME/bin/jar 2\nalternatives --install /usr/bin/javac javac $JAVA_HOME/bin/javac 2\nalternatives --set jar $JAVA_HOME/bin/jar\nalternatives --set javac $JAVA_HOME/bin/javac\nalternatives --set java $JAVA_HOME/bin/java\n\n        export CATALINA_HOME=/opt/tomcat\n        export PATH=$CATALINA_HOME/bin:$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n\n        mkdir -p \"$CATALINA_HOME\"\n        cd $CATALINA_HOME\n\n        export TOMCAT_MAJOR=7\n        export TOMCAT_VERSION=7.0.84\n        export TOMCAT_TGZ_URL=https://www.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz\n\n        curl -fSL \"$TOMCAT_TGZ_URL\" -o tomcat.tar.gz\n        tar -xvf tomcat.tar.gz --strip-components=1\n        $CATALINA_HOME/bin/catalina.sh start\nfi'   /etc/rc.d/rc.local\necho '\nexport JAVA_HOME=/opt/java\nexport JRE_HOME=$JAVA_HOME/jre\nexport CATALINA_HOME=/opt/tomcat\n\nexport PATH=$CATALINA_HOME/bin:$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n\n\n'   /etc/profile\n\n\n%end  for  centos 7  (no gui):  install\nlang en_GB.UTF-8\nkeyboard us\ntimezone Asia/Jakarta\nauth --useshadow --enablemd5\nselinux --disabled\nfirewall --disabled\nservices --enabled=NetworkManager,sshd\neula --agreed\nignoredisk --only-use=sda\nreboot\n\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\nautopart\n#part swap --asprimary --fstype=\"swap\" --size=1024\n#part /boot --fstype xfs --size=200\n#part pv.01 --size=1 --grow\n#volgroup rootvg01 pv.01\n#logvol / --fstype ext4 --name=lv01 --vgname=rootvg01 --size=1 --grow\n\nrootpw 123456\n\nrepo --name=base --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\nurl --url=\"http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\"\n\n#url --url http://mirror.centos.org/centos/7/os/x86_64/\n#repo --name=base --baseurl=http://mirror.centos.org/centos/7/os/x86_64/\nrepo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/7/x86_64/\nrepo --name=updates --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/updates/x86_64/\n\n%packages --nobase --ignoremissing\n@core\nepel-release\nopenssh-clients\nopenssh-server\nyum\nat\ncronie-noanacron\ncrontabs\nlogrotate\nntp\nntpdate\ntmpwatch\nrsync\nwhich\nwget\ncurl\n%end  for  centos 7  ks7.desktop (with gui + docker + symmetricDS):  install\nlang en_GB.UTF-8\nkeyboard us\ntimezone Asia/Jakarta\nauth --useshadow --enablemd5\nselinux --disabled   \nfirewall --disabled  \nservices --enabled=NetworkManager,sshd\n#services --disabled=initial-setup-text\n#initial-setup-text --disabled\nfirstboot --disable  \neula --agreed\nignoredisk --only-use=sda\nreboot\n\nxconfig  --startxonboot\nbootloader --location=mbr\nzerombr\nclearpart --all --initlabel\nautopart\n#part swap --asprimary --fstype=\"swap\" --size=1024\n##part /boot --fstype ext4 --size=200\n#part pv.01 --size=1 --grow\n#volgroup rootvg01 pv.01\n#logvol / --fstype ext4 --name=lv01 --vgname=rootvg01 --size=1 --grow\n\nrootpw 123456\nuser --name=asd --password=123123\n\nrepo --name=base --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\nurl --url=\"http://mirror.cogentco.com/pub/linux/centos/7/os/x86_64/\"\n\n#url --url http://mirror.centos.org/centos/7/os/x86_64/\n#repo --name=base --baseurl=http://mirror.centos.org/centos/7/os/x86_64/\nrepo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/7/x86_64/\nrepo --name=updates --baseurl=http://mirror.cogentco.com/pub/linux/centos/7/updates/x86_64/\n\n\n%packages\n@^graphical-server-environment\n@base\n@core\n@desktop-debugging   \n@dial-up\n@fonts\n@gnome-desktop\n@guest-agents\n@guest-desktop-agents\n@input-methods\n@internet-browser\n@multimedia\n@print-client\n@x11\nchrony\nkexec-tools\n\n%end\n\n%addon com_redhat_kdump --enable --reserve-mb='auto'\n\n%end\n\n%post\n\nsystemctl disable initial-setup-graphical.service\nchmod a+x /etc/rc.d/rc.local\n\necho '\nif ! (which docker   /dev/null 2 1); then\n\n        curl \"https://gitlab.com/symmetric-ds.tar\"   /opt/symmetric-ds.tar\n        cd /opt/;tar -xvf symmetric-ds.tar;\n        mkdir -p /opt/webapps/jspapps;\n        echo \"jspapps put here\"   /opt/webapps/jspapps/index.jsp;\n        curl \"http://url/install-docker-centos7.sh\"   /usr/src/install-docker.sh\n        /bin/bash -x /usr/src/install-docker.sh 2 1 | tee /usr/src/debug-install.log\nfi\n'   /etc/rc.d/rc.local\n\n%end  for  core os   preconf.ign  (with tomcat container):   {\n  \"ignition\": {\n    \"config\": {},\n    \"timeouts\": {},\n    \"version\": \"2.1.0\"\n  },\n  \"networkd\": {},\n  \"passwd\": {},\n  \"storage\": {\n    \"disks\": [\n      {\n        \"device\": \"/dev/sda\",\n        \"partitions\": [\n          {\n            \"label\": \"ROOT\"\n          }\n        ],\n        \"wipeTable\": true\n      }\n    ],\n    \"filesystems\": [\n      {\n        \"mount\": {\n          \"device\": \"/dev/disk/by-partlabel/ROOT\",\n          \"format\": \"ext4\",\n          \"label\": \"ROOT\",\n          \"wipeFilesystem\": true\n        }\n      }\n    ],\n    \"files\": [\n      {\n        \"filesystem\": \"root\",\n        \"path\": \"/opt/installer\",\n        \"mode\": 755,\n        \"contents\": {\n          \"source\": \"http://10.10.4.22/coreos/installer.sh\"\n        }\n      },\n      {\n        \"filesystem\": \"root\",\n        \"path\": \"/etc/hostname\",\n        \"mode\": 420,\n        \"contents\": {\n          \"source\": \"data:,installer\"\n        }\n      }\n    ]\n  },\n  \"systemd\": {\n    \"units\": [\n      {\n        \"name\": \"installer.service\",\n        \"enabled\": true,\n        \"contents\": \"[Unit]\\nRequires=network-online.target\\nAfter=network-online.target\\n[Service]\\nType=simple\\nExecStart=/opt/installer\\n[Install]\\nWantedBy=multi-user.target\"\n      }\n    ]\n  }\n}  put  installer.sh  to /var/www/coreos/:  #!/bin/bash -ex\n\n#curl --retry 10 --fail \"{{.ignition_endpoint}}?{{.request.raw_query}} os=installed\" -o ignition.json\n\ncurl http://10.10.4.22/coreos/install.ign -o /tmp/install.ign\ncoreos-install -d /dev/sda -C stable -i /tmp/install.ign\n#{{.coreos_channel}} -V {{.coreos_version}} -i ignition.json {{if index . \"baseurl\"}}-b {{.baseurl}}{{end}}\nudevadm settle\nsystemctl reboot  put  install.ign  to /var/www/coreos/:  {\n  \"ignition\": {\n    \"config\": {},\n    \"timeouts\": {},\n    \"version\": \"2.1.0\"\n  },\n  \"networkd\": {},\n  \"passwd\": {\n    \"users\": [\n      {\n        \"groups\": [\n          \"sudo\",\n          \"docker\"\n        ],\n        \"name\": \"asd\",\n        \"passwordHash\": \"$6$pk78SVN.I$veAoRIG9GZkstvrVLY0aIRAvOoqOqz3r4YZdZoQ5aZTFD2jrDlF1.GCzLuU.h274MyYmu1KFnuss51SPARMQv.\"\n      }\n    ]\n  },\n  \"storage\": {\n    \"files\": [\n      {\n        \"filesystem\": \"root\",\n        \"path\": \"/etc/hostname\",\n        \"mode\": 420,\n        \"contents\": {\n          \"source\": \"data:,coreos-asd\"\n        }\n      },\n        {\n        \"filesystem\": \"root\",\n        \"path\": \"/opt/tomcat-install\",\n        \"mode\": 755,\n        \"contents\": {\n          \"source\": \"http://10.10.4.22/coreos/tomcat-install.sh\"\n         }\n        }\n    ]\n  },\n  \"systemd\": {    \"units\": [\n  {\n    \"name\": \"tomcat-install.service\",\n    \"enabled\": true,\n    \"contents\": \"[Unit]\\nRequires=network-online.target\\nAfter=network-online.target\\n[Service]\\nType=simple\\nExecStart=/opt/tomcat-install\\n[Install]\\nWantedBy=multi-user.target\"\n  }\n]}\n}  put  tomcat-install.sh  to /var/www/html/coreos/:  #!/bin/bash\n\ndocker run -id --rm -p 8888:8080 tomcat:7  start dnsmasq for turn on dhcp services plus ipxe:  /etc/init.d/dnsmasq start", 
            "title": "Kickstart"
        }, 
        {
            "location": "/net-boot-ipxe-docker-tomcat-centos-coreos/#done", 
            "text": "and try boot with ipxe.", 
            "title": "Done"
        }, 
        {
            "location": "/google-cloud-platform-connect-two-instances-with-ip-private-via-vpc-peering/", 
            "text": "How to connect two instances Google Cloud Platform with ip private via VPC Peering\n\n\nIn order this environment, we need create two instances and running as well.\n\n\nConfiguring\n\n\nInstance 1 - VPC\n\n\n\n\nCreate VPC Network, in example with name: \ndhroot\n , subnet: \n10.10.10.0/24\n , private google: \non\n\n\nCreate VPC Network Peering, in example with name of peering: \nungaran-peering\n, current name vpc: \ndhroot\n (VPC Network created before), other Peered VPC network: \ndefault\n (example), other Peered project ID: \ndd1177\n (example).\n\n\nclick create\n\n\n\n\nInstance 1 - Compute\n\n\n\n\nconfigure nic0 with internal ip: \n10.10.10.4\n and subnet network: \ndhroot\n.\n\n\nsave, done. reboot or restart to make sure use new subnet.\n\n\n\n\nInstance 2 - VPC\n\n\n\n\nDont Create VPC Network, because we use existing network. But if you want to create, you must define the current name VPC into step 2.\n\n\nCreate VPC Network Peering, in example with name of peering: \nungaran-peering\n, current name vpc: \ndefault\n (existing VPC Network), other Peered VPC network: \ndhroot\n, other Peered project ID: dd1188 (example).\n\n\nclick create\n\n\n\n\nInstance 2 - Compute\n\n\nnothing to do.\n\n\nTesting\n\n\nAfter we create VPC Network Peering, check connection. it should be like this:\n\n\nfrom instance 1:\n\n\n\n\neth\n\n\nuser@dct:~$ ip addr show eth0\n2: eth0: \nBROADCAST,MULTICAST,UP,LOWER_UP\n mtu 1460 qdisc pfifo_fast state UP group default qlen 1000\nlink/ether 42:01:0a:0a:0a:04 brd ff:ff:ff:ff:ff:ff\ninet 10.10.10.4/32 brd 10.10.10.4 scope global eth0\n   valid_lft forever preferred_lft forever\ninet6 fe80::4001:aff:fe0a:a04/64 scope link \n   valid_lft forever preferred_lft forever\n\n\n\ntrying ping\n\n\nuser@dct:~$ ping 10.148.0.4\nPING 10.148.0.4 (10.148.0.4) 56(84) bytes of data.\n64 bytes from 10.148.0.4: icmp_seq=1 ttl=64 time=0.872 ms\n64 bytes from 10.148.0.4: icmp_seq=2 ttl=64 time=0.213 ms\n64 bytes from 10.148.0.4: icmp_seq=3 ttl=64 time=0.245 ms\n^C\n--- 10.148.0.4 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 2040ms\nrtt min/avg/max/mdev = 0.213/0.443/0.872/0.303 ms\n\n\n\nfrom instance 2:\n\n\n\n\neth:\n\n\n[root@serv3 ~]# ip addr show eth0\n2: eth0: \nBROADCAST,MULTICAST,UP,LOWER_UP\n mtu 1460 qdisc mq state UP group default qlen 1000\n    link/ether 42:01:0a:94:00:04 brd ff:ff:ff:ff:ff:ff\n    inet 10.148.0.4/32 brd 10.148.0.4 scope global dynamic eth0\n       valid_lft 59636sec preferred_lft 59636sec\n    inet6 fe80::4001:aff:fe94:4/64 scope link \n       valid_lft forever preferred_lft forever\n[root@serv3 ~]#\n\n\n\nping:\n\n\n[root@serv3 ~]# ping 10.10.10.4\nPING 10.10.10.4 (10.10.10.4) 56(84) bytes of data.\n64 bytes from 10.10.10.4: icmp_seq=1 ttl=64 time=1.02 ms\n64 bytes from 10.10.10.4: icmp_seq=2 ttl=64 time=0.185 ms\n64 bytes from 10.10.10.4: icmp_seq=3 ttl=64 time=0.305 ms\n64 bytes from 10.10.10.4: icmp_seq=4 ttl=64 time=0.202 ms\n\n\n\ndone.", 
            "title": "GCP - How to connect two instances with IP Private via VPC Peering"
        }, 
        {
            "location": "/google-cloud-platform-connect-two-instances-with-ip-private-via-vpc-peering/#how-to-connect-two-instances-google-cloud-platform-with-ip-private-via-vpc-peering", 
            "text": "In order this environment, we need create two instances and running as well.", 
            "title": "How to connect two instances Google Cloud Platform with ip private via VPC Peering"
        }, 
        {
            "location": "/google-cloud-platform-connect-two-instances-with-ip-private-via-vpc-peering/#configuring", 
            "text": "Instance 1 - VPC   Create VPC Network, in example with name:  dhroot  , subnet:  10.10.10.0/24  , private google:  on  Create VPC Network Peering, in example with name of peering:  ungaran-peering , current name vpc:  dhroot  (VPC Network created before), other Peered VPC network:  default  (example), other Peered project ID:  dd1177  (example).  click create   Instance 1 - Compute   configure nic0 with internal ip:  10.10.10.4  and subnet network:  dhroot .  save, done. reboot or restart to make sure use new subnet.   Instance 2 - VPC   Dont Create VPC Network, because we use existing network. But if you want to create, you must define the current name VPC into step 2.  Create VPC Network Peering, in example with name of peering:  ungaran-peering , current name vpc:  default  (existing VPC Network), other Peered VPC network:  dhroot , other Peered project ID: dd1188 (example).  click create   Instance 2 - Compute  nothing to do.", 
            "title": "Configuring"
        }, 
        {
            "location": "/google-cloud-platform-connect-two-instances-with-ip-private-via-vpc-peering/#testing", 
            "text": "After we create VPC Network Peering, check connection. it should be like this:  from instance 1:   eth  user@dct:~$ ip addr show eth0\n2: eth0:  BROADCAST,MULTICAST,UP,LOWER_UP  mtu 1460 qdisc pfifo_fast state UP group default qlen 1000\nlink/ether 42:01:0a:0a:0a:04 brd ff:ff:ff:ff:ff:ff\ninet 10.10.10.4/32 brd 10.10.10.4 scope global eth0\n   valid_lft forever preferred_lft forever\ninet6 fe80::4001:aff:fe0a:a04/64 scope link \n   valid_lft forever preferred_lft forever  trying ping  user@dct:~$ ping 10.148.0.4\nPING 10.148.0.4 (10.148.0.4) 56(84) bytes of data.\n64 bytes from 10.148.0.4: icmp_seq=1 ttl=64 time=0.872 ms\n64 bytes from 10.148.0.4: icmp_seq=2 ttl=64 time=0.213 ms\n64 bytes from 10.148.0.4: icmp_seq=3 ttl=64 time=0.245 ms\n^C\n--- 10.148.0.4 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 2040ms\nrtt min/avg/max/mdev = 0.213/0.443/0.872/0.303 ms  from instance 2:   eth:  [root@serv3 ~]# ip addr show eth0\n2: eth0:  BROADCAST,MULTICAST,UP,LOWER_UP  mtu 1460 qdisc mq state UP group default qlen 1000\n    link/ether 42:01:0a:94:00:04 brd ff:ff:ff:ff:ff:ff\n    inet 10.148.0.4/32 brd 10.148.0.4 scope global dynamic eth0\n       valid_lft 59636sec preferred_lft 59636sec\n    inet6 fe80::4001:aff:fe94:4/64 scope link \n       valid_lft forever preferred_lft forever\n[root@serv3 ~]#  ping:  [root@serv3 ~]# ping 10.10.10.4\nPING 10.10.10.4 (10.10.10.4) 56(84) bytes of data.\n64 bytes from 10.10.10.4: icmp_seq=1 ttl=64 time=1.02 ms\n64 bytes from 10.10.10.4: icmp_seq=2 ttl=64 time=0.185 ms\n64 bytes from 10.10.10.4: icmp_seq=3 ttl=64 time=0.305 ms\n64 bytes from 10.10.10.4: icmp_seq=4 ttl=64 time=0.202 ms  done.", 
            "title": "Testing"
        }, 
        {
            "location": "/google-cloud-platform-multiple-nics-with-vpc-peering/", 
            "text": "How to connect Multiple Nics with VPC Peering at Google Cloud Platform\n\n\nAssumed we can connect successfuly with VPC Peering within \nthis tutorial\n. Now we try add more nics. in this example, we added 1 nic. Nic at Google compute engine cant add or remove, we must recreate compute engine to have more or less nic.\n\n\nTopology:\n\n\n+-------+                 +--------+\n|       nic0+             |        |\n|       |   \n-----------\n nic0     |\n|       nic1+             |        |\n+-------+                 +--------+\n\nserver 1                  server2\n\n\n\nserver 1\n\n\nnic0 = 10.10.10.4/24\nnic1 = 10.10.8.4/24\n\n\n\nserver 2\n\n\nnic0 = 10.148.0.4/24\n\n\n\nConfigure:\n\n\nserver 1\n\n\n\n\nCreate a new VPC Network with subnet \n10.10.8.0/24\n . Dont overlap other subnet, in this example we use \n10.10.8.0/24\n.\n\n\nCreate VPC Network Peering with name \nsingle-iface\n (in example). Follow \nthis tutorial\n. \n\n\nconfigure or add two nic\n\n\nwith first nic0 \n10.10.10.4/32\n subnet/network \ndhroot\n (in example), with external custom static ip address.\n\n\nwith second nic1 \n10.10.8.4/32\n subnet/network \nsingle-iface\n (in example), with none external ip address.\n\n\n\n\n\n\n\n\n\n\n\n\nserver 1 done.\n\n\n\n\nserver 2\n\n\n\n\nCreate VPC Network Peering with name \nsingle-iface2-dgp\n (in example). Follow \nthis tutorial\n. \n\n\nserver 2 done\n\n\n\n\nat the end configuration, it should be looks like these:\n\n\nfrom instance 1\n\n\n\n\nfrom instance 2\n\n\n\n\nwe can ping {from,to} server 1 {to,from} server 2 via \nnic0\n. But cant ping \nserver 1\n with ip address \n10.10.8.0/24\n from \nserver 2\n because main/default routed to \n10.10.10.1\n when leave interface. We can use \ntcpdump\n to troubleshoot this issue.\n\n\nso we need route nic1 traffic from/to \n10.10.8.0/24\n via interface \nnic1\n or \neth1\n to \n10.10.8.1\n with table routing to fix this issue.\n\n\nassumed ip address nic1/eth1: \n10.10.8.4\n, so configure \nserver 1\n with these commands:\n\n\nifconfig eth1 10.10.8.4 netmask 255.255.255.255 broadcast 10.10.8.4 mtu 1430\necho \"1 rt1\" | tee -a /etc/iproute2/rt_tables\nip route add 10.10.8.1 src 10.10.8.4 dev eth1\nip route add default via 10.10.8.1 dev eth1 table rt1\nip rule add from 10.10.8.4/32 table rt1\nip rule add to 10.10.8.4/32 table rt1\n\n\n\nrecheck again traffic route to \n10.10.8.1\n:\n\n\nroot@dct:~# ip route show dev eth1 table rt1\ndefault via 10.10.8.1 \nroot@dct:~#\n\n\n\nTesting\n\n\nnow, trying ping or other tcp connect from server 2:\n\n\n[root@serv3 ~]# telnet 10.10.8.4 22\nTrying 10.10.8.4...\nConnected to 10.10.8.4.\nEscape character is '^]'.\nSSH-2.0-OpenSSH_7.4p1 Debian-10+deb9u2\n\n\n\ndone.", 
            "title": "GCP - How to connect Multiple Nics with VPC Peering at Google Cloud Platform"
        }, 
        {
            "location": "/google-cloud-platform-multiple-nics-with-vpc-peering/#how-to-connect-multiple-nics-with-vpc-peering-at-google-cloud-platform", 
            "text": "Assumed we can connect successfuly with VPC Peering within  this tutorial . Now we try add more nics. in this example, we added 1 nic. Nic at Google compute engine cant add or remove, we must recreate compute engine to have more or less nic.", 
            "title": "How to connect Multiple Nics with VPC Peering at Google Cloud Platform"
        }, 
        {
            "location": "/google-cloud-platform-multiple-nics-with-vpc-peering/#topology", 
            "text": "+-------+                 +--------+\n|       nic0+             |        |\n|       |    -----------  nic0     |\n|       nic1+             |        |\n+-------+                 +--------+\n\nserver 1                  server2  server 1  nic0 = 10.10.10.4/24\nnic1 = 10.10.8.4/24  server 2  nic0 = 10.148.0.4/24", 
            "title": "Topology:"
        }, 
        {
            "location": "/google-cloud-platform-multiple-nics-with-vpc-peering/#configure", 
            "text": "server 1   Create a new VPC Network with subnet  10.10.8.0/24  . Dont overlap other subnet, in this example we use  10.10.8.0/24 .  Create VPC Network Peering with name  single-iface  (in example). Follow  this tutorial .   configure or add two nic  with first nic0  10.10.10.4/32  subnet/network  dhroot  (in example), with external custom static ip address.  with second nic1  10.10.8.4/32  subnet/network  single-iface  (in example), with none external ip address.       server 1 done.   server 2   Create VPC Network Peering with name  single-iface2-dgp  (in example). Follow  this tutorial .   server 2 done   at the end configuration, it should be looks like these:  from instance 1   from instance 2   we can ping {from,to} server 1 {to,from} server 2 via  nic0 . But cant ping  server 1  with ip address  10.10.8.0/24  from  server 2  because main/default routed to  10.10.10.1  when leave interface. We can use  tcpdump  to troubleshoot this issue.  so we need route nic1 traffic from/to  10.10.8.0/24  via interface  nic1  or  eth1  to  10.10.8.1  with table routing to fix this issue.  assumed ip address nic1/eth1:  10.10.8.4 , so configure  server 1  with these commands:  ifconfig eth1 10.10.8.4 netmask 255.255.255.255 broadcast 10.10.8.4 mtu 1430\necho \"1 rt1\" | tee -a /etc/iproute2/rt_tables\nip route add 10.10.8.1 src 10.10.8.4 dev eth1\nip route add default via 10.10.8.1 dev eth1 table rt1\nip rule add from 10.10.8.4/32 table rt1\nip rule add to 10.10.8.4/32 table rt1  recheck again traffic route to  10.10.8.1 :  root@dct:~# ip route show dev eth1 table rt1\ndefault via 10.10.8.1 \nroot@dct:~#", 
            "title": "Configure:"
        }, 
        {
            "location": "/google-cloud-platform-multiple-nics-with-vpc-peering/#testing", 
            "text": "now, trying ping or other tcp connect from server 2:  [root@serv3 ~]# telnet 10.10.8.4 22\nTrying 10.10.8.4...\nConnected to 10.10.8.4.\nEscape character is '^]'.\nSSH-2.0-OpenSSH_7.4p1 Debian-10+deb9u2  done.", 
            "title": "Testing"
        }, 
        {
            "location": "/kimsufi-dns-ipv6-openvz-promox/", 
            "text": "Build DNS Server IPV6 dengan DBNDNS di Kimsufi menggunakan OpenVZ Proxmox\n\n\nSebelum membangun DNS server IPV6, kita coba persiapkan terlebih dahulu infrastruktur IPV6 di dalam Proxmox. Karena dalam percobaan kali ini menggunakan Proxmox sebagai host, dan OpenVZ sebagai Guest.\n\n\n\n\nOpenVZ dengan IPV4.\n\n\nOpenVZ dengan IPV6\n\n\nInstall DBNDNS di OpenVZ.\n\n\n\n\nOpenVZ dengan IPV4\n\n\ninstall openvz terlebih dahulu dengan \ncreate CT\n via Proxmox. setelah itu setting IPV4 misal dengan \n10.10.11.2\n.\nsetelah openvz ok. setting Host Proxmox agar dapat berkomunikasi dengan Guest OpenVZ. misal kita set ip host proxmox dengan ip \n10.10.11.1\n di interface venet0.\n\n\nifconfig venet0 10.10.11.1 netmask 255.255.255.0\n\n\n\nstart OpenVZ dengan perintah:\n\n\nvzctl start OpenVZ_ID\n\n\n\nGunakan perintah \nvzlist -a\n untuk melihat \nOpenVZ_ID\n\n\nPing dari Host untuk melihat hasilnya:\n\n\nroot@ipv6:~# ping 10.10.11.2\nPING 10.10.11.2 (10.10.11.2) 56(84) bytes of data.\n64 bytes from 10.10.11.2: icmp_req=1 ttl=64 time=0.106 ms\n64 bytes from 10.10.11.2: icmp_req=2 ttl=64 time=0.067 ms\n\n\n\nPing dari Guest OpenVZ untuk test:\n\n\nroot@ipv6:~# vzctl enter 104\nentered into CT 104\nroot@nsX:/# ping 10.10.10.1\nPING 10.10.10.1 (10.10.10.1) 56(84) bytes of data.\n64 bytes from 10.10.10.1: icmp_req=1 ttl=64 time=0.089 ms\n\n\n\nSampai di sini kita sudah membuat jaringan internal dari Host Proxmox ke Guest OpenVZ atau sebaliknya. Agar Guest OpenVZ dapat ping keluar (internet), maka perlu ditambahkan tabel \nNAT IPTABLE\n:\n\n\niptables -t nat -A POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE\n\n\n\nbagian ini adalah optional saja, karena kadangkala ada repository yang belum dapat ngreach dari IPV6, maka kita perlu koneksi IPV4. Jika repostory sudah didukung IPV6. skip saja.\n\n\nOpenVZ dengan IPV6\n\n\nTambahkan di \n/etc/sysctl.conf\n:\n\n\nnet.ipv6.conf.all.forwarding=1\nnet.ipv6.conf.all.proxy_ndp=1\nnet.ipv6.bindv6only=1\n\n\n\nReload:\n\n\nsysctl -p\n\n\n\nUntuk menambahkan IPV6 di dalam Guest OpenVZ dari Host Proxmox tinggal ketik perintah:\n\n\nvzctl set OPENVZ_ID --ipadd 2001:41d0:8:9a2d::d7d7/64 --save\n\n\n\nsecara default kita akan mendapatkan IPV6 dari Kimsufi sebanyak /64.\n\n\nUntuk setting DNS Google IPV6 di Guest OpenVZ dari Host Proxmox tinggal ketik:\n\n\nzctl set OPENVZ_ID --nameserver 2001:4860:4860::8888 --save\n\n\n\nCek Hasilnya, masuk ke kontainer dulu:\n\n\nroot@nsX:/# curl ip.appspot.com;echo   \n2001:41d0:8:9a2d::d7d7\nroot@nsX:/#\n\n\n\nTerlihat sudah menggunakan ipv6.\n\n\nInstall DBNDNS di OpenVZ\n\n\nKenapa pakai DBNDNS ? . Karena berdasarkan informasi dari \nhttp://blog.reimus.ca/how-to-install-tinydns-djbdns-on-linux-debian/\n , versi djbdns di debian ada 2 paket, yaitu djbdns yang versi asli original + 3 minor patches dan \ndbndns\n yaitu fork dari djbdns + ipv6 support patch.\n\n\nSebelum installasi, arahkan dulu repository ke dalam versi sid:\n\n\ndeb http://ftp.debian.org/debian sid main contrib\n\n\n\nInstall \nDBNDNS\n:\n\n\napt-get install dbndns\n\n\n\nKonfigurasi:\n\n\nuseradd Gtinydns;\nuseradd Gdnslog;\ntinydns-conf Gtinydns Gdnslog /etc/tinydns7 2001:41d0:e:dc4::d7d7\n\n\n\nip \n2001:41d0:e:dc4::d7d7\n adalah IPV6 yang kita tambahkan tadi.\n\n\nCreate Symlink agar service dapat jalan:\n\n\nln -s /etc/tinydns7 /etc/service/tinydns7\n\n\n\ncheck service\n\n\nroot@ipv6:~# svstat /etc/service/tinydns7\n/etc/service/tinydns7: up (pid 4421) 70914 seconds\nroot@ipv6:~#\n\n\n\nuntuk menambahkan IPV6 lain tinggal ulangi:\n\n\ndari Host Proxmox\n\n\nvzctl set OPENVZ_ID --ipadd 2001:41d0:8:9a2d::d8d8/64 --save\n\n\n\ndari Guest OpenVZ:\n\n\nuseradd Gtinydns8;\nuseradd Gdnslog8;\ntinydns-conf Gtinydns8 Gdnslog8 /etc/tinydns8 2001:41d0:e:dc4::d8d8\nln -s /etc/tinydns8 /etc/service/tinydns8\n\n\n\nsampai di sini sudah selesai. \ndata.cdb\n dari tinydns bisa ditempatkan di dalam directory \n/etc/tinydnsX/root/\n\n\ncek terakhir:\n\n\nroot@ipv6:~# dig host @IPV6_DNS_SERVE\n\n\n\nTambahan\n\n\nUntuk menambahkan IPV6 di Host Proxmox Kimsufi bisa dengan:\n\n\nip -6 addr add YOUR_IPV6_ADDRESS/64 dev vmbr0\nip -6 addr add 2001:41d0:8:9a2d::2/64 dev vmbr0\n\n\n\nKarena saya memakai promox, default route sudah otomatis didefine. Alamat route default route di Kimsufi :\n\n\nXXXX:XXXX:X:XXFF:FF:FF:FF:FF\n\n\n\nuntuk test, bisa test \nping6\n ke \n2001:41d0:8:9a2d::2\n atau lihat route dengan command \nip -6 route show\n\n\nroot@ipv6:~# ip -6 route show | grep default\ndefault via 2001:41d0:8:9aff:ff:ff:ff:ff dev vmbr0  metric 1024  mtu 1500 advmss 1440 hoplimit 0\nroot@ipv6:~#\n\n\n\nReferensi:\n\n\n\n\nhttps://known.phyks.me/2014/getting-ipv6-to-work-with-a-kimsufi-server\n.\n\n\nhttp://mmaton.com/2014/02/ipv6-only-proxmox-ct/\n\n\nhttp://blog.reimus.ca/how-to-install-tinydns-djbdns-on-linux-debian/", 
            "title": "OVH - Build DNS Server IPV6 dengan DBNDNS di Kimsufi menggunakan OpenVZ Proxmox"
        }, 
        {
            "location": "/kimsufi-dns-ipv6-openvz-promox/#build-dns-server-ipv6-dengan-dbndns-di-kimsufi-menggunakan-openvz-proxmox", 
            "text": "Sebelum membangun DNS server IPV6, kita coba persiapkan terlebih dahulu infrastruktur IPV6 di dalam Proxmox. Karena dalam percobaan kali ini menggunakan Proxmox sebagai host, dan OpenVZ sebagai Guest.   OpenVZ dengan IPV4.  OpenVZ dengan IPV6  Install DBNDNS di OpenVZ.", 
            "title": "Build DNS Server IPV6 dengan DBNDNS di Kimsufi menggunakan OpenVZ Proxmox"
        }, 
        {
            "location": "/kimsufi-dns-ipv6-openvz-promox/#openvz-dengan-ipv4", 
            "text": "install openvz terlebih dahulu dengan  create CT  via Proxmox. setelah itu setting IPV4 misal dengan  10.10.11.2 .\nsetelah openvz ok. setting Host Proxmox agar dapat berkomunikasi dengan Guest OpenVZ. misal kita set ip host proxmox dengan ip  10.10.11.1  di interface venet0.  ifconfig venet0 10.10.11.1 netmask 255.255.255.0  start OpenVZ dengan perintah:  vzctl start OpenVZ_ID  Gunakan perintah  vzlist -a  untuk melihat  OpenVZ_ID  Ping dari Host untuk melihat hasilnya:  root@ipv6:~# ping 10.10.11.2\nPING 10.10.11.2 (10.10.11.2) 56(84) bytes of data.\n64 bytes from 10.10.11.2: icmp_req=1 ttl=64 time=0.106 ms\n64 bytes from 10.10.11.2: icmp_req=2 ttl=64 time=0.067 ms  Ping dari Guest OpenVZ untuk test:  root@ipv6:~# vzctl enter 104\nentered into CT 104\nroot@nsX:/# ping 10.10.10.1\nPING 10.10.10.1 (10.10.10.1) 56(84) bytes of data.\n64 bytes from 10.10.10.1: icmp_req=1 ttl=64 time=0.089 ms  Sampai di sini kita sudah membuat jaringan internal dari Host Proxmox ke Guest OpenVZ atau sebaliknya. Agar Guest OpenVZ dapat ping keluar (internet), maka perlu ditambahkan tabel  NAT IPTABLE :  iptables -t nat -A POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE  bagian ini adalah optional saja, karena kadangkala ada repository yang belum dapat ngreach dari IPV6, maka kita perlu koneksi IPV4. Jika repostory sudah didukung IPV6. skip saja.", 
            "title": "OpenVZ dengan IPV4"
        }, 
        {
            "location": "/kimsufi-dns-ipv6-openvz-promox/#openvz-dengan-ipv6", 
            "text": "Tambahkan di  /etc/sysctl.conf :  net.ipv6.conf.all.forwarding=1\nnet.ipv6.conf.all.proxy_ndp=1\nnet.ipv6.bindv6only=1  Reload:  sysctl -p  Untuk menambahkan IPV6 di dalam Guest OpenVZ dari Host Proxmox tinggal ketik perintah:  vzctl set OPENVZ_ID --ipadd 2001:41d0:8:9a2d::d7d7/64 --save  secara default kita akan mendapatkan IPV6 dari Kimsufi sebanyak /64.  Untuk setting DNS Google IPV6 di Guest OpenVZ dari Host Proxmox tinggal ketik:  zctl set OPENVZ_ID --nameserver 2001:4860:4860::8888 --save  Cek Hasilnya, masuk ke kontainer dulu:  root@nsX:/# curl ip.appspot.com;echo   \n2001:41d0:8:9a2d::d7d7\nroot@nsX:/#  Terlihat sudah menggunakan ipv6.", 
            "title": "OpenVZ dengan IPV6"
        }, 
        {
            "location": "/kimsufi-dns-ipv6-openvz-promox/#install-dbndns-di-openvz", 
            "text": "Kenapa pakai DBNDNS ? . Karena berdasarkan informasi dari  http://blog.reimus.ca/how-to-install-tinydns-djbdns-on-linux-debian/  , versi djbdns di debian ada 2 paket, yaitu djbdns yang versi asli original + 3 minor patches dan  dbndns  yaitu fork dari djbdns + ipv6 support patch.  Sebelum installasi, arahkan dulu repository ke dalam versi sid:  deb http://ftp.debian.org/debian sid main contrib  Install  DBNDNS :  apt-get install dbndns  Konfigurasi:  useradd Gtinydns;\nuseradd Gdnslog;\ntinydns-conf Gtinydns Gdnslog /etc/tinydns7 2001:41d0:e:dc4::d7d7  ip  2001:41d0:e:dc4::d7d7  adalah IPV6 yang kita tambahkan tadi.  Create Symlink agar service dapat jalan:  ln -s /etc/tinydns7 /etc/service/tinydns7  check service  root@ipv6:~# svstat /etc/service/tinydns7\n/etc/service/tinydns7: up (pid 4421) 70914 seconds\nroot@ipv6:~#  untuk menambahkan IPV6 lain tinggal ulangi:  dari Host Proxmox  vzctl set OPENVZ_ID --ipadd 2001:41d0:8:9a2d::d8d8/64 --save  dari Guest OpenVZ:  useradd Gtinydns8;\nuseradd Gdnslog8;\ntinydns-conf Gtinydns8 Gdnslog8 /etc/tinydns8 2001:41d0:e:dc4::d8d8\nln -s /etc/tinydns8 /etc/service/tinydns8  sampai di sini sudah selesai.  data.cdb  dari tinydns bisa ditempatkan di dalam directory  /etc/tinydnsX/root/  cek terakhir:  root@ipv6:~# dig host @IPV6_DNS_SERVE", 
            "title": "Install DBNDNS di OpenVZ"
        }, 
        {
            "location": "/kimsufi-dns-ipv6-openvz-promox/#tambahan", 
            "text": "Untuk menambahkan IPV6 di Host Proxmox Kimsufi bisa dengan:  ip -6 addr add YOUR_IPV6_ADDRESS/64 dev vmbr0\nip -6 addr add 2001:41d0:8:9a2d::2/64 dev vmbr0  Karena saya memakai promox, default route sudah otomatis didefine. Alamat route default route di Kimsufi :  XXXX:XXXX:X:XXFF:FF:FF:FF:FF  untuk test, bisa test  ping6  ke  2001:41d0:8:9a2d::2  atau lihat route dengan command  ip -6 route show  root@ipv6:~# ip -6 route show | grep default\ndefault via 2001:41d0:8:9aff:ff:ff:ff:ff dev vmbr0  metric 1024  mtu 1500 advmss 1440 hoplimit 0\nroot@ipv6:~#  Referensi:   https://known.phyks.me/2014/getting-ipv6-to-work-with-a-kimsufi-server .  http://mmaton.com/2014/02/ipv6-only-proxmox-ct/  http://blog.reimus.ca/how-to-install-tinydns-djbdns-on-linux-debian/", 
            "title": "Tambahan"
        }, 
        {
            "location": "/centos-7-network-configuration-without-network-manager/", 
            "text": "Centos 7 Network configuration without network manager daemon\n\n\nA posting from member at \ncentos forum\n, it said \"network can't connect when Network Manager disable\". This is vey annonying when we need install cpanel but network manager must disable. If we looking \nmanual documentation\n from ovh, we can setup network configuration like this:\n\n\nDEVICE=(insert interface Name)\nBOOTPROTO=none\nONBOOT=yes\nUSERCTL=no\nIPV6INIT=no\nPEERDNS=yes\nTYPE=Ethernet\nNETMASK=255.255.255.255\nIPADDR=FAILOVER_IP\nGATEWAY=GATEWAY_IP\nARP=yes\nHWADDR=MY:VI:RT:UA:LM:AC\n\n\n\nand set for routing like this:\n\n\nGATEWAY_IP - 255.255.255.255 (insert interface Name)\nNETWORK_GW_VM - 255.255.255.0 (insert interface Name)\ndefault GATEWAY_IP\n\n\n\nwe can setup like above, but network manager is still running. we can disable network manager like this:\n\n\nNM_CONTROLLED=no\nUSERCTL=no\n\n\n\nif network manager still running, we can use route centos 6 model like this to disable network manager:\n\n\n123.123.123.123 dev eth0\ndefault via 123.123.123.254 dev eth0\n\n\n\nand for network config:\n\n\nTYPE=Ethernet\nDEVICE=eth0\nONBOOT=yes\nNM_CONTROLLED=no\nUSERCTL=no\nIPV6INIT=no\nPEERDNS=no\nNETMASK=255.255.255.255\nIPADDR=123.123.123.123\nGATEWAY=123.123.123.254\nARP=yes\nHWADDR=02:00:00:aa:bb:cc\n\n\n\nto disable network manager run command:\n\n\nfor a in NetworkManager.service NetworkManager-wait-online.service NetworkManager-dispatcher.service;do systemctl disable $a;done\n\n\n\ndone;", 
            "title": "OVH - Centos 7 Network configuration without network manager daemon"
        }, 
        {
            "location": "/centos-7-network-configuration-without-network-manager/#centos-7-network-configuration-without-network-manager-daemon", 
            "text": "A posting from member at  centos forum , it said \"network can't connect when Network Manager disable\". This is vey annonying when we need install cpanel but network manager must disable. If we looking  manual documentation  from ovh, we can setup network configuration like this:  DEVICE=(insert interface Name)\nBOOTPROTO=none\nONBOOT=yes\nUSERCTL=no\nIPV6INIT=no\nPEERDNS=yes\nTYPE=Ethernet\nNETMASK=255.255.255.255\nIPADDR=FAILOVER_IP\nGATEWAY=GATEWAY_IP\nARP=yes\nHWADDR=MY:VI:RT:UA:LM:AC  and set for routing like this:  GATEWAY_IP - 255.255.255.255 (insert interface Name)\nNETWORK_GW_VM - 255.255.255.0 (insert interface Name)\ndefault GATEWAY_IP  we can setup like above, but network manager is still running. we can disable network manager like this:  NM_CONTROLLED=no\nUSERCTL=no  if network manager still running, we can use route centos 6 model like this to disable network manager:  123.123.123.123 dev eth0\ndefault via 123.123.123.254 dev eth0  and for network config:  TYPE=Ethernet\nDEVICE=eth0\nONBOOT=yes\nNM_CONTROLLED=no\nUSERCTL=no\nIPV6INIT=no\nPEERDNS=no\nNETMASK=255.255.255.255\nIPADDR=123.123.123.123\nGATEWAY=123.123.123.254\nARP=yes\nHWADDR=02:00:00:aa:bb:cc  to disable network manager run command:  for a in NetworkManager.service NetworkManager-wait-online.service NetworkManager-dispatcher.service;do systemctl disable $a;done  done;", 
            "title": "Centos 7 Network configuration without network manager daemon"
        }, 
        {
            "location": "/centos-upgrade-7-to-8/", 
            "text": "How to upgrade Centos 7 to 8\n\n\nInstall Dependencies\n\n\nyum install epel-release yum-utils rpmconf -y\n\n\n\nUninstall duplicate/Unused Packages and Configurations\n\n\n# pmconf -a\n# package-cleanup --leaves\n# package-cleanup --orphans\n\n\n\nUninstall paket yang muncul dari perintah \npackage-cleanup\n dengan perintah \nyum remove nama_paket\n.\n\n\nmengganti package manager dari \nyum\n ke \ndnf\n\n\nyum install dnf\n\n\n\nlalu menghapus paket yum:\n\n\ndnf remove yum yum-metadata-parser\nrm -Rf /etc/yum\n\n\n\nmegupgrade paket dengan dnf\n\n\ndnf upgrade\n\n\n\nUpgrade repository dengan dnf:\n\n\ndnf upgrade http://mirror.biznetgio.com/centos/8/BaseOS/x86_64/os/Packages/{centos-release-8.1-1.1911.0.8.el8.x86_64.rpm,centos-gpg-keys-8.1-1.1911.0.8.el8.noarch.rpm,centos-repos-8.1-1.1911.0.8.el8.x86_64.rpm}\n\n\n\nUpgrade EPEL yum repository from EL 7 to EL 8:\n\n\ndnf upgrade -y epel-release\n\n\n\nbuild cache dnf:\n\n\ndnf makecache\n\n\n\nUpgrade Centos 7 ke Centos 8\n\n\nMenghapus semua kernel yg terinstall dengan perintah:\n\n\nrpm -e `rpm -q kernel`\n\n\n\nMenghapus paket yg konflik:\n\n\nrpm -e --nodeps sysvinit-tools\n\n\n\nmemulai upgrade system dengan perintah:\n\n\ndnf -y --releasever=8 --allowerasing --setopt=deltarpm=false distro-sync\n\n\n\nInstall kernel core baru Centos 8:\n\n\ndnf install -y kernel-core\n\n\n\nInstall Minimal dan Core group paket di server.\n\n\ndnf -y groupupdate \"Core\" \"Minimal Install\"\n\n\n\nReboot lalu cek versi:\n\n\nsystemctl reboot\n\n\n\nbefore:\n\n\n\n\nAfter:", 
            "title": "Centos - Upgrade from 7 to 8"
        }, 
        {
            "location": "/centos-upgrade-7-to-8/#how-to-upgrade-centos-7-to-8", 
            "text": "", 
            "title": "How to upgrade Centos 7 to 8"
        }, 
        {
            "location": "/centos-upgrade-7-to-8/#install-dependencies", 
            "text": "yum install epel-release yum-utils rpmconf -y", 
            "title": "Install Dependencies"
        }, 
        {
            "location": "/centos-upgrade-7-to-8/#uninstall-duplicateunused-packages-and-configurations", 
            "text": "# pmconf -a\n# package-cleanup --leaves\n# package-cleanup --orphans  Uninstall paket yang muncul dari perintah  package-cleanup  dengan perintah  yum remove nama_paket .", 
            "title": "Uninstall duplicate/Unused Packages and Configurations"
        }, 
        {
            "location": "/centos-upgrade-7-to-8/#mengganti-package-manager-dari-yum-ke-dnf", 
            "text": "yum install dnf  lalu menghapus paket yum:  dnf remove yum yum-metadata-parser\nrm -Rf /etc/yum  megupgrade paket dengan dnf  dnf upgrade  Upgrade repository dengan dnf:  dnf upgrade http://mirror.biznetgio.com/centos/8/BaseOS/x86_64/os/Packages/{centos-release-8.1-1.1911.0.8.el8.x86_64.rpm,centos-gpg-keys-8.1-1.1911.0.8.el8.noarch.rpm,centos-repos-8.1-1.1911.0.8.el8.x86_64.rpm}  Upgrade EPEL yum repository from EL 7 to EL 8:  dnf upgrade -y epel-release  build cache dnf:  dnf makecache", 
            "title": "mengganti package manager dari yum ke dnf"
        }, 
        {
            "location": "/centos-upgrade-7-to-8/#upgrade-centos-7-ke-centos-8", 
            "text": "Menghapus semua kernel yg terinstall dengan perintah:  rpm -e `rpm -q kernel`  Menghapus paket yg konflik:  rpm -e --nodeps sysvinit-tools  memulai upgrade system dengan perintah:  dnf -y --releasever=8 --allowerasing --setopt=deltarpm=false distro-sync  Install kernel core baru Centos 8:  dnf install -y kernel-core  Install Minimal dan Core group paket di server.  dnf -y groupupdate \"Core\" \"Minimal Install\"  Reboot lalu cek versi:  systemctl reboot  before:   After:", 
            "title": "Upgrade Centos 7 ke Centos 8"
        }, 
        {
            "location": "/ceph-osds-troubleshooting/", 
            "text": "Ceph OSDS Full Troubleshooting\n\n\nIssue\n\n\nPada percobaan kali ini kita akan mensimulasikan bagaimana ketika OSD Ceph dalam kondisi full dan cara troubleshooting.\n\n\nSimulasi\n\n\nKondisi normal, environment sama dengan production:\n\n\n\n\n10 osd\n\n\n2 host osd, 1 ceph-mon.\n\n\n\n\nEnvironment Production:\n\n\n\n\n\n\nEnvironment Test server:\n\n\n\n\nDilakukan penambahan data/disk secara terus menerus:\n\n\n\n\nLalu kondisi \nceph\n berubah dari status \nhealth_ok\n menjadi \nhealth_err\n:\n\n\n\n\nosd 8 menjadi full:\n\n\n\n\ndetail space osd:\n\n\n\n\nsemua operation tidak bisa berjalan sempurna:\n\n\n\n\nTroubleshoot\n\n\nAda 2 cara untuk menyeimbangkan full cluster ceph:\n\n\n\n\nMenambahkan \nceph-osds\n baru.\n\n\nRedistribute storage.\n\n\n\n\nMenambahkan \nceph-osds\n baru\n\n\nMenambahkan \nOSDs\n baru akan secara otomatis mendistribusikan \npages ceph\n.\n\n\nlihat berikut:\n\n\ndari \n10 osd\n ditambah 2 osd menjadi \n12 osd\n:\n\n\n\n\ndata pages ceph akan secara otomatis \nrebalanced\n\n\nhasil akhir:\n\n\n\n\n\n\nRedistribute storage\n\n\nDistribusikan storage dengan perintah seperti berikut:\n\n\nceph osd reweight-by-utilization\n\n\n\n\nRunning the command will make adjustments to a maximum of 4 OSDs that are at 120% utilization\n\n\nhasil akhir setelah \nredistribute\n:\n\n\n\n\n\n\nRef:\n\n\n\n\nhttp://centosquestions.com/what-do-you-do-when-a-ceph-osd-is-nearfull/\n\n\nhttps://docs.ceph.com/docs/giant/rados/troubleshooting/troubleshooting-osd/\n\n\nhttps://docs.ceph.com/docs/bobtail/rados/operations/add-or-rm-osds/\n\n\nhttps://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/troubleshooting_guide/troubleshooting-osds\n\n\nhttps://access.redhat.com/documentation/en-us/red_hat_ceph_storage/3/html/operations_guide/handling-a-disk-failure", 
            "title": "OpenStack - Ceph OSDS Troubleshooting"
        }, 
        {
            "location": "/ceph-osds-troubleshooting/#ceph-osds-full-troubleshooting", 
            "text": "", 
            "title": "Ceph OSDS Full Troubleshooting"
        }, 
        {
            "location": "/ceph-osds-troubleshooting/#issue", 
            "text": "Pada percobaan kali ini kita akan mensimulasikan bagaimana ketika OSD Ceph dalam kondisi full dan cara troubleshooting.", 
            "title": "Issue"
        }, 
        {
            "location": "/ceph-osds-troubleshooting/#simulasi", 
            "text": "Kondisi normal, environment sama dengan production:   10 osd  2 host osd, 1 ceph-mon.   Environment Production:    Environment Test server:   Dilakukan penambahan data/disk secara terus menerus:   Lalu kondisi  ceph  berubah dari status  health_ok  menjadi  health_err :   osd 8 menjadi full:   detail space osd:   semua operation tidak bisa berjalan sempurna:", 
            "title": "Simulasi"
        }, 
        {
            "location": "/ceph-osds-troubleshooting/#troubleshoot", 
            "text": "Ada 2 cara untuk menyeimbangkan full cluster ceph:   Menambahkan  ceph-osds  baru.  Redistribute storage.", 
            "title": "Troubleshoot"
        }, 
        {
            "location": "/ceph-osds-troubleshooting/#menambahkan-ceph-osds-baru", 
            "text": "Menambahkan  OSDs  baru akan secara otomatis mendistribusikan  pages ceph .  lihat berikut:  dari  10 osd  ditambah 2 osd menjadi  12 osd :   data pages ceph akan secara otomatis  rebalanced  hasil akhir:", 
            "title": "Menambahkan ceph-osds baru"
        }, 
        {
            "location": "/ceph-osds-troubleshooting/#redistribute-storage", 
            "text": "Distribusikan storage dengan perintah seperti berikut:  ceph osd reweight-by-utilization   Running the command will make adjustments to a maximum of 4 OSDs that are at 120% utilization  hasil akhir setelah  redistribute :    Ref:   http://centosquestions.com/what-do-you-do-when-a-ceph-osd-is-nearfull/  https://docs.ceph.com/docs/giant/rados/troubleshooting/troubleshooting-osd/  https://docs.ceph.com/docs/bobtail/rados/operations/add-or-rm-osds/  https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/troubleshooting_guide/troubleshooting-osds  https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/3/html/operations_guide/handling-a-disk-failure", 
            "title": "Redistribute storage"
        }, 
        {
            "location": "/freebsd-11-upgrade-to-12/", 
            "text": "How to upgrade FreeBSD 11 to 12\n\n\nPertama catat versi FreeBSD yang running dengan menjalankan perintah:\n\n\nfreebsd-version\nuname -mrs\n\n\n\ncontoh hasil:\n\n\n11.3-RELEASE-p3\n\n\n\n\n\nUpdate Base OS\n\n\nFetch dan update package base os:\n\n\nfreebsd-update fetch install\n\n\n\ncontoh outputs:\n\n\n11.3-RELEASE-p3:\n/boot/kernel/kernel\n/boot/kernel/mqueuefs.ko\n/boot/kernel/sound.ko\n/boot/kernel/vmm.ko\n/usr/lib/debug/boot/kernel/kernel.debug\n/usr/lib/debug/boot/kernel/mqueuefs.ko.debug\n/usr/lib/debug/boot/kernel/sound.ko.debug\n/usr/lib/debug/boot/kernel/vmm.ko.debug\nInstalling updates...  done.\n\n\n\nSelanjutnya update paket juga, jalankan perintah:\n\n\npkg update \n pkg upgrade\n\n\n\nUpgrade FreeBSD 11.3 ke 12.0 dengan metode paket binary.\n\n\nJalankan dengan perintah:\n\n\nfreebsd-update -r 12.0-RELEASE upgrade\n\n\n\nperintah freebsd-update akan mengevaluasi konfigurasi file dan kita akan review satu persatu serta merge configuration file seperti berikut:\n\n\nDoes this look reasonable (y/n) y\n....\n...\n/bin/rmail\n/bin/rmdir\n/bin/setfacl\n/bin/sh\n/bin/sleep\n/bin/stty\n/bin/sync\n/bin/tcsh\n/bin/test\n/bin/unlink\n/bin/uuidgen\n/boot\nTo install the downloaded upgrades, run \"/usr/sbin/freebsd-update install\".\n\n\n\nSetelah semuanya terdownload paket tersebut akan diinstall ke dalam disk. jalankan perintah:\n\n\nfreebsd-update install\n\n\n\ncontoh outputs:\n\n\nInstalling updates...\nKernel updates have been installed.  Please reboot and run\n\"/usr/sbin/freebsd-update install\" again to finish installing updates.\n\n\n\nuntuk reboot jalankan perintah:\n\n\nreboot\n\n\n\nSetelah up lagi, jalankan ulang perintah \nfreebsd-update\n untuk menghapus semua shared libraries dan object files yg lama:\n\n\nfreebsd-update install\n\n\n\nContoh outputs:\n\n\nInstalling updates...\nCompleting this upgrade requires removing old shared object files.\nPlease rebuild all installed 3rd party software (e.g., programs\ninstalled from the ports tree) and then run \"/usr/sbin/freebsd-update install\"\nagain to finish installing updates.\n\n\n\nsekarang sistem telah diupdate. untuk update semua paket binary jalankan perintah:\n\n\npkg-static install -f pkg\npkg update\npkg upgrade\n\n\n\nContoh outputs:\n\n\nUpdating FreeBSD repository catalogue...\nFreeBSD repository is up to date.\nAll repositories are up to date.\nChecking for upgrades (39 candidates): 100%\nProcessing candidates (39 candidates): 100%\nThe following 42 package(s) will be affected (of 0 checked):\n\nNew packages to be INSTALLED:\n    gdb: 8.2\n    expat: 2.2.6_1\n    libiconv: 1.14_11\n\nInstalled packages to be UPGRADED:\n    ca_root_nss: 3.40.1 -\n 3.41\n\nInstalled packages to be REINSTALLED:\n    sudo-1.8.25p1 (ABI changed: 'freebsd:11:x86:64' -\n 'freebsd:12:x86:64')\n    sqlite3-3.25.1 (ABI changed: 'freebsd:11:x86:64' -\n 'freebsd:12:x86:64')\n    readline-7.0.3_1 (ABI changed: 'freebsd:11:x86:64' -\n 'freebsd:12:x86:64')\n.....\n...\n....\n    binutils-2.30_5,1 (ABI changed: 'freebsd:11:x86:64' -\n 'freebsd:12:x86:64')\n\nNumber of packages to be installed: 3\nNumber of packages to be upgraded: 1\nNumber of packages to be reinstalled: 38\n\nThe process will require 53 MiB more space.\n145 MiB to be downloaded.\n\nProceed with this action? [y/N]: y\n[1/42] Fetching sudo-1.8.25p1.txz: 100%  682 KiB 698.3kB/s    00:01    \n[2/42] Fetching sqlite3-3.25.1.txz: 100%    1 MiB 266.6kB/s    00:05    \n....\n..\n...\n[42/42] Fetching libiconv-1.14_11.txz: 100%  601 KiB 615.9kB/s    00:01    \nChecking integrity... done (0 conflicting)\n[1/42] Reinstalling indexinfo-0.3.1...\n[1/42] Extracting indexinfo-0.3.1: 100%\n[2/42] Reinstalling readline-7.0.3_1...\n[2/42] Extracting readline-7.0.3_1: 100%\n[3/42] Reinstalling libffi-3.2.1_2...\n....\n..\n...\nBy default panic reports will be sent to root with instructions to forward\nthem if they do not contain any sensitive information.  To automatically\nsubmit panic reports directly, add\n    panicmail_autosubmit=\"YES\"\nto your /etc/rc.conf in addition.\nMessage from gcc6-6.4.0_8:\n\nTo ensure binaries built with this toolchain find appropriate versions\nof the necessary run-time libraries, you may want to link using\n\n  -Wl,-rpath=/usr/local/lib/gcc6\n\nFor ports leveraging USE_GCC, USES=compiler, or USES=fortran this happens\ntransparently.\n\n\n\nsatu kali lagi jalankan:\n\n\n/usr/sbin/freebsd-update install\n\n\n\nVerifikasi version:\n\n\nuname -mrs\nfreebsd-version\n\n\n\n\n\nJika ada services lain, maka package services tersebut jika akan terupgrade:", 
            "title": "FreeBSD - Upgrade from 11 to 12"
        }, 
        {
            "location": "/freebsd-11-upgrade-to-12/#how-to-upgrade-freebsd-11-to-12", 
            "text": "Pertama catat versi FreeBSD yang running dengan menjalankan perintah:  freebsd-version\nuname -mrs  contoh hasil:  11.3-RELEASE-p3", 
            "title": "How to upgrade FreeBSD 11 to 12"
        }, 
        {
            "location": "/freebsd-11-upgrade-to-12/#update-base-os", 
            "text": "Fetch dan update package base os:  freebsd-update fetch install  contoh outputs:  11.3-RELEASE-p3:\n/boot/kernel/kernel\n/boot/kernel/mqueuefs.ko\n/boot/kernel/sound.ko\n/boot/kernel/vmm.ko\n/usr/lib/debug/boot/kernel/kernel.debug\n/usr/lib/debug/boot/kernel/mqueuefs.ko.debug\n/usr/lib/debug/boot/kernel/sound.ko.debug\n/usr/lib/debug/boot/kernel/vmm.ko.debug\nInstalling updates...  done.  Selanjutnya update paket juga, jalankan perintah:  pkg update   pkg upgrade", 
            "title": "Update Base OS"
        }, 
        {
            "location": "/freebsd-11-upgrade-to-12/#upgrade-freebsd-113-ke-120-dengan-metode-paket-binary", 
            "text": "Jalankan dengan perintah:  freebsd-update -r 12.0-RELEASE upgrade  perintah freebsd-update akan mengevaluasi konfigurasi file dan kita akan review satu persatu serta merge configuration file seperti berikut:  Does this look reasonable (y/n) y\n....\n...\n/bin/rmail\n/bin/rmdir\n/bin/setfacl\n/bin/sh\n/bin/sleep\n/bin/stty\n/bin/sync\n/bin/tcsh\n/bin/test\n/bin/unlink\n/bin/uuidgen\n/boot\nTo install the downloaded upgrades, run \"/usr/sbin/freebsd-update install\".  Setelah semuanya terdownload paket tersebut akan diinstall ke dalam disk. jalankan perintah:  freebsd-update install  contoh outputs:  Installing updates...\nKernel updates have been installed.  Please reboot and run\n\"/usr/sbin/freebsd-update install\" again to finish installing updates.  untuk reboot jalankan perintah:  reboot  Setelah up lagi, jalankan ulang perintah  freebsd-update  untuk menghapus semua shared libraries dan object files yg lama:  freebsd-update install  Contoh outputs:  Installing updates...\nCompleting this upgrade requires removing old shared object files.\nPlease rebuild all installed 3rd party software (e.g., programs\ninstalled from the ports tree) and then run \"/usr/sbin/freebsd-update install\"\nagain to finish installing updates.  sekarang sistem telah diupdate. untuk update semua paket binary jalankan perintah:  pkg-static install -f pkg\npkg update\npkg upgrade  Contoh outputs:  Updating FreeBSD repository catalogue...\nFreeBSD repository is up to date.\nAll repositories are up to date.\nChecking for upgrades (39 candidates): 100%\nProcessing candidates (39 candidates): 100%\nThe following 42 package(s) will be affected (of 0 checked):\n\nNew packages to be INSTALLED:\n    gdb: 8.2\n    expat: 2.2.6_1\n    libiconv: 1.14_11\n\nInstalled packages to be UPGRADED:\n    ca_root_nss: 3.40.1 -  3.41\n\nInstalled packages to be REINSTALLED:\n    sudo-1.8.25p1 (ABI changed: 'freebsd:11:x86:64' -  'freebsd:12:x86:64')\n    sqlite3-3.25.1 (ABI changed: 'freebsd:11:x86:64' -  'freebsd:12:x86:64')\n    readline-7.0.3_1 (ABI changed: 'freebsd:11:x86:64' -  'freebsd:12:x86:64')\n.....\n...\n....\n    binutils-2.30_5,1 (ABI changed: 'freebsd:11:x86:64' -  'freebsd:12:x86:64')\n\nNumber of packages to be installed: 3\nNumber of packages to be upgraded: 1\nNumber of packages to be reinstalled: 38\n\nThe process will require 53 MiB more space.\n145 MiB to be downloaded.\n\nProceed with this action? [y/N]: y\n[1/42] Fetching sudo-1.8.25p1.txz: 100%  682 KiB 698.3kB/s    00:01    \n[2/42] Fetching sqlite3-3.25.1.txz: 100%    1 MiB 266.6kB/s    00:05    \n....\n..\n...\n[42/42] Fetching libiconv-1.14_11.txz: 100%  601 KiB 615.9kB/s    00:01    \nChecking integrity... done (0 conflicting)\n[1/42] Reinstalling indexinfo-0.3.1...\n[1/42] Extracting indexinfo-0.3.1: 100%\n[2/42] Reinstalling readline-7.0.3_1...\n[2/42] Extracting readline-7.0.3_1: 100%\n[3/42] Reinstalling libffi-3.2.1_2...\n....\n..\n...\nBy default panic reports will be sent to root with instructions to forward\nthem if they do not contain any sensitive information.  To automatically\nsubmit panic reports directly, add\n    panicmail_autosubmit=\"YES\"\nto your /etc/rc.conf in addition.\nMessage from gcc6-6.4.0_8:\n\nTo ensure binaries built with this toolchain find appropriate versions\nof the necessary run-time libraries, you may want to link using\n\n  -Wl,-rpath=/usr/local/lib/gcc6\n\nFor ports leveraging USE_GCC, USES=compiler, or USES=fortran this happens\ntransparently.  satu kali lagi jalankan:  /usr/sbin/freebsd-update install  Verifikasi version:  uname -mrs\nfreebsd-version   Jika ada services lain, maka package services tersebut jika akan terupgrade:", 
            "title": "Upgrade FreeBSD 11.3 ke 12.0 dengan metode paket binary."
        }, 
        {
            "location": "/lets-encrypt-autossl-wildcard-acme.sh/", 
            "text": "Create wildcard Lets Encrypt ssl with acme.sh\n\n\nLet's Encrypt is a free, automated, and open certificate authority brought to you by the non-profit Internet Security Research Group (ISRG).\n\n\nacme.sh is A pure Unix shell script implementing ACME client protocol\n\n\nto create a wildcard ssl from a domain.com simply with command: \n\n\n\"/root/.acme.sh\"/acme.sh --cron --home \"/root/.acme.sh\" --issue -d domain.com  -d '*.domain.com'  --dns --yes-I-know-dns-manual-mode-enough-go-ahead-please --force\n\n\n\nafter run command above, we need setup dns record manually for two txt records:\n\n\n_acme-challenge.domain.com\n\n\n\nand then run again with --renew command option:\n\n\n\"/root/.acme.sh\"/acme.sh --cron --home \"/root/.acme.sh\" --issue -d domain.com  -d '*.domain.com'  --dns --yes-I-know-dns-manual-mode-enough-go-ahead-please --force --renew\n\n\n\nwe can use dns api setup to automatically those txt records.", 
            "title": "Lets Encrypt - Create wildcard ssl with acme.sh"
        }, 
        {
            "location": "/lets-encrypt-autossl-wildcard-acme.sh/#create-wildcard-lets-encrypt-ssl-with-acmesh", 
            "text": "Let's Encrypt is a free, automated, and open certificate authority brought to you by the non-profit Internet Security Research Group (ISRG).  acme.sh is A pure Unix shell script implementing ACME client protocol  to create a wildcard ssl from a domain.com simply with command:   \"/root/.acme.sh\"/acme.sh --cron --home \"/root/.acme.sh\" --issue -d domain.com  -d '*.domain.com'  --dns --yes-I-know-dns-manual-mode-enough-go-ahead-please --force  after run command above, we need setup dns record manually for two txt records:  _acme-challenge.domain.com  and then run again with --renew command option:  \"/root/.acme.sh\"/acme.sh --cron --home \"/root/.acme.sh\" --issue -d domain.com  -d '*.domain.com'  --dns --yes-I-know-dns-manual-mode-enough-go-ahead-please --force --renew  we can use dns api setup to automatically those txt records.", 
            "title": "Create wildcard Lets Encrypt ssl with acme.sh"
        }, 
        {
            "location": "/openstack-upgrade-from-rocky-to-stein/", 
            "text": "OpenStack - Upgrade from Rocky to Stein Release\n\n\nScenario yang akan digunakan dalam upgrade ini adalah semua service akan terkena interruptions. Dalam upgrade kali ini menggunakan environment test, dan setelah berhasil akan di implementasikan di environment Productions.  Semua OpenStack services akan down pada saat bersamaan, dan tidak akan up lagi sampai proses upgrade telah selesai.\n\n\nKondisi environment:\n\n\n\n\nOpenStack terinstall secara ALL in ONE via PackStack\n\n\nOpenStack terinstall secara terpisah antara controller dan compute.\n\n\n\n\n1. OpenStack terinstall secara ALL in ONE via PackStack\n\n\nUpdate Package\n\n\nSebelum mengupgrade, ambil snapshot systemd dari service OpenStack:\n\n\n# systemctl snapshot openstack-services\n\n\n\nStop OpenStack Services:\n\n\n# systemctl stop 'openstack-*'\n# systemctl stop 'neutron-*'\n# systemctl stop 'openvswitch'\n\n\n\nInstall openstack release repo untuk Stein Release:\n\n\n# yum install -y centos-release-openstack-stein\n\n\n\nJika ada conflict, remove terlebih dahulu packet yang conflict dan pastikan tidak mengganggu system. Setelah itu bisa jalankan kembali installasi paket openstack release repo untuk \nStein\n\n\n# yum remove centos-release-ceph-luminous-1.1-2.el7.centos.noarch\n\n\n\nNon aktifkan openstack release untuk rocky:\n\n\n# yum-config-manager --disable centos-release-openstack-rocky\n\n\n\nLalu bisa lakukan upgrade release dari \nRocky\n ke \nStein\n\n\n# yum update\n\n\n\nSampai dengan langkah ini, proses Upgrade sudah selesai, dan langkah terakhir adalah\n\n\nUpdate Database\n\n\nlakukan di node \ncontroller\n\n\nUpdate keystone db:\n\n\n[root@rocky ~]# su -s /bin/sh -c \"keystone-manage db_sync\" keystone\n\n\n\nUpdate glance db:\n\n\n[root@rocky ~]# su -s /bin/sh -c \"glance-manage db_sync\" glance\n/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:1371: OsloDBDeprecationWarning: EngineFacade is deprecated; please use oslo_db.sqlalchemy.enginefacad\ne\n  expire_on_commit=expire_on_commit, _conf=conf)\nDatabase is up to date. No migrations needed.\n\n\n\nUpdate cinder db:\n\n\n[root@rocky ~]# su -s /bin/sh -c \"cinder-manage db sync\" cinder\nDeprecated: Option \"logdir\" from group \"DEFAULT\" is deprecated. Use option \"log-dir\" from group \"DEFAULT\".\n\n\n\nceilometer update db:\n\n\n[root@rocky ~]# ceilometer-upgrade\n\n\n\nupdate aodh db:\n\n\n[root@rocky ~]# aodh-dbsync\n\n\n\nupdate gnocchi db:\n\n\n[root@rocky ~]# gnocchi-upgrade\n2019-06-27 13:36:49,952 [19407] INFO     gnocchi.service: Gnocchi version 4.3.2\n2019-06-27 13:36:50,231 [19407] INFO     gnocchi.cli.manage: Upgrading indexer SQLAlchemyIndexer: mysql+pymysql://gnocchi:fb620dedd7de442b@10.10.2.204/gnocchi?charset=utf8\n2019-06-27 13:36:50,579 [19407] INFO     gnocchi.cli.manage: Upgrading storage FileStorage: /var/lib/gnocchi\n2019-06-27 13:36:50,581 [19407] INFO     gnocchi.cli.manage: Upgrading incoming storage FileStorage: /var/lib/gnocchi\n[root@rocky ~]# su -s /bin/sh -c \"neutron-db-manage upgrade heads\" neutron\nINFO  [alembic.runtime.migration] Context impl MySQLImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n  Running upgrade for neutron ...\nINFO  [alembic.runtime.migration] Context impl MySQLImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade 867d39095bf4 -\n d72db3e25539, modify uniq port forwarding\nINFO  [alembic.runtime.migration] Running upgrade d72db3e25539 -\n cada2437bf41\nINFO  [alembic.runtime.migration] Running upgrade cada2437bf41 -\n 195176fb410d, router gateway IP QoS\nINFO  [alembic.runtime.migration] Running upgrade 195176fb410d -\n fb0167bd9639\nINFO  [alembic.runtime.migration] Running upgrade fb0167bd9639 -\n 0ff9e3881597\nINFO  [alembic.runtime.migration] Running upgrade 0ff9e3881597 -\n 9bfad3f1e780\n  OK\n\n\n\nUpdate Nova Compute DB:\n\n\n[root@rocky ~]# su -s /bin/sh -c \"nova-manage db sync\" nova\n[root@rocky ~]# su -s /bin/sh -c \"nova-manage api_db sync\" nova\n\n\n\ncheck / discover host Nova:\n\n\n[root@rocky ~]# su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\nFound 2 cell mappings.\nSkipping cell0 since it does not contain hosts.\nGetting computes from cell 'default': 8af6b639-390c-43d6-94cb-dfba685b6036\nFound 0 unmapped computes in cell: 8af6b639-390c-43d6-94cb-dfba685b6036\n\n\n\ncheck list cells nova:\n\n\n[root@rocky ~]# nova-manage cell_v2 list_cells\n+---------+--------------------------------------+---------------------------------------+--------------------------------------------------+----------+\n|   Name  |                 UUID                 |             Transport URL             |               Database Connection                | Disabled |\n+---------+--------------------------------------+---------------------------------------+--------------------------------------------------+----------+\n|  cell0  | 00000000-0000-0000-0000-000000000000 |                 none:/                | mysql+pymysql://nova:****@10.10.2.204/nova_cell0 |  False   |\n| default | 8af6b639-390c-43d6-94cb-dfba685b6036 | rabbit://guest:****@10.10.2.204:5672/ |    mysql+pymysql://nova:****@10.10.2.204/nova    |  False   |\n+---------+--------------------------------------+---------------------------------------+--------------------------------------------------+----------+\n\n\n\nLalu restart all OpenStack services:\n\n\n# systemctl isolate openstack-services.snapshot\n# systemctl start 'openstack-*';systemctl start 'neutron-*';systemctl start 'openvswitch'\n\n\n\nReboot Host jika ada kendala di Horizon Openstack\n\n\n# reboot\n\n\n\n2. OpenStack terinstall secara terpisah antara controller dan compute.\n\n\nCara upgrade sama dengan nomor 1, lalu edit file \n/etc/neutron/neutron.conf\n\n\n#service_plugins=qos,trunk,neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2,router,metering,firewall\nservice_plugins=lbaasv2,router,metering,qos,trunk\n\n\n\nrubah seperti diatas pada service_plugins.\n\n\nRestart all service openstack atau reboot mesin cara paling mudah.\n\n\nSummary Code\n\n\n#!/bin/bash\n\nsystemctl snapshot openstack-services\nsystemctl stop 'openstack-*'\nsystemctl stop 'neutron-*'\n#systemctl stop 'openvswitch'\n\nyum remove  -y centos-release-ceph-luminous-1.1-2.el7.centos.noarch\nyum install -y centos-release-openstack-stein\n\nyum-config-manager --disable centos-release-openstack-rocky -y\n\nyum update -y\n\nsu -s /bin/sh -c \"keystone-manage db_sync\" keystone\nsu -s /bin/sh -c \"glance-manage db_sync\" glance\nsu -s /bin/sh -c \"cinder-manage db sync\" cinder\nceilometer-upgrade\naodh-dbsync\ngnocchi-upgrade\nsu -s /bin/sh -c \"neutron-db-manage upgrade heads\" neutron\nsu -s /bin/sh -c \"nova-manage db sync\" nova\nsu -s /bin/sh -c \"nova-manage api_db sync\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\nsystemctl isolate openstack-services.snapshot\nsystemctl start 'openstack-*';\nsystemctl start 'neutron-*';\n\n\n\n\n\nReferensi:\n\nhttps://www.rdoproject.org/install/upgrading-rdo-1/\n\nhttps://wiki.openstack.org/wiki/Neutron/LBaaS/Deprecation", 
            "title": "OpenStack - Upgrade from Rocky to Stein Release"
        }, 
        {
            "location": "/openstack-upgrade-from-rocky-to-stein/#openstack-upgrade-from-rocky-to-stein-release", 
            "text": "Scenario yang akan digunakan dalam upgrade ini adalah semua service akan terkena interruptions. Dalam upgrade kali ini menggunakan environment test, dan setelah berhasil akan di implementasikan di environment Productions.  Semua OpenStack services akan down pada saat bersamaan, dan tidak akan up lagi sampai proses upgrade telah selesai.  Kondisi environment:   OpenStack terinstall secara ALL in ONE via PackStack  OpenStack terinstall secara terpisah antara controller dan compute.", 
            "title": "OpenStack - Upgrade from Rocky to Stein Release"
        }, 
        {
            "location": "/openstack-upgrade-from-rocky-to-stein/#1-openstack-terinstall-secara-all-in-one-via-packstack", 
            "text": "", 
            "title": "1. OpenStack terinstall secara ALL in ONE via PackStack"
        }, 
        {
            "location": "/openstack-upgrade-from-rocky-to-stein/#update-package", 
            "text": "Sebelum mengupgrade, ambil snapshot systemd dari service OpenStack:  # systemctl snapshot openstack-services  Stop OpenStack Services:  # systemctl stop 'openstack-*'\n# systemctl stop 'neutron-*'\n# systemctl stop 'openvswitch'  Install openstack release repo untuk Stein Release:  # yum install -y centos-release-openstack-stein  Jika ada conflict, remove terlebih dahulu packet yang conflict dan pastikan tidak mengganggu system. Setelah itu bisa jalankan kembali installasi paket openstack release repo untuk  Stein  # yum remove centos-release-ceph-luminous-1.1-2.el7.centos.noarch  Non aktifkan openstack release untuk rocky:  # yum-config-manager --disable centos-release-openstack-rocky  Lalu bisa lakukan upgrade release dari  Rocky  ke  Stein  # yum update  Sampai dengan langkah ini, proses Upgrade sudah selesai, dan langkah terakhir adalah", 
            "title": "Update Package"
        }, 
        {
            "location": "/openstack-upgrade-from-rocky-to-stein/#update-database", 
            "text": "lakukan di node  controller  Update keystone db:  [root@rocky ~]# su -s /bin/sh -c \"keystone-manage db_sync\" keystone  Update glance db:  [root@rocky ~]# su -s /bin/sh -c \"glance-manage db_sync\" glance\n/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:1371: OsloDBDeprecationWarning: EngineFacade is deprecated; please use oslo_db.sqlalchemy.enginefacad\ne\n  expire_on_commit=expire_on_commit, _conf=conf)\nDatabase is up to date. No migrations needed.  Update cinder db:  [root@rocky ~]# su -s /bin/sh -c \"cinder-manage db sync\" cinder\nDeprecated: Option \"logdir\" from group \"DEFAULT\" is deprecated. Use option \"log-dir\" from group \"DEFAULT\".  ceilometer update db:  [root@rocky ~]# ceilometer-upgrade  update aodh db:  [root@rocky ~]# aodh-dbsync  update gnocchi db:  [root@rocky ~]# gnocchi-upgrade\n2019-06-27 13:36:49,952 [19407] INFO     gnocchi.service: Gnocchi version 4.3.2\n2019-06-27 13:36:50,231 [19407] INFO     gnocchi.cli.manage: Upgrading indexer SQLAlchemyIndexer: mysql+pymysql://gnocchi:fb620dedd7de442b@10.10.2.204/gnocchi?charset=utf8\n2019-06-27 13:36:50,579 [19407] INFO     gnocchi.cli.manage: Upgrading storage FileStorage: /var/lib/gnocchi\n2019-06-27 13:36:50,581 [19407] INFO     gnocchi.cli.manage: Upgrading incoming storage FileStorage: /var/lib/gnocchi\n[root@rocky ~]# su -s /bin/sh -c \"neutron-db-manage upgrade heads\" neutron\nINFO  [alembic.runtime.migration] Context impl MySQLImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n  Running upgrade for neutron ...\nINFO  [alembic.runtime.migration] Context impl MySQLImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade 867d39095bf4 -  d72db3e25539, modify uniq port forwarding\nINFO  [alembic.runtime.migration] Running upgrade d72db3e25539 -  cada2437bf41\nINFO  [alembic.runtime.migration] Running upgrade cada2437bf41 -  195176fb410d, router gateway IP QoS\nINFO  [alembic.runtime.migration] Running upgrade 195176fb410d -  fb0167bd9639\nINFO  [alembic.runtime.migration] Running upgrade fb0167bd9639 -  0ff9e3881597\nINFO  [alembic.runtime.migration] Running upgrade 0ff9e3881597 -  9bfad3f1e780\n  OK  Update Nova Compute DB:  [root@rocky ~]# su -s /bin/sh -c \"nova-manage db sync\" nova\n[root@rocky ~]# su -s /bin/sh -c \"nova-manage api_db sync\" nova  check / discover host Nova:  [root@rocky ~]# su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\nFound 2 cell mappings.\nSkipping cell0 since it does not contain hosts.\nGetting computes from cell 'default': 8af6b639-390c-43d6-94cb-dfba685b6036\nFound 0 unmapped computes in cell: 8af6b639-390c-43d6-94cb-dfba685b6036  check list cells nova:  [root@rocky ~]# nova-manage cell_v2 list_cells\n+---------+--------------------------------------+---------------------------------------+--------------------------------------------------+----------+\n|   Name  |                 UUID                 |             Transport URL             |               Database Connection                | Disabled |\n+---------+--------------------------------------+---------------------------------------+--------------------------------------------------+----------+\n|  cell0  | 00000000-0000-0000-0000-000000000000 |                 none:/                | mysql+pymysql://nova:****@10.10.2.204/nova_cell0 |  False   |\n| default | 8af6b639-390c-43d6-94cb-dfba685b6036 | rabbit://guest:****@10.10.2.204:5672/ |    mysql+pymysql://nova:****@10.10.2.204/nova    |  False   |\n+---------+--------------------------------------+---------------------------------------+--------------------------------------------------+----------+  Lalu restart all OpenStack services:  # systemctl isolate openstack-services.snapshot\n# systemctl start 'openstack-*';systemctl start 'neutron-*';systemctl start 'openvswitch'  Reboot Host jika ada kendala di Horizon Openstack  # reboot", 
            "title": "Update Database"
        }, 
        {
            "location": "/openstack-upgrade-from-rocky-to-stein/#2-openstack-terinstall-secara-terpisah-antara-controller-dan-compute", 
            "text": "Cara upgrade sama dengan nomor 1, lalu edit file  /etc/neutron/neutron.conf  #service_plugins=qos,trunk,neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2,router,metering,firewall\nservice_plugins=lbaasv2,router,metering,qos,trunk  rubah seperti diatas pada service_plugins.  Restart all service openstack atau reboot mesin cara paling mudah.", 
            "title": "2. OpenStack terinstall secara terpisah antara controller dan compute."
        }, 
        {
            "location": "/openstack-upgrade-from-rocky-to-stein/#summary-code", 
            "text": "#!/bin/bash\n\nsystemctl snapshot openstack-services\nsystemctl stop 'openstack-*'\nsystemctl stop 'neutron-*'\n#systemctl stop 'openvswitch'\n\nyum remove  -y centos-release-ceph-luminous-1.1-2.el7.centos.noarch\nyum install -y centos-release-openstack-stein\n\nyum-config-manager --disable centos-release-openstack-rocky -y\n\nyum update -y\n\nsu -s /bin/sh -c \"keystone-manage db_sync\" keystone\nsu -s /bin/sh -c \"glance-manage db_sync\" glance\nsu -s /bin/sh -c \"cinder-manage db sync\" cinder\nceilometer-upgrade\naodh-dbsync\ngnocchi-upgrade\nsu -s /bin/sh -c \"neutron-db-manage upgrade heads\" neutron\nsu -s /bin/sh -c \"nova-manage db sync\" nova\nsu -s /bin/sh -c \"nova-manage api_db sync\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\nsystemctl isolate openstack-services.snapshot\nsystemctl start 'openstack-*';\nsystemctl start 'neutron-*';   Referensi: https://www.rdoproject.org/install/upgrading-rdo-1/ \nhttps://wiki.openstack.org/wiki/Neutron/LBaaS/Deprecation", 
            "title": "Summary Code"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/", 
            "text": "Pengantar\n\n\nSetelah \nsebelumnya\n kita melakukan installasi OpenStack dengan PackStack. Dalam skenario kali ini kita akan menggantikan disk space yang digunakan oleh, block storage dan image stock dengan Ceph.\n\n\nCeph (diucapkan /\u02c8s\u025bf/ atau /\u02c8k\u025bf/ ) adalah perangkat lunak sumber terbuka penyimpanan terdistribusi yang berbasis penyimpanan objek pada suatu kluster komputer. Ceph menyediakan antarmuka penyimpanan dengan level objek, blok- dan berkas. Tujuan utama Ceph adalah menyediakan penyimpanan terdistribusi tanpa satu titik kegagalan, dapat ditingkatkan hingga skala exabyte, dan tersedia secara bebas. \nhttps://id.wikipedia.org/wiki/Ceph_(perangkat_lunak)\n\n\nPastikan OpenStack sudah berjalan dengan lancar, tidak ada kendala baik didalam networkingnya maupun instances, dan lain-lain.\n\n\nTopology\n\n\n                                                          +--------------------------+\n                                                          |                          |\n                                                          |                          |\n                                                          |   - Compute (Nova)       |\n                                +-----------------------\n |                          +------------+\n                                |                         |                          |            |\n+---------------------------+   |                         |                          |            |\n|                           |   |                         |                          |            |\n| - Controller              |   |                         +--------------------------+            |\n| | Compute (Nova)          | +-^                                                                 |\n| | Images Storage (glance) | |                                                                   |\n| - Block Storage (cinder)  | |                           +---------------------------+           |\n|                           | +-------------------------\n |                           | \n---------+\n|                           | |                           |  ceph mon atau ceph1      |           |\n+---------------------------+ |                           |                           |           |\n                              |                           +---------------------------+           |\n                              |                           +---------------------------+           |\n                              |                           |                           |           |\n                              +-------------------------\n |  osd0                     | \n---------+\n                              |                           |                           |           |\n                              |                           +---------------------------+           |\n                              |                           +---------------------------+           |\n                              |                           |                           |           |\n                              +-------------------------\n |  osd1                     | \n---------+\n                                                          |                           |\n                                                          +---------------------------+\n\n\n10.10.2.205 ceph-mon ceph1\n10.10.2.206 osd0\n10.10.2.207 osd1\n10.10.2.205 mds0\n10.10.2.204 controller compute0 labopenstack.local\n10.10.2.202 compute1 compute compute.localdomain\n\n\n\nDisk \nceph-mon\n:\n\n\n[ceph-mon][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[ceph-mon][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[ceph-mon][INFO  ] Disk /dev/sdc: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[ceph-mon][INFO  ] Disk /dev/sdd: 68.7 GB, 68719476736 bytes, 134217728 sectors\n\n\n\nDisk \nosd0\n:\n\n\n[osd0][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[osd0][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[osd0][INFO  ] Disk /dev/sdc: 68.7 GB, 68719476736 bytes, 134217728 sectors\n\n\n\nDisk \nosd1\n:\n\n\n[osd1][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[osd1][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors\n\n\n\nRequierements\n\n\n\n\nsiapkan \nkopi lampung\n dulu :D , langkah lumayan panjang soalnya :D\n\n\nopenstack yg sudah running well.\n\n\nuntuk kebutuhan ini, kita butuh ceph server paling tidak 1 atau 2 server dengan minimal ram 8GB.\n\n\nmatikan terlebih dahulu firewall dan network manager:\n\n\n\n\njalankan dengan perintah:\n\n\n    sudo systemctl disable firewalld\n    sudo systemctl stop firewalld\n    sudo systemctl disable NetworkManager\n    sudo systemctl stop NetworkManager\n    sudo systemctl enable network\n    sudo systemctl start network\n\n\n\nInstallasi CEPH Cluster\n\n\n\n\n\n\ninstall ceph repo dan update, lakukan di mesin \nceph-mon\n\n\nyum install epel-release\nyum install wget -y\nyum -y install vim screen crudini\nyum install epel-release yum-plugin-priorities https://download.ceph.com/rpm-mimic/el7/noarch/ceph-release-1-1.el7.noarch.rpm\nyum install https://download.ceph.com/rpm-mimic/el7/noarch/ceph-deploy-2.0.1-0.noarch.rpm\nyum repolist\nyum -y update\n\n\n\n\n\n\n\ninstall ntp, lakukan di mesin \nceph-mon\n\n\nyum -y install chrony\nsystemctl enable chronyd.service\nsystemctl restart chronyd.service\nsystemctl status chronyd.service\n\n\n\n\n\n\n\ncreate sudoer untuk user stack. user ini digunakan untuk manajemen ceph. lakukan di mesin \nceph-mon\n, \nosd0\n, \nosd1\n\n\ncat \n EOF \n/etc/sudoers.d/stack\nstack ALL = (root) NOPASSWD:ALL\nDefaults:stack !requiretty\nEOF\n\nuseradd -d /home/stack -m stack\npasswd stack\nchmod 0440 /etc/sudoers.d/stack\nsetenforce 0\ngetenforce\nsed -i 's/SELINUX\\=enforcing/SELINUX\\=permissive/g' /etc/selinux/config\ncat /etc/selinux/config\n\n\n\n\n\n\n\nsetup auto ssh \n\n\n\n\n\n\nsetup auto ssh berjalan dari mesin \nceph-mon\n ke \nosd0\n ataupun \nosd1\n dan mesin \nceph-mon\n sendiri.\n\n\nlakukan di mesin \nceph-mon\n\n\n[stack@ceph1 ~]$ cat .ssh/config \nHost ceph1\n   Hostname ceph1\n   User stack\nHost osd0\n   Hostname osd0\n   User stack\nHost ceph-osd1\n   Hostname osd1\n   User stack\n[stack@ceph1 ~]$\n\n\n\ncopy public key:\n\n\nssh-copy-id -i ~/.ssh/id_rsa.pub 10.10.2.205\nssh-copy-id -i ~/.ssh/id_rsa.pub 10.10.2.206\nssh-copy-id -i ~/.ssh/id_rsa.pub 10.10.2.207\n\n\n\n\n\nDeploy Ceph\n\n\n\n\nlakukan di mesin \nceph-mon\n sebagai user \nstack\n\n\nmkdir os-ceph\ncd os-ceph/\nceph-deploy new ceph-mon\n\n\n\nnote\n: pada saat percobaan ini menggunakan host \nceph1\n daripada host \nceph-mon\n. Jika ada penulisan dengan host \nceph-mon\n itu artinya mesin \nceph1\n. Intinya kedua host tersebut mengarah ke mesin yang sama.\n\n\nSet jumlah replica 2 (sehingga data yang tersimpan pada cluster ceph akan di replica sebanyak 2)\n\n\necho \"osd pool default size = 2\" \n ceph.conf\necho \"osd pool default min size = 1\" \n ceph.conf\necho \"osd crush chooseleaf type = 1\" \n ceph.conf\necho \"osd journal size  = 100\" \n ceph.conf\n\n\n\nInstall ceph mengunakan ceph-deploy:\n\n\nceph-deploy install ceph-mon\nceph-deploy install osd0 osd1\n\n\n\nMembuat initial monitor:\n\n\nceph-deploy mon create-initial\nceph-deploy mon create\n\n\n\nMelihat disk list di mesin \nosd0\n\n\n[stack@ceph1 osceph2]$ ceph-deploy disk list osd0\n[ceph_deploy.conf][DEBUG ] found configuration file at: /home/stack/.cephdeploy.conf\n[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /bin/ceph-deploy disk list osd0\n[ceph_deploy.cli][INFO  ] ceph-deploy options:\n[ceph_deploy.cli][INFO  ]  username                      : None\n[ceph_deploy.cli][INFO  ]  verbose                       : False\n[ceph_deploy.cli][INFO  ]  debug                         : False\n[ceph_deploy.cli][INFO  ]  overwrite_conf                : False\n[ceph_deploy.cli][INFO  ]  subcommand                    : list\n[ceph_deploy.cli][INFO  ]  quiet                         : False\n[ceph_deploy.cli][INFO  ]  cd_conf                       : \nceph_deploy.conf.cephdeploy.Conf instance at 0x7f610f1773f8\n\n[ceph_deploy.cli][INFO  ]  cluster                       : ceph\n[ceph_deploy.cli][INFO  ]  host                          : ['osd0']\n[ceph_deploy.cli][INFO  ]  func                          : \nfunction disk at 0x7f610f3c9938\n\n[ceph_deploy.cli][INFO  ]  ceph_conf                     : None\n[ceph_deploy.cli][INFO  ]  default_release               : False\n[osd0][DEBUG ] connection detected need for sudo\n[osd0][DEBUG ] connected to host: osd0 \n[osd0][DEBUG ] detect platform information from remote host\n[osd0][DEBUG ] detect machine type\n[osd0][DEBUG ] find the location of an executable\n[osd0][INFO  ] Running command: sudo fdisk -l\n[osd0][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[osd0][INFO  ] Disk /dev/mapper/centos-root: 31.1 GB, 31130124288 bytes, 60801024 sectors\n[osd0][INFO  ] Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors\n[osd0][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[osd0][INFO  ] Disk /dev/sdc: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[osd0][INFO  ] Disk /dev/mapper/ceph--455f828c--2454--4f1d--b6f3--887fa8b48e58-osd--block--b1f537f7--8b40--490e--b872--98b84f5f0118: 68.7 GB, 68715282432 bytes, 134209536 sectors\n[osd0][INFO  ] Disk /dev/mapper/ceph--e389bab8--4765--4fd3--868e--26bfb019dc7b-osd--block--087e2243--02c1--4573--afc8--e642fff2afb4: 68.7 GB, 68715282432 bytes, 134209536 sectors\n\n\n\nFormat multiple disk ceph lewat \nceph-deploy\n:\n\n\njalankan \nceph-deploy disk zap osd1 /dev/sdc /dev/sdd\n\n\n[stack@ceph1 ~]$ ceph-deploy disk zap osd1 /dev/sdc /dev/sdd\n[ceph_deploy.conf][DEBUG ] found configuration file at: /home/stack/.cephdeploy.conf\n[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /bin/ceph-deploy disk zap osd1 /dev/sdc /dev/sdd\n[ceph_deploy.cli][INFO  ] ceph-deploy options:\n[ceph_deploy.cli][INFO  ]  username                      : None\n[ceph_deploy.cli][INFO  ]  verbose                       : False\n[ceph_deploy.cli][INFO  ]  debug                         : False\n[ceph_deploy.cli][INFO  ]  overwrite_conf                : False\n[ceph_deploy.cli][INFO  ]  subcommand                    : zap\n[ceph_deploy.cli][INFO  ]  quiet                         : False\n[ceph_deploy.cli][INFO  ]  cd_conf                       : \nceph_deploy.conf.cephdeploy.Conf instance at 0x7f3d5e9323f8\n\n[ceph_deploy.cli][INFO  ]  cluster                       : ceph\n[ceph_deploy.cli][INFO  ]  host                          : osd1\n[ceph_deploy.cli][INFO  ]  func                          : \nfunction disk at 0x7f3d5eb84938\n\n[ceph_deploy.cli][INFO  ]  ceph_conf                     : None\n[ceph_deploy.cli][INFO  ]  default_release               : False\n[ceph_deploy.cli][INFO  ]  disk                          : ['/dev/sdc', '/dev/sdd']\n[ceph_deploy.osd][DEBUG ] zapping /dev/sdc on osd1\n[osd1][DEBUG ] connection detected need for sudo\n[osd1][DEBUG ] connected to host: osd1 \n[osd1][DEBUG ] detect platform information from remote host\n[osd1][DEBUG ] detect machine type\n[osd1][DEBUG ] find the location of an executable\n[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.6.1810 Core\n[osd1][DEBUG ] zeroing last few blocks of device\n[osd1][DEBUG ] find the location of an executable\n[osd1][INFO  ] Running command: sudo /usr/sbin/ceph-volume lvm zap /dev/sdc\n[osd1][DEBUG ] --\n Zapping: /dev/sdc\n[osd1][DEBUG ] --\n --destroy was not specified, but zapping a whole device will remove the partition table\n[osd1][DEBUG ] Running command: /usr/sbin/wipefs --all /dev/sdc\n[osd1][DEBUG ] Running command: /bin/dd if=/dev/zero of=/dev/sdc bs=1M count=10\n[osd1][DEBUG ]  stderr: 10+0 records in\n[osd1][DEBUG ] 10+0 records out\n[osd1][DEBUG ] 10485760 bytes (10 MB) copied\n[osd1][DEBUG ]  stderr: , 0.010268 s, 1.0 GB/s\n[osd1][DEBUG ] --\n Zapping successful for: \nRaw Device: /dev/sdc\n\n[ceph_deploy.osd][DEBUG ] zapping /dev/sdd on osd1\n[osd1][DEBUG ] connection detected need for sudo\n[osd1][DEBUG ] connected to host: osd1\n[osd1][DEBUG ] detect platform information from remote host\n[osd1][DEBUG ] detect machine type\n[osd1][DEBUG ] find the location of an executable\n[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.6.1810 Core\n[osd1][DEBUG ] zeroing last few blocks of device\n[osd1][DEBUG ] find the location of an executable\n[osd1][INFO  ] Running command: sudo /usr/sbin/ceph-volume lvm zap /dev/sdd\n[osd1][DEBUG ] --\n Zapping: /dev/sdd\n[osd1][DEBUG ] --\n --destroy was not specified, but zapping a whole device will remove the partition table\n[osd1][DEBUG ] Running command: /usr/sbin/wipefs --all /dev/sdd\n[osd1][DEBUG ] Running command: /bin/dd if=/dev/zero of=/dev/sdd bs=1M count=10\n[osd1][DEBUG ]  stderr: 10+0 records in\n[osd1][DEBUG ] 10+0 records out\n[osd1][DEBUG ] 10485760 bytes (10 MB) copied\n[osd1][DEBUG ]  stderr: , 0.00494895 s, 2.1 GB/s\n[osd1][DEBUG ] --\n Zapping successful for: \nRaw Device: /dev/sdd\n\n\n\n\nlakukan hal sama pada host \nceph-mon\n dan \nosd0\n sesuai dengan disk yang dimiliki.\n\n\nMembuat OSD dengan \nceph-deploy\n:\n\n\nfor a in /dev/sdc /dev/sdd;do ceph-deploy osd create --data $a osd1`;done\n\n\n\nlakukan hal sama pada host \nceph-mon\n dan \nosd0\n sesuai dengan disk yang dimiliki.\n\n\nCopy konfigurasi dan key ke semua node:\n\n\nceph-deploy admin ceph1 osd0 osd1\nsudo chmod +r /etc/ceph/ceph.client.admin.keyring\n\n\n\ncek ceph status:\n\n\n[stack@ceph1 osceph2]$ ceph -s\n  cluster:\n    id:     10925d88-4e51-4311-88aa-52c81ab14eb6\n    health: HEALTH_WARN\n            no active mgr\n\n  services:\n    mon: 1 daemons, quorum ceph1\n    mgr: no daemons active\n    osd: 6 osds: 6 up, 6 in\n\n  data:\n    pools:   0 pools, 0 pgs   \n    objects: 0  objects, 0 B  \n    usage:   0 B used, 0 B / 0 B avail\n    pgs:\n\n\n\nno active mgr\n, untuk mengaktifkannya:\n\n\n[stack@ceph1 osceph2]$ ceph-deploy mgr create ceph1\n[ceph_deploy.conf][DEBUG ] found configuration file at: /home/stack/.cephdeploy.conf\n[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /bin/ceph-deploy mgr create ceph1\n[ceph_deploy.cli][INFO  ] ceph-deploy options:\n.....\n[ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph1\n[ceph1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf\n[ceph1][WARNIN] mgr keyring does not exist yet, creating one\n[ceph1][DEBUG ] create a keyring file\n[ceph1][DEBUG ] create path recursively if it doesn't exist\n[ceph1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.ceph1 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-ceph1/keyring\n[ceph1][INFO  ] Running command: sudo systemctl enable ceph-mgr@ceph1\n[ceph1][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@ceph1.service to /usr/lib/systemd/system/ceph-mgr@.service.\n[ceph1][INFO  ] Running command: sudo systemctl start ceph-mgr@ceph1\n[ceph1][INFO  ] Running command: sudo systemctl enable ceph.target\n\n\n\nlalu cek dengan command:\n\n\nsudo systemctl status ceph-mgr@ceph1\n\n\n\nTest create pool:\n\n\nceph osd pool create volumes 128\nceph osd pool create images 128\nceph osd pool create backups 128\nceph osd pool create vms 128\nrbd pool init volumes\nrbd pool init images\nrbd pool init backups\nrbd pool init vms\n\n\n\nCek status:\n\n\n[stack@ceph1 osceph2]$ ceph -s\n  cluster:\n    id:     10925d88-4e51-4311-88aa-52c81ab14eb6\n    health: HEALTH_OK\n\n  services:\n    mon: 1 daemons, quorum ceph1\n    mgr: ceph1(active)\n    osd: 6 osds: 6 up, 6 in\n\n  data:\n    pools:   0 pools, 0 pgs\n    objects: 0  objects, 0 B\n    usage:   6.0 GiB used, 378 GiB / 384 GiB avail\n    pgs:\n\n\n\nIntegrasi Ceph Cluster dengan OpenStack Rocky\n\n\nInstall requierements\n\n\nmasuk ke dalam user root di mesin ceph1\n\n\nssh controller sudo yum -y install python-rbd ceph-common\nssh compute1 sudo yum -y install python-rbd ceph-common\ncat /etc/ceph/ceph.conf | ssh controller sudo tee /etc/ceph/ceph.conf\ncat /etc/ceph/ceph.conf | ssh compute1 sudo tee /etc/ceph/ceph.conf\n\n\n\nmasuk ke dalam user \nstack\n\n\nsetup client authentication untuk service cinder:\n\n\n[stack@ceph1 osceph2]$ ceph auth get-or-create client.cinder mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=vms, allow rx pool=images'\n[client.cinder]\n        key = AQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==\n[stack@ceph1 osceph2]$\n\n\n\nsetup client authentication untuk service glance:\n\n\n[stack@ceph1 osceph2]$ ceph auth get-or-create client.glance mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=images'\n[client.glance]\n        key = AQDDtCJd4aiPLhAALdSwrLdxizoZWZKs2nnBGg==\n[stack@ceph1 osceph2]$\n\n\n\nMenambahkan key untuk client.cinder dan client.glance ke masing-masing nodes dan mengganti ownershipnya:\n\n\nglance@controller\n:\n\n\n[stack@ceph1 osceph2]$ ceph auth get-or-create client.glance | ssh root@controller sudo tee /etc/ceph/ceph.client.glance.keyring\n[client.glance]\n        key = AQDDtCJd4aiPLhAALdSwrLdxizoZWZKs2nnBGg==\n[stack@ceph1 osceph2]$ \n[stack@ceph1 osceph2]$ ssh root@controller sudo chown glance:glance /etc/ceph/ceph.client.glance.keyring\n[stack@ceph1 osceph2]$\n\n\n\ncinder@controller\n:\n\n\n[stack@ceph1 osceph2]$ ceph auth get-or-create client.cinder | ssh root@controller sudo tee /etc/ceph/ceph.client.cinder.keyring\n[client.cinder]\n        key = AQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==\n[stack@ceph1 osceph2]$ ssh root@controller sudo chown cinder:cinder /etc/ceph/ceph.client.cinder.keyring\n[stack@ceph1 osceph2]$\n\n\n\nglance@compute\n:\n\n\n[stack@ceph1 osceph2]$ ceph auth get-or-create client.glance | ssh root@compute1 sudo tee /etc/ceph/ceph.client.glance.keyring\n[client.glance]\n        key = AQDDtCJd4aiPLhAALdSwrLdxizoZWZKs2nnBGg==\n[stack@ceph1 osceph2]$\n\n\n\ncinder@compute\n:\n\n\n[stack@ceph1 osceph2]$ ceph auth get-or-create client.cinder | ssh root@compute1 sudo tee /etc/ceph/ceph.client.cinder.keyring\n[client.cinder]\n        key = AQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==\n[stack@ceph1 osceph2]$\n\n\n\ncopy cinder key:\n\n\n[stack@ceph1 osceph2]$ ceph auth get-key client.cinder | ssh root@controller tee client.cinder.key\nAQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==[stack@ceph1 osceph2]$ \n[stack@ceph1 osceph2]$\n\n[stack@ceph1 osceph2]$ ceph auth get-key client.cinder | ssh root@compute1 tee client.cinder.key\nAQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==[stack@ceph1 osceph2]$ \n[stack@ceph1 osceph2]$\n\n\n\nGenerate a UUID for the secret, and save the UUID of the secret for configuring nova-compute later\n\n\n[root@compute ~]# uuidgen \n uuid-secret.txt\n[root@compute ~]# cat uuid-secret.txt \neba93c91-5641-4890-aad7-42606c3c3e66\n\n\n\nThen, on the compute nodes, add the secret key to libvirt:\n\n\ncat \n secret.xml \nEOF\n\nsecret ephemeral='no' private='no'\n\n  \nuuid\n`cat uuid-secret.txt`\n/uuid\n\n  \nusage type='ceph'\n\n    \nname\nclient.cinder secret\n/name\n\n  \n/usage\n\n\n/secret\n\nEOF\n\n\n\ngo:\n\n\n[root@compute ~]# cat \n secret.xml \nEOF\n\n \nsecret ephemeral='no' private='no'\n\n\n   \nuuid\n`cat uuid-secret.txt`\n/uuid\n\n\n   \nusage type='ceph'\n\n\n     \nname\nclient.cinder secret\n/name\n\n\n   \n/usage\n\n\n \n/secret\n\n\n EOF\n\n\n\n[root@compute ~]# virsh secret-define --file secret.xml\nSecret eba93c91-5641-4890-aad7-42606c3c3e66 created\n[root@compute ~]# virsh secret-set-value --secret $(cat uuid-secret.txt) --base64 $(cat client.cinder.key)\nSecret value set\n[root@compute ~]#\n\n\n\nJika compute node ada di controller, maka perlu dilakukan juga.\n\n\nSetup Cinder\n\n\nCinder digunakan untuk menyimpan disk dari vm yg ada di openstack.\n\n\nmasuk ke mesin controller, edit file \n/etc/cinder/cinder.conf\n lalu tambahkan ke section \n[DEFAULT]\n  dan aktifkan \nCeph\n sebagai backend dari cinder.\n\n\nenabled_backends = ceph\nglance_api_version = 2\n\n\n\ntambahkan section \nceph\n:\n\n\n[ceph]\nrbd_flatten_volume_from_snapshot = false\nrbd_max_clone_depth = 5\nrbd_store_chunk_size = 4\nrados_connect_timeout = -1\nvolume_driver = cinder.volume.drivers.rbd.RBDDriver\nrbd_ceph_conf = /etc/ceph/ceph.conf\nrbd_pool = volumes\nrbd_user = cinder\nglance_api_version = 2\nrbd_secret_uuid = eba93c91-5641-4890-aad7-42606c3c3e66\nvolume_backend_name = ceph\nrbd_cluster_name = ceph\n\n\n\nrbd_secret_uuid sesuaikan dengan hasil \nuuidgen\n.\n\n\nhasil akhir \ncinder.conf\n: \n\n\n[DEFAULT]\nbackup_swift_url=http://10.10.2.204:8080/v1/AUTH_\nbackup_swift_container=volumebackups\nbackup_driver=cinder.backup.drivers.swift\nenable_v3_api=True\nstorage_availability_zone=nova\ndefault_availability_zone=nova\n#default_volume_type=iscsi\n\ndefault_volume_type=ceph\nauth_strategy=keystone\nenabled_backends=ceph\nglance_api_version = 2\nosapi_volume_listen=0.0.0.0\nosapi_volume_workers=4\ndebug=False\nlog_dir=/var/log/cinder\ntransport_url=rabbit://guest:guest@10.10.2.204:5672/\ncontrol_exchange=openstack\napi_paste_config=/etc/cinder/api-paste.ini\nglance_host=10.10.2.204\n\n[backend]\n\n[backend_defaults]\n\n[barbican]\n\n[brcd_fabric_example]\n\n[cisco_fabric_example]\n\n[coordination]\n\n[cors]\n\n[database]\n\nconnection=mysql+pymysql://cinder:1c36661a5efa4c2b@10.10.2.204/cinder\n\n[fc-zone-manager]\n\n[healthcheck]\n\n[key_manager]\n\nbackend=cinder.keymgr.conf_key_mgr.ConfKeyManager\n\n[keystone_authtoken]\n\nwww_authenticate_uri=http://10.10.2.204:5000/\n\nauth_uri=http://10.10.2.204:5000/\n\nauth_type=password\n\nauth_url=http://10.10.2.204:35357\nusername=cinder\npassword=e3f3c81d1b41459b\nuser_domain_name=Default\nproject_name=services\nproject_domain_name=Default\n\n[matchmaker_redis]\n\n[nova]\n\n[oslo_concurrency]\n\nlock_path=/var/lib/cinder/tmp\n\n[oslo_messaging_amqp]\n\n[oslo_messaging_kafka]\n\n[oslo_messaging_notifications]\n\ndriver=messagingv2\n\n[oslo_messaging_rabbit]\n\nssl=False\n\n[oslo_messaging_zmq]\n\n[oslo_middleware]\n\n[oslo_policy]\n\npolicy_file=/etc/cinder/policy.json\n\n[oslo_reports]\n\n[oslo_versionedobjects]\n\n[profiler]\n\n[sample_remote_file_source]\n\n[service_user]\n\n[ssl]\n\n[vault]\n#[lvm]\n#volume_backend_name=lvm\n#volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver\n#iscsi_ip_address=10.10.2.204\n#iscsi_helper=lioadm\n#volume_group=cinder-volumes\n#volumes_dir=/var/lib/cinder/volumes\n\n[ceph]\n##volume_driver = cinder.volume.drivers.rbd.RBDDriver\n##rbd_pool = volumes\n##rbd_user = cinder\n##rbd_ceph_conf = /etc/ceph/ceph.conf\nrbd_flatten_volume_from_snapshot = false\nrbd_max_clone_depth = 5\nrbd_store_chunk_size = 4\nrados_connect_timeout = -1\nvolume_driver = cinder.volume.drivers.rbd.RBDDriver\nrbd_ceph_conf = /etc/ceph/ceph.conf\nrbd_pool = volumes\nrbd_user = cinder\nglance_api_version = 2\nrbd_secret_uuid = eba93c91-5641-4890-aad7-42606c3c3e66\nvolume_backend_name = ceph\nrbd_cluster_name = ceph\n\n#volume_driver = cinder.volume.drivers.rbd.RBDDriver\n#rbd_pool = volumes\n#rbd_ceph_conf = /etc/ceph/ceph.conf\n#rbd_flatten_volume_from_snapshot = false\n#rbd_max_clone_depth = 5\n#rbd_store_chunk_size = 4\n#rados_connect_timeout = -1\n#rbd_user = cinder\n#rbd_secret_uuid = ca405f73-e2c9-40aa-ab67-34cf47f7caf9\n\n\n\nRestart Service Cinder\n\n\nrestart dengan perintah:\n\n\n[root@controller ~(keystone_admin)]# service openstack-cinder-api restart\nRedirecting to /bin/systemctl restart openstack-cinder-api.service\n[root@controller ~(keystone_admin)]# service openstack-cinder-scheduler restart\nRedirecting to /bin/systemctl restart openstack-cinder-scheduler.service\n[root@controller ~(keystone_admin)]# service openstack-cinder-volume restart\nRedirecting to /bin/systemctl restart openstack-cinder-volume.service\n[root@controller ~(keystone_admin)]#\n\n\n\nlalu test dengan perintah \nrbd --id cinder ls volumes\n\n\n[root@controller ~(keystone_admin)]#  rbd --id cinder ls volumes\n2019-07-18 10:49:20.216 7f8210d64b00 -1 asok(0x55b893fd64f0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/guests/ceph-client.cinder.28025.94251245209344.asok': (2) No such file or directory\nvolume-23d36d36-5969-49e2-a542-9f6350359b38\nvolume-8ec1920f-b3fe-4ce8-9a45-456645ac480c\nvolume-8f7c693b-a32f-4c7e-9cf8-cc6b490687f8\nvolume-9ffa5128-31d6-4ae9-a668-949ac49b5255\nvolume-a711ee9e-418a-4b39-a661-d7a5990270d5\nvolume-b3e0396b-b346-42c7-9ff3-1058e839f870\nvolume-dd948a95-6d6a-4624-a000-1949e4a915a4\nvolume-f9a9bb00-6f5a-4f57-ae16-3a6368d9ec5c\n[root@controller ~(keystone_admin)]#\n\n\n\nTest Create volume:\n\n\n[root@controller ~(keystone_admin)]# cinder create --volume-type ceph --display-name testCephVolTut 5\n+--------------------------------+--------------------------------------+\n| Property                       | Value                                |\n+--------------------------------+--------------------------------------+\n| attachments                    | []                                   |\n| availability_zone              | nova                                 |\n| bootable                       | false                                |\n| consistencygroup_id            | None                                 |\n| created_at                     | 2019-07-18T03:51:11.000000           |\n| description                    | None                                 |\n| encrypted                      | False                                |\n| id                             | 4897b2b4-c9eb-4c40-b3e8-f0fb75fed592 |\n| metadata                       | {}                                   |\n| migration_status               | None                                 |\n| multiattach                    | False                                |\n| name                           | testCephVolTut                       |\n| os-vol-host-attr:host          | None                                 |\n| os-vol-mig-status-attr:migstat | None                                 |\n| os-vol-mig-status-attr:name_id | None                                 |\n| os-vol-tenant-attr:tenant_id   | b0a4a8851d114a3f9bf4265c9e4c5a9c     |\n| replication_status             | None                                 |\n| size                           | 5                                    |\n| snapshot_id                    | None                                 |\n| source_volid                   | None                                 |\n| status                         | creating                             |\n| updated_at                     | None                                 |\n| user_id                        | dfba230d76a8486287912da65d815769     |\n| volume_type                    | ceph                                 |\n+--------------------------------+--------------------------------------+\n[root@controller ~(keystone_admin)]#\n\n\n\nlihat list volume:\n\n\n[root@controller ~(keystone_admin)]# cinder list\n+--------------------------------------+-----------+----------------+------+-------------+----------+--------------------------------------+\n| ID                                   | Status    | Name           | Size | Volume Type | Bootable | Attached to                          |\n+--------------------------------------+-----------+----------------+------+-------------+----------+--------------------------------------+\n| 23d36d36-5969-49e2-a542-9f6350359b38 | available | testCephVold   | 5    | ceph        | false    |                                      |\n| 4897b2b4-c9eb-4c40-b3e8-f0fb75fed592 | available | testCephVolTut | 5    | ceph        | false    |                                      |\n| 88a95ab2-7f9b-4367-bee0-211926ab2bcc | error     | testaja        | 2    | ceph        | false    |                                      |\n| 8ec1920f-b3fe-4ce8-9a45-456645ac480c | in-use    |                | 40   | ceph        | true     | 45644d8c-4cf3-4faf-95c7-02a8bc9095c2 |\n| 8f7c693b-a32f-4c7e-9cf8-cc6b490687f8 | available | test           | 1    | ceph        | false    |                                      |\n| 9ffa5128-31d6-4ae9-a668-949ac49b5255 | available | testCephVasdol | 5    | ceph        | false    |                                      |\n| a711ee9e-418a-4b39-a661-d7a5990270d5 | available | testCephVol    | 5    | ceph        | false    |                                      |\n| b3e0396b-b346-42c7-9ff3-1058e839f870 | available | cephvol        | 2    | ceph        | false    |                                      |\n| dd948a95-6d6a-4624-a000-1949e4a915a4 | in-use    |                | 10   | ceph        | true     | bac4ed05-4c5d-458f-b6ec-6276d54b52e5 |\n| f9a9bb00-6f5a-4f57-ae16-3a6368d9ec5c | in-use    | freebsd        | 40   | ceph        | true     | 0736390f-3f9e-4ebb-a08e-05d9b0611703 |\n+--------------------------------------+-----------+----------------+------+-------------+----------+--------------------------------------+\n[root@controller ~(keystone_admin)]# openstack volume list\n+--------------------------------------+----------------+-----------+------+---------------------------------+\n| ID                                   | Name           | Status    | Size | Attached to                     |\n+--------------------------------------+----------------+-----------+------+---------------------------------+\n| 4897b2b4-c9eb-4c40-b3e8-f0fb75fed592 | testCephVolTut | available |    5 |                                 |\n| 8ec1920f-b3fe-4ce8-9a45-456645ac480c |                | in-use    |   40 | Attached to centos on /dev/vda  |\n| dd948a95-6d6a-4624-a000-1949e4a915a4 |                | in-use    |   10 | Attached to cirros on /dev/vda  |\n| f9a9bb00-6f5a-4f57-ae16-3a6368d9ec5c | freebsd        | in-use    |   40 | Attached to fbsd on /dev/vda    |\n| 23d36d36-5969-49e2-a542-9f6350359b38 | testCephVold   | available |    5 |                                 |\n| 9ffa5128-31d6-4ae9-a668-949ac49b5255 | testCephVasdol | available |    5 |                                 |\n| 88a95ab2-7f9b-4367-bee0-211926ab2bcc | testaja        | error     |    2 |                                 |\n| a711ee9e-418a-4b39-a661-d7a5990270d5 | testCephVol    | available |    5 |                                 |\n| b3e0396b-b346-42c7-9ff3-1058e839f870 | cephvol        | available |    2 |                                 |\n| 8f7c693b-a32f-4c7e-9cf8-cc6b490687f8 | test           | available |    1 |                                 |\n+--------------------------------------+----------------+-----------+------+---------------------------------+\n[root@controller ~(keystone_admin)]#\n\n\n\nlihat \nservice-list\n status dari \ncinder\n:\n\n\n[root@controller ~(keystone_admin)]# cinder service-list\n+------------------+-----------------+------+----------+-------+----------------------------+-----------------+\n| Binary           | Host            | Zone | Status   | State | Updated_at                 | Disabled Reason |\n+------------------+-----------------+------+----------+-------+----------------------------+-----------------+\n| cinder-backup    | controller      | nova | enabled  | down  | 2019-07-12T07:02:01.000000 | -               |\n| cinder-scheduler | controller      | nova | enabled  | up    | 2019-07-18T03:54:33.000000 | -               |\n| cinder-volume    | controller@ceph | nova | enabled  | up    | 2019-07-18T03:54:36.000000 | -               |\n| cinder-volume    | controller@lvm  | nova | disabled | down  | 2019-07-08T07:11:04.000000 | migratekeCeph   |\n+------------------+-----------------+------+----------+-------+----------------------------+-----------------+\n\n\n\njika ingin menonaktifkan \nservice-list\n:\n\n\nopenstack volume service set --disable --disable-reason migratekeCeph controller@lvm cinder-volume\n\n\n\nmelihat type storage dari cinder:\n\n\n[root@controller ~(keystone_admin)]# cinder type-list\n\n+--------------------------------------+-------+-------------+-----------+\n| ID                                   | Name  | Description | Is_Public |\n+--------------------------------------+-------+-------------+-----------+\n| 16e4f895-3f64-4a3d-b9be-6accd740a3fc | ceph  | -           | True      |\n| 513f6ef6-58af-4db6-97c3-76911c812d55 | iscsi | -           | True      |\n+--------------------------------------+-------+-------------+-----------+\n[root@controller ~(keystone_admin)]# cinder extra-specs-list\n+--------------------------------------+-------+---------------------------------+\n| ID                                   | Name  | extra_specs                     |\n+--------------------------------------+-------+---------------------------------+\n| 16e4f895-3f64-4a3d-b9be-6accd740a3fc | ceph  | {'volume_backend_name': 'ceph'} |\n| 513f6ef6-58af-4db6-97c3-76911c812d55 | iscsi | {'volume_backend_name': 'lvm'}  |\n+--------------------------------------+-------+---------------------------------+\n\n\n\nset ceph sebagai default backend:\n\n\nopenstack-config --set /etc/cinder/cinder.conf DEFAULT enabled_backends ceph\n\n\n\nSetup Glance\n\n\nGlance digunakan untuk menyimpan iso ataupun images yang akan digunakan vm di OpenStack.\n\n\nedit file \n/etc/glance/glance-api.conf\n dan tambahkan:\n\n\nstores=rbd,file,http,swift\ndefault_store=rbd\n##file\nrbd_store_chunk_size = 8\nrbd_store_pool = images\nrbd_store_user = glance\nrbd_store_ceph_conf = /etc/ceph/ceph.conf\n\n\n\nhasil akhir \nglance-api.conf\n: \n\n\n[DEFAULT]\nbind_host=0.0.0.0\nbind_port=9292\nworkers=4\nimage_cache_dir=/var/lib/glance/image-cache\nregistry_host=0.0.0.0\ndebug=False\nlog_file=/var/log/glance/api.log\nlog_dir=/var/log/glance\ntransport_url=rabbit://guest:guest@10.10.2.204:5672/\nenable_v1_api=False\n\n[cors]\n[database]\nconnection=mysql+pymysql://glance:4d819a8b65594569@10.10.2.204/glance\n\n[glance_store]\n\nstores=rbd,file,http,swift\n\ndefault_store=rbd\n##file\n\nrbd_store_chunk_size = 8\nrbd_store_pool = images\nrbd_store_user = glance\nrbd_store_ceph_conf = /etc/ceph/ceph.conf\n\nfilesystem_store_datadir=/var/lib/glance/images/\n\nos_region_name=RegionOne\n\n[image_format]\n\n[keystone_authtoken]\n\nwww_authenticate_uri=http://10.10.2.204:5000/v3\n\nauth_uri=http://10.10.2.204:5000/v3\n\nauth_type=password\n\nauth_url=http://10.10.2.204:35357\nusername=glance\npassword=21de7a56246541aa\nuser_domain_name=Default\nproject_name=services\nproject_domain_name=Default\n\n[matchmaker_redis]\n\n[oslo_concurrency]\n\n[oslo_messaging_amqp]\n\n[oslo_messaging_kafka]\n[oslo_messaging_notifications]\n\ndriver=messagingv2\n\ntopics=notifications\n\n[oslo_messaging_rabbit]\n\nssl=False\n\ndefault_notification_exchange=glance\n\n[oslo_messaging_zmq]\n\n[oslo_middleware]\n\n[oslo_policy]\n\npolicy_file=/etc/glance/policy.json\n\n[paste_deploy]\n\nflavor=keystone\n\n[profiler]\n\n[store_type_location_strategy]\n\n[task]\n\n[taskflow_executor]\n\n\n\nrestart service glance\n\n\nservice openstack-glance-api restart\nservice gpenstack-glance-registry restart\n\n\n\ncheck images lewat rbd\n\n\n[root@controller ~(keystone_admin)]# rbd --id glance ls images\n2019-07-18 13:29:24.350 7f4ebe2f1b00 -1 asok(0x55d34ebfb4f0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/guests/ceph-client.glance.24598.94366047655680.asok': (2) No such file or directory\n5759f626-32c2-45c7-b2e4-6972f606ae68\n9991376d-b436-437a-b76a-e9e68bb6e8e4\nca03be4c-d5ce-4a1a-b0a0-d769edd6b703\n[root@controller ~(keystone_admin)]#\n\n\n\ncheck image list:\n\n\n[root@controller ~(keystone_admin)]# glance image-list\n+--------------------------------------+---------------------+\n| ID                                   | Name                |\n+--------------------------------------+---------------------+\n| 5759f626-32c2-45c7-b2e4-6972f606ae68 | CentOS-7-x86_64     |\n| 9991376d-b436-437a-b76a-e9e68bb6e8e4 | Cirros              |\n| ca03be4c-d5ce-4a1a-b0a0-d769edd6b703 | FreeBSD-11.2-stable |\n+--------------------------------------+---------------------+\n\n\n\nJika masih kosong, bisa diisi sendiri:\n\n\nwget -c https://download.freebsd.org/ftp/snapshots/VM-IMAGES/11.2-STABLE/amd64/Latest/FreeBSD-11.2-STABLE-amd64.qcow2.xz\ntar -xvf FreeBSD-11.2-STABLE-amd64.qcow2.xz\nopenstack image create --container-format bare --disk-format qcow2 --file FreeBSD-11.2-STABLE-amd64.qcow2 --public FreeBSD-11.2-stable\n\n\n\nlalu check lagi:\n\n\n[root@controller ~(keystone_admin)]# openstack image list\n+--------------------------------------+---------------------+--------+\n| ID                                   | Name                | Status |\n+--------------------------------------+---------------------+--------+\n| 5759f626-32c2-45c7-b2e4-6972f606ae68 | CentOS-7-x86_64     | active |\n| 9991376d-b436-437a-b76a-e9e68bb6e8e4 | Cirros              | active |\n| ca03be4c-d5ce-4a1a-b0a0-d769edd6b703 | FreeBSD-11.2-stable | active |\n+--------------------------------------+---------------------+--------+\n[root@controller ~(keystone_admin)]#\n\n\n\ncoba test dengan \ncentos image\n;\n\n\nwget -c \"http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2.xz\"\nunxz CentOS-7-x86_64-GenericCloud.qcow2.xz\n\n\n\ncreate image lagi:\n\n\n[root@controller ~(keystone_admin)]#  openstack image create --container-format bare --disk-format qcow2 --file CentOS-7-x86_64-GenericCloud.qcow2 --public CentOS-7-Test\n\n\n\nlalu check:\n\n\n[root@controller ~(keystone_admin)]# openstack image list\n+--------------------------------------+---------------------+--------+\n| ID                                   | Name                | Status |\n+--------------------------------------+---------------------+--------+\n| 0d9d18de-df05-46b0-96fc-10c9e1e8cc8a | CentOS-7-Test       | active |\n| 5759f626-32c2-45c7-b2e4-6972f606ae68 | CentOS-7-x86_64     | active |\n| 9991376d-b436-437a-b76a-e9e68bb6e8e4 | Cirros              | active |\n| ca03be4c-d5ce-4a1a-b0a0-d769edd6b703 | FreeBSD-11.2-stable | active |\n+--------------------------------------+---------------------+--------+\n[root@controller ~(keystone_admin)]#\n\n\n\nok done.\n\n\nNova compute\n\n\nDisetiap node \nnova-compute\n edit file \n/etc/ceph/ceph.conf\n dan tambahkan:\n\n\n[client]\nrbd cache = true\nrbd cache writethrough until flush = true\nrbd concurrent management ops = 20\nadmin socket = /var/run/ceph/guests/$cluster-$type.$id.$pid.$cctid.asok\nlog file = /var/log/ceph/qemu-guest-$pid.log\n\n\n\nhasil akhir \nceph.conf\n: \n\n\n[global]\nfsid = ac9b148c-e413-48ae-8adc-93a5cca6e88a\nmon_initial_members = ceph1\nmon_host = 10.10.2.205\nauth_cluster_required = cephx\nauth_service_required = cephx\nauth_client_required = cephx\n\nosd pool default size = 2\nosd pool default min size = 1\nosd crush chooseleaf type = 1\nosd journal size  = 100\n\n[client]\nrbd cache = true\nrbd cache writethrough until flush = true\nrbd concurrent management ops = 20\nadmin socket = /var/run/ceph/guests/$cluster-$type.$id.$pid.$cctid.asok\nlog file = /var/log/ceph/qemu-guest-$pid.log\n\n\n\nrestart nova services\n\n\nsystemctl restart openstack-nova-compute\n\n\n\ncheck \nhypervisor\n list:\n\n\n[root@controller ~(keystone_admin)]# nova hypervisor-list\n\n+--------------------------------------+---------------------+-------+---------+\n| ID                                   | Hypervisor hostname | State | Status  |\n+--------------------------------------+---------------------+-------+---------+\n| 62391ec9-6b71-4b00-be98-1d89bee17129 | controller          | up    | enabled |\n| a3a253c0-10fe-464a-a77c-f85de9ff3720 | compute1            | up    | enabled |\n+--------------------------------------+---------------------+-------+---------+\n\n\n\nvia \nopenstack\n cli\n\n\n[root@controller ~(keystone_admin)]# openstack compute service list\n+----+------------------+------------+----------+---------+-------+----------------------------+\n| ID | Binary           | Host       | Zone     | Status  | State | Updated At                 |\n+----+------------------+------------+----------+---------+-------+----------------------------+\n|  3 | nova-conductor   | controller | internal | enabled | up    | 2019-07-18T06:55:09.000000 |\n|  5 | nova-scheduler   | controller | internal | enabled | up    | 2019-07-18T06:55:08.000000 |\n|  7 | nova-consoleauth | controller | internal | enabled | up    | 2019-07-18T06:55:15.000000 |\n|  9 | nova-compute     | controller | nova     | enabled | up    | 2019-07-18T06:55:09.000000 |\n| 13 | nova-compute     | compute1   | nova     | enabled | up    | 2019-07-18T06:55:17.000000 |\n+----+------------------+------------+----------+---------+-------+----------------------------+\n\n\n\nvia \nnova\n cli:\n\n\n[root@controller ~(keystone_admin)]# nova service-list\n+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+\n| Id                                   | Binary           | Host       | Zone     | Status  | State | Updated_at                 | Disabled Reason | Forced down |\n+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+\n| b77d04ea-302d-4470-a171-9ccf04c6535b | nova-conductor   | controller | internal | enabled | up    | 2019-07-18T06:57:29.000000 | -               | False       |\n| 45a49f72-bce0-4800-b97e-2ec4f6b8ee54 | nova-scheduler   | controller | internal | enabled | up    | 2019-07-18T06:57:38.000000 | -               | False       |\n| bbe646df-3028-4e5a-a8bd-577cc6860b44 | nova-consoleauth | controller | internal | enabled | up    | 2019-07-18T06:57:35.000000 | -               | False       |\n| 77660dbd-a5ad-47c5-b93f-38e1bcf5045b | nova-compute     | controller | nova     | enabled | up    | 2019-07-18T06:57:29.000000 | -               | False       |\n| 98c1c43d-c78c-4445-b36f-91c8ffe4fde5 | nova-compute     | compute1   | nova     | enabled | up    | 2019-07-18T06:57:37.000000 | -               | False       |\n+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+\n[root@controller ~(keystone_admin)]#\n\n\n\ncara hapus service via \nnova\n\n\nnova service-delete 0d770b47-d95d-4ba5-a366-5e5baa29aebd\n\n\n\ncara \nmenonaktifkan\n dan \nmengaktifkan\n:\n\n\nnova service-disable 0d770b47-d95d-4ba5-a366-5e5baa29aebd\nnova service-enable 0d770b47-d95d-4ba5-a366-5e5baa29aebd\n\n\n\ncara hapus service lewat \nopenstack\n cli:\n\n\nopenstack compute service delete 12\n\n\n\nNote\n: Jika terjadi perbedaan antara compute node record di host openstack di horizon dengan versi cli, solusinya:\n\n\n`delete service-list yang bersangkutan, hingga tersisa yg masih running well saja`\n\n\n\nlalu discover lagi:\n\n\nnova-manage discover_hosts\n\n\n\nlihat list services:    \n\n\nopenstack hypervisor list;nova hypervisor-list;nova service-list;openstack compute service list;\n\n\n\n\n\ndone.\n\n\nHasil OpenStack yang sudah terkoneksi dengan Ceph Cluster\n\n\n\n\n\n\n\n\n\n\nReferensi:\n\n\n\n\nhttps://gist.github.com/zhanghui9700/9874686\n\n\nhttps://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/ceph_block_device_to_openstack_guide/configuring_openstack_to_use_ceph\n\n\nhttp://docs.ceph.com/docs/master/rbd/rbd-openstack/\n\n\nhttps://ask.openstack.org/en/question/119889/openstack-compute-node-not-recognized-as-hypervisor/", 
            "title": "OpenStack - Integrasi dengan Ceph Cluster"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#pengantar", 
            "text": "Setelah  sebelumnya  kita melakukan installasi OpenStack dengan PackStack. Dalam skenario kali ini kita akan menggantikan disk space yang digunakan oleh, block storage dan image stock dengan Ceph.  Ceph (diucapkan /\u02c8s\u025bf/ atau /\u02c8k\u025bf/ ) adalah perangkat lunak sumber terbuka penyimpanan terdistribusi yang berbasis penyimpanan objek pada suatu kluster komputer. Ceph menyediakan antarmuka penyimpanan dengan level objek, blok- dan berkas. Tujuan utama Ceph adalah menyediakan penyimpanan terdistribusi tanpa satu titik kegagalan, dapat ditingkatkan hingga skala exabyte, dan tersedia secara bebas.  https://id.wikipedia.org/wiki/Ceph_(perangkat_lunak)  Pastikan OpenStack sudah berjalan dengan lancar, tidak ada kendala baik didalam networkingnya maupun instances, dan lain-lain.", 
            "title": "Pengantar"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#topology", 
            "text": "+--------------------------+\n                                                          |                          |\n                                                          |                          |\n                                                          |   - Compute (Nova)       |\n                                +-----------------------  |                          +------------+\n                                |                         |                          |            |\n+---------------------------+   |                         |                          |            |\n|                           |   |                         |                          |            |\n| - Controller              |   |                         +--------------------------+            |\n| | Compute (Nova)          | +-^                                                                 |\n| | Images Storage (glance) | |                                                                   |\n| - Block Storage (cinder)  | |                           +---------------------------+           |\n|                           | +-------------------------  |                           |  ---------+\n|                           | |                           |  ceph mon atau ceph1      |           |\n+---------------------------+ |                           |                           |           |\n                              |                           +---------------------------+           |\n                              |                           +---------------------------+           |\n                              |                           |                           |           |\n                              +-------------------------  |  osd0                     |  ---------+\n                              |                           |                           |           |\n                              |                           +---------------------------+           |\n                              |                           +---------------------------+           |\n                              |                           |                           |           |\n                              +-------------------------  |  osd1                     |  ---------+\n                                                          |                           |\n                                                          +---------------------------+\n\n\n10.10.2.205 ceph-mon ceph1\n10.10.2.206 osd0\n10.10.2.207 osd1\n10.10.2.205 mds0\n10.10.2.204 controller compute0 labopenstack.local\n10.10.2.202 compute1 compute compute.localdomain  Disk  ceph-mon :  [ceph-mon][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[ceph-mon][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[ceph-mon][INFO  ] Disk /dev/sdc: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[ceph-mon][INFO  ] Disk /dev/sdd: 68.7 GB, 68719476736 bytes, 134217728 sectors  Disk  osd0 :  [osd0][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[osd0][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[osd0][INFO  ] Disk /dev/sdc: 68.7 GB, 68719476736 bytes, 134217728 sectors  Disk  osd1 :  [osd1][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[osd1][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors", 
            "title": "Topology"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#requierements", 
            "text": "siapkan  kopi lampung  dulu :D , langkah lumayan panjang soalnya :D  openstack yg sudah running well.  untuk kebutuhan ini, kita butuh ceph server paling tidak 1 atau 2 server dengan minimal ram 8GB.  matikan terlebih dahulu firewall dan network manager:   jalankan dengan perintah:      sudo systemctl disable firewalld\n    sudo systemctl stop firewalld\n    sudo systemctl disable NetworkManager\n    sudo systemctl stop NetworkManager\n    sudo systemctl enable network\n    sudo systemctl start network", 
            "title": "Requierements"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#installasi-ceph-cluster", 
            "text": "install ceph repo dan update, lakukan di mesin  ceph-mon  yum install epel-release\nyum install wget -y\nyum -y install vim screen crudini\nyum install epel-release yum-plugin-priorities https://download.ceph.com/rpm-mimic/el7/noarch/ceph-release-1-1.el7.noarch.rpm\nyum install https://download.ceph.com/rpm-mimic/el7/noarch/ceph-deploy-2.0.1-0.noarch.rpm\nyum repolist\nyum -y update    install ntp, lakukan di mesin  ceph-mon  yum -y install chrony\nsystemctl enable chronyd.service\nsystemctl restart chronyd.service\nsystemctl status chronyd.service    create sudoer untuk user stack. user ini digunakan untuk manajemen ceph. lakukan di mesin  ceph-mon ,  osd0 ,  osd1  cat   EOF  /etc/sudoers.d/stack\nstack ALL = (root) NOPASSWD:ALL\nDefaults:stack !requiretty\nEOF\n\nuseradd -d /home/stack -m stack\npasswd stack\nchmod 0440 /etc/sudoers.d/stack\nsetenforce 0\ngetenforce\nsed -i 's/SELINUX\\=enforcing/SELINUX\\=permissive/g' /etc/selinux/config\ncat /etc/selinux/config    setup auto ssh     setup auto ssh berjalan dari mesin  ceph-mon  ke  osd0  ataupun  osd1  dan mesin  ceph-mon  sendiri.  lakukan di mesin  ceph-mon  [stack@ceph1 ~]$ cat .ssh/config \nHost ceph1\n   Hostname ceph1\n   User stack\nHost osd0\n   Hostname osd0\n   User stack\nHost ceph-osd1\n   Hostname osd1\n   User stack\n[stack@ceph1 ~]$  copy public key:  ssh-copy-id -i ~/.ssh/id_rsa.pub 10.10.2.205\nssh-copy-id -i ~/.ssh/id_rsa.pub 10.10.2.206\nssh-copy-id -i ~/.ssh/id_rsa.pub 10.10.2.207   Deploy Ceph   lakukan di mesin  ceph-mon  sebagai user  stack  mkdir os-ceph\ncd os-ceph/\nceph-deploy new ceph-mon  note : pada saat percobaan ini menggunakan host  ceph1  daripada host  ceph-mon . Jika ada penulisan dengan host  ceph-mon  itu artinya mesin  ceph1 . Intinya kedua host tersebut mengarah ke mesin yang sama.  Set jumlah replica 2 (sehingga data yang tersimpan pada cluster ceph akan di replica sebanyak 2)  echo \"osd pool default size = 2\"   ceph.conf\necho \"osd pool default min size = 1\"   ceph.conf\necho \"osd crush chooseleaf type = 1\"   ceph.conf\necho \"osd journal size  = 100\"   ceph.conf  Install ceph mengunakan ceph-deploy:  ceph-deploy install ceph-mon\nceph-deploy install osd0 osd1  Membuat initial monitor:  ceph-deploy mon create-initial\nceph-deploy mon create  Melihat disk list di mesin  osd0  [stack@ceph1 osceph2]$ ceph-deploy disk list osd0\n[ceph_deploy.conf][DEBUG ] found configuration file at: /home/stack/.cephdeploy.conf\n[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /bin/ceph-deploy disk list osd0\n[ceph_deploy.cli][INFO  ] ceph-deploy options:\n[ceph_deploy.cli][INFO  ]  username                      : None\n[ceph_deploy.cli][INFO  ]  verbose                       : False\n[ceph_deploy.cli][INFO  ]  debug                         : False\n[ceph_deploy.cli][INFO  ]  overwrite_conf                : False\n[ceph_deploy.cli][INFO  ]  subcommand                    : list\n[ceph_deploy.cli][INFO  ]  quiet                         : False\n[ceph_deploy.cli][INFO  ]  cd_conf                       :  ceph_deploy.conf.cephdeploy.Conf instance at 0x7f610f1773f8 \n[ceph_deploy.cli][INFO  ]  cluster                       : ceph\n[ceph_deploy.cli][INFO  ]  host                          : ['osd0']\n[ceph_deploy.cli][INFO  ]  func                          :  function disk at 0x7f610f3c9938 \n[ceph_deploy.cli][INFO  ]  ceph_conf                     : None\n[ceph_deploy.cli][INFO  ]  default_release               : False\n[osd0][DEBUG ] connection detected need for sudo\n[osd0][DEBUG ] connected to host: osd0 \n[osd0][DEBUG ] detect platform information from remote host\n[osd0][DEBUG ] detect machine type\n[osd0][DEBUG ] find the location of an executable\n[osd0][INFO  ] Running command: sudo fdisk -l\n[osd0][INFO  ] Disk /dev/sda: 34.4 GB, 34359738368 bytes, 67108864 sectors\n[osd0][INFO  ] Disk /dev/mapper/centos-root: 31.1 GB, 31130124288 bytes, 60801024 sectors\n[osd0][INFO  ] Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors\n[osd0][INFO  ] Disk /dev/sdb: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[osd0][INFO  ] Disk /dev/sdc: 68.7 GB, 68719476736 bytes, 134217728 sectors\n[osd0][INFO  ] Disk /dev/mapper/ceph--455f828c--2454--4f1d--b6f3--887fa8b48e58-osd--block--b1f537f7--8b40--490e--b872--98b84f5f0118: 68.7 GB, 68715282432 bytes, 134209536 sectors\n[osd0][INFO  ] Disk /dev/mapper/ceph--e389bab8--4765--4fd3--868e--26bfb019dc7b-osd--block--087e2243--02c1--4573--afc8--e642fff2afb4: 68.7 GB, 68715282432 bytes, 134209536 sectors  Format multiple disk ceph lewat  ceph-deploy :  jalankan  ceph-deploy disk zap osd1 /dev/sdc /dev/sdd  [stack@ceph1 ~]$ ceph-deploy disk zap osd1 /dev/sdc /dev/sdd\n[ceph_deploy.conf][DEBUG ] found configuration file at: /home/stack/.cephdeploy.conf\n[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /bin/ceph-deploy disk zap osd1 /dev/sdc /dev/sdd\n[ceph_deploy.cli][INFO  ] ceph-deploy options:\n[ceph_deploy.cli][INFO  ]  username                      : None\n[ceph_deploy.cli][INFO  ]  verbose                       : False\n[ceph_deploy.cli][INFO  ]  debug                         : False\n[ceph_deploy.cli][INFO  ]  overwrite_conf                : False\n[ceph_deploy.cli][INFO  ]  subcommand                    : zap\n[ceph_deploy.cli][INFO  ]  quiet                         : False\n[ceph_deploy.cli][INFO  ]  cd_conf                       :  ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3d5e9323f8 \n[ceph_deploy.cli][INFO  ]  cluster                       : ceph\n[ceph_deploy.cli][INFO  ]  host                          : osd1\n[ceph_deploy.cli][INFO  ]  func                          :  function disk at 0x7f3d5eb84938 \n[ceph_deploy.cli][INFO  ]  ceph_conf                     : None\n[ceph_deploy.cli][INFO  ]  default_release               : False\n[ceph_deploy.cli][INFO  ]  disk                          : ['/dev/sdc', '/dev/sdd']\n[ceph_deploy.osd][DEBUG ] zapping /dev/sdc on osd1\n[osd1][DEBUG ] connection detected need for sudo\n[osd1][DEBUG ] connected to host: osd1 \n[osd1][DEBUG ] detect platform information from remote host\n[osd1][DEBUG ] detect machine type\n[osd1][DEBUG ] find the location of an executable\n[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.6.1810 Core\n[osd1][DEBUG ] zeroing last few blocks of device\n[osd1][DEBUG ] find the location of an executable\n[osd1][INFO  ] Running command: sudo /usr/sbin/ceph-volume lvm zap /dev/sdc\n[osd1][DEBUG ] --  Zapping: /dev/sdc\n[osd1][DEBUG ] --  --destroy was not specified, but zapping a whole device will remove the partition table\n[osd1][DEBUG ] Running command: /usr/sbin/wipefs --all /dev/sdc\n[osd1][DEBUG ] Running command: /bin/dd if=/dev/zero of=/dev/sdc bs=1M count=10\n[osd1][DEBUG ]  stderr: 10+0 records in\n[osd1][DEBUG ] 10+0 records out\n[osd1][DEBUG ] 10485760 bytes (10 MB) copied\n[osd1][DEBUG ]  stderr: , 0.010268 s, 1.0 GB/s\n[osd1][DEBUG ] --  Zapping successful for:  Raw Device: /dev/sdc \n[ceph_deploy.osd][DEBUG ] zapping /dev/sdd on osd1\n[osd1][DEBUG ] connection detected need for sudo\n[osd1][DEBUG ] connected to host: osd1\n[osd1][DEBUG ] detect platform information from remote host\n[osd1][DEBUG ] detect machine type\n[osd1][DEBUG ] find the location of an executable\n[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.6.1810 Core\n[osd1][DEBUG ] zeroing last few blocks of device\n[osd1][DEBUG ] find the location of an executable\n[osd1][INFO  ] Running command: sudo /usr/sbin/ceph-volume lvm zap /dev/sdd\n[osd1][DEBUG ] --  Zapping: /dev/sdd\n[osd1][DEBUG ] --  --destroy was not specified, but zapping a whole device will remove the partition table\n[osd1][DEBUG ] Running command: /usr/sbin/wipefs --all /dev/sdd\n[osd1][DEBUG ] Running command: /bin/dd if=/dev/zero of=/dev/sdd bs=1M count=10\n[osd1][DEBUG ]  stderr: 10+0 records in\n[osd1][DEBUG ] 10+0 records out\n[osd1][DEBUG ] 10485760 bytes (10 MB) copied\n[osd1][DEBUG ]  stderr: , 0.00494895 s, 2.1 GB/s\n[osd1][DEBUG ] --  Zapping successful for:  Raw Device: /dev/sdd   lakukan hal sama pada host  ceph-mon  dan  osd0  sesuai dengan disk yang dimiliki.  Membuat OSD dengan  ceph-deploy :  for a in /dev/sdc /dev/sdd;do ceph-deploy osd create --data $a osd1`;done  lakukan hal sama pada host  ceph-mon  dan  osd0  sesuai dengan disk yang dimiliki.  Copy konfigurasi dan key ke semua node:  ceph-deploy admin ceph1 osd0 osd1\nsudo chmod +r /etc/ceph/ceph.client.admin.keyring  cek ceph status:  [stack@ceph1 osceph2]$ ceph -s\n  cluster:\n    id:     10925d88-4e51-4311-88aa-52c81ab14eb6\n    health: HEALTH_WARN\n            no active mgr\n\n  services:\n    mon: 1 daemons, quorum ceph1\n    mgr: no daemons active\n    osd: 6 osds: 6 up, 6 in\n\n  data:\n    pools:   0 pools, 0 pgs   \n    objects: 0  objects, 0 B  \n    usage:   0 B used, 0 B / 0 B avail\n    pgs:  no active mgr , untuk mengaktifkannya:  [stack@ceph1 osceph2]$ ceph-deploy mgr create ceph1\n[ceph_deploy.conf][DEBUG ] found configuration file at: /home/stack/.cephdeploy.conf\n[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /bin/ceph-deploy mgr create ceph1\n[ceph_deploy.cli][INFO  ] ceph-deploy options:\n.....\n[ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph1\n[ceph1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf\n[ceph1][WARNIN] mgr keyring does not exist yet, creating one\n[ceph1][DEBUG ] create a keyring file\n[ceph1][DEBUG ] create path recursively if it doesn't exist\n[ceph1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.ceph1 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-ceph1/keyring\n[ceph1][INFO  ] Running command: sudo systemctl enable ceph-mgr@ceph1\n[ceph1][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@ceph1.service to /usr/lib/systemd/system/ceph-mgr@.service.\n[ceph1][INFO  ] Running command: sudo systemctl start ceph-mgr@ceph1\n[ceph1][INFO  ] Running command: sudo systemctl enable ceph.target  lalu cek dengan command:  sudo systemctl status ceph-mgr@ceph1  Test create pool:  ceph osd pool create volumes 128\nceph osd pool create images 128\nceph osd pool create backups 128\nceph osd pool create vms 128\nrbd pool init volumes\nrbd pool init images\nrbd pool init backups\nrbd pool init vms  Cek status:  [stack@ceph1 osceph2]$ ceph -s\n  cluster:\n    id:     10925d88-4e51-4311-88aa-52c81ab14eb6\n    health: HEALTH_OK\n\n  services:\n    mon: 1 daemons, quorum ceph1\n    mgr: ceph1(active)\n    osd: 6 osds: 6 up, 6 in\n\n  data:\n    pools:   0 pools, 0 pgs\n    objects: 0  objects, 0 B\n    usage:   6.0 GiB used, 378 GiB / 384 GiB avail\n    pgs:", 
            "title": "Installasi CEPH Cluster"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#integrasi-ceph-cluster-dengan-openstack-rocky", 
            "text": "", 
            "title": "Integrasi Ceph Cluster dengan OpenStack Rocky"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#install-requierements", 
            "text": "masuk ke dalam user root di mesin ceph1  ssh controller sudo yum -y install python-rbd ceph-common\nssh compute1 sudo yum -y install python-rbd ceph-common\ncat /etc/ceph/ceph.conf | ssh controller sudo tee /etc/ceph/ceph.conf\ncat /etc/ceph/ceph.conf | ssh compute1 sudo tee /etc/ceph/ceph.conf  masuk ke dalam user  stack  setup client authentication untuk service cinder:  [stack@ceph1 osceph2]$ ceph auth get-or-create client.cinder mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=vms, allow rx pool=images'\n[client.cinder]\n        key = AQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==\n[stack@ceph1 osceph2]$  setup client authentication untuk service glance:  [stack@ceph1 osceph2]$ ceph auth get-or-create client.glance mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=images'\n[client.glance]\n        key = AQDDtCJd4aiPLhAALdSwrLdxizoZWZKs2nnBGg==\n[stack@ceph1 osceph2]$  Menambahkan key untuk client.cinder dan client.glance ke masing-masing nodes dan mengganti ownershipnya:  glance@controller :  [stack@ceph1 osceph2]$ ceph auth get-or-create client.glance | ssh root@controller sudo tee /etc/ceph/ceph.client.glance.keyring\n[client.glance]\n        key = AQDDtCJd4aiPLhAALdSwrLdxizoZWZKs2nnBGg==\n[stack@ceph1 osceph2]$ \n[stack@ceph1 osceph2]$ ssh root@controller sudo chown glance:glance /etc/ceph/ceph.client.glance.keyring\n[stack@ceph1 osceph2]$  cinder@controller :  [stack@ceph1 osceph2]$ ceph auth get-or-create client.cinder | ssh root@controller sudo tee /etc/ceph/ceph.client.cinder.keyring\n[client.cinder]\n        key = AQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==\n[stack@ceph1 osceph2]$ ssh root@controller sudo chown cinder:cinder /etc/ceph/ceph.client.cinder.keyring\n[stack@ceph1 osceph2]$  glance@compute :  [stack@ceph1 osceph2]$ ceph auth get-or-create client.glance | ssh root@compute1 sudo tee /etc/ceph/ceph.client.glance.keyring\n[client.glance]\n        key = AQDDtCJd4aiPLhAALdSwrLdxizoZWZKs2nnBGg==\n[stack@ceph1 osceph2]$  cinder@compute :  [stack@ceph1 osceph2]$ ceph auth get-or-create client.cinder | ssh root@compute1 sudo tee /etc/ceph/ceph.client.cinder.keyring\n[client.cinder]\n        key = AQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==\n[stack@ceph1 osceph2]$  copy cinder key:  [stack@ceph1 osceph2]$ ceph auth get-key client.cinder | ssh root@controller tee client.cinder.key\nAQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==[stack@ceph1 osceph2]$ \n[stack@ceph1 osceph2]$\n\n[stack@ceph1 osceph2]$ ceph auth get-key client.cinder | ssh root@compute1 tee client.cinder.key\nAQAmtCJdV85NHBAAhPX88nr0pVPZP6+34IPQhw==[stack@ceph1 osceph2]$ \n[stack@ceph1 osceph2]$  Generate a UUID for the secret, and save the UUID of the secret for configuring nova-compute later  [root@compute ~]# uuidgen   uuid-secret.txt\n[root@compute ~]# cat uuid-secret.txt \neba93c91-5641-4890-aad7-42606c3c3e66  Then, on the compute nodes, add the secret key to libvirt:  cat   secret.xml  EOF secret ephemeral='no' private='no' \n   uuid `cat uuid-secret.txt` /uuid \n   usage type='ceph' \n     name client.cinder secret /name \n   /usage  /secret \nEOF  go:  [root@compute ~]# cat   secret.xml  EOF   secret ephemeral='no' private='no'      uuid `cat uuid-secret.txt` /uuid      usage type='ceph'        name client.cinder secret /name      /usage    /secret   EOF\n\n\n\n[root@compute ~]# virsh secret-define --file secret.xml\nSecret eba93c91-5641-4890-aad7-42606c3c3e66 created\n[root@compute ~]# virsh secret-set-value --secret $(cat uuid-secret.txt) --base64 $(cat client.cinder.key)\nSecret value set\n[root@compute ~]#  Jika compute node ada di controller, maka perlu dilakukan juga.", 
            "title": "Install requierements"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#setup-cinder", 
            "text": "Cinder digunakan untuk menyimpan disk dari vm yg ada di openstack.  masuk ke mesin controller, edit file  /etc/cinder/cinder.conf  lalu tambahkan ke section  [DEFAULT]   dan aktifkan  Ceph  sebagai backend dari cinder.  enabled_backends = ceph\nglance_api_version = 2  tambahkan section  ceph :  [ceph]\nrbd_flatten_volume_from_snapshot = false\nrbd_max_clone_depth = 5\nrbd_store_chunk_size = 4\nrados_connect_timeout = -1\nvolume_driver = cinder.volume.drivers.rbd.RBDDriver\nrbd_ceph_conf = /etc/ceph/ceph.conf\nrbd_pool = volumes\nrbd_user = cinder\nglance_api_version = 2\nrbd_secret_uuid = eba93c91-5641-4890-aad7-42606c3c3e66\nvolume_backend_name = ceph\nrbd_cluster_name = ceph  rbd_secret_uuid sesuaikan dengan hasil  uuidgen .  hasil akhir  cinder.conf :   [DEFAULT]\nbackup_swift_url=http://10.10.2.204:8080/v1/AUTH_\nbackup_swift_container=volumebackups\nbackup_driver=cinder.backup.drivers.swift\nenable_v3_api=True\nstorage_availability_zone=nova\ndefault_availability_zone=nova\n#default_volume_type=iscsi\n\ndefault_volume_type=ceph\nauth_strategy=keystone\nenabled_backends=ceph\nglance_api_version = 2\nosapi_volume_listen=0.0.0.0\nosapi_volume_workers=4\ndebug=False\nlog_dir=/var/log/cinder\ntransport_url=rabbit://guest:guest@10.10.2.204:5672/\ncontrol_exchange=openstack\napi_paste_config=/etc/cinder/api-paste.ini\nglance_host=10.10.2.204\n\n[backend]\n\n[backend_defaults]\n\n[barbican]\n\n[brcd_fabric_example]\n\n[cisco_fabric_example]\n\n[coordination]\n\n[cors]\n\n[database]\n\nconnection=mysql+pymysql://cinder:1c36661a5efa4c2b@10.10.2.204/cinder\n\n[fc-zone-manager]\n\n[healthcheck]\n\n[key_manager]\n\nbackend=cinder.keymgr.conf_key_mgr.ConfKeyManager\n\n[keystone_authtoken]\n\nwww_authenticate_uri=http://10.10.2.204:5000/\n\nauth_uri=http://10.10.2.204:5000/\n\nauth_type=password\n\nauth_url=http://10.10.2.204:35357\nusername=cinder\npassword=e3f3c81d1b41459b\nuser_domain_name=Default\nproject_name=services\nproject_domain_name=Default\n\n[matchmaker_redis]\n\n[nova]\n\n[oslo_concurrency]\n\nlock_path=/var/lib/cinder/tmp\n\n[oslo_messaging_amqp]\n\n[oslo_messaging_kafka]\n\n[oslo_messaging_notifications]\n\ndriver=messagingv2\n\n[oslo_messaging_rabbit]\n\nssl=False\n\n[oslo_messaging_zmq]\n\n[oslo_middleware]\n\n[oslo_policy]\n\npolicy_file=/etc/cinder/policy.json\n\n[oslo_reports]\n\n[oslo_versionedobjects]\n\n[profiler]\n\n[sample_remote_file_source]\n\n[service_user]\n\n[ssl]\n\n[vault]\n#[lvm]\n#volume_backend_name=lvm\n#volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver\n#iscsi_ip_address=10.10.2.204\n#iscsi_helper=lioadm\n#volume_group=cinder-volumes\n#volumes_dir=/var/lib/cinder/volumes\n\n[ceph]\n##volume_driver = cinder.volume.drivers.rbd.RBDDriver\n##rbd_pool = volumes\n##rbd_user = cinder\n##rbd_ceph_conf = /etc/ceph/ceph.conf\nrbd_flatten_volume_from_snapshot = false\nrbd_max_clone_depth = 5\nrbd_store_chunk_size = 4\nrados_connect_timeout = -1\nvolume_driver = cinder.volume.drivers.rbd.RBDDriver\nrbd_ceph_conf = /etc/ceph/ceph.conf\nrbd_pool = volumes\nrbd_user = cinder\nglance_api_version = 2\nrbd_secret_uuid = eba93c91-5641-4890-aad7-42606c3c3e66\nvolume_backend_name = ceph\nrbd_cluster_name = ceph\n\n#volume_driver = cinder.volume.drivers.rbd.RBDDriver\n#rbd_pool = volumes\n#rbd_ceph_conf = /etc/ceph/ceph.conf\n#rbd_flatten_volume_from_snapshot = false\n#rbd_max_clone_depth = 5\n#rbd_store_chunk_size = 4\n#rados_connect_timeout = -1\n#rbd_user = cinder\n#rbd_secret_uuid = ca405f73-e2c9-40aa-ab67-34cf47f7caf9  Restart Service Cinder  restart dengan perintah:  [root@controller ~(keystone_admin)]# service openstack-cinder-api restart\nRedirecting to /bin/systemctl restart openstack-cinder-api.service\n[root@controller ~(keystone_admin)]# service openstack-cinder-scheduler restart\nRedirecting to /bin/systemctl restart openstack-cinder-scheduler.service\n[root@controller ~(keystone_admin)]# service openstack-cinder-volume restart\nRedirecting to /bin/systemctl restart openstack-cinder-volume.service\n[root@controller ~(keystone_admin)]#  lalu test dengan perintah  rbd --id cinder ls volumes  [root@controller ~(keystone_admin)]#  rbd --id cinder ls volumes\n2019-07-18 10:49:20.216 7f8210d64b00 -1 asok(0x55b893fd64f0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/guests/ceph-client.cinder.28025.94251245209344.asok': (2) No such file or directory\nvolume-23d36d36-5969-49e2-a542-9f6350359b38\nvolume-8ec1920f-b3fe-4ce8-9a45-456645ac480c\nvolume-8f7c693b-a32f-4c7e-9cf8-cc6b490687f8\nvolume-9ffa5128-31d6-4ae9-a668-949ac49b5255\nvolume-a711ee9e-418a-4b39-a661-d7a5990270d5\nvolume-b3e0396b-b346-42c7-9ff3-1058e839f870\nvolume-dd948a95-6d6a-4624-a000-1949e4a915a4\nvolume-f9a9bb00-6f5a-4f57-ae16-3a6368d9ec5c\n[root@controller ~(keystone_admin)]#  Test Create volume:  [root@controller ~(keystone_admin)]# cinder create --volume-type ceph --display-name testCephVolTut 5\n+--------------------------------+--------------------------------------+\n| Property                       | Value                                |\n+--------------------------------+--------------------------------------+\n| attachments                    | []                                   |\n| availability_zone              | nova                                 |\n| bootable                       | false                                |\n| consistencygroup_id            | None                                 |\n| created_at                     | 2019-07-18T03:51:11.000000           |\n| description                    | None                                 |\n| encrypted                      | False                                |\n| id                             | 4897b2b4-c9eb-4c40-b3e8-f0fb75fed592 |\n| metadata                       | {}                                   |\n| migration_status               | None                                 |\n| multiattach                    | False                                |\n| name                           | testCephVolTut                       |\n| os-vol-host-attr:host          | None                                 |\n| os-vol-mig-status-attr:migstat | None                                 |\n| os-vol-mig-status-attr:name_id | None                                 |\n| os-vol-tenant-attr:tenant_id   | b0a4a8851d114a3f9bf4265c9e4c5a9c     |\n| replication_status             | None                                 |\n| size                           | 5                                    |\n| snapshot_id                    | None                                 |\n| source_volid                   | None                                 |\n| status                         | creating                             |\n| updated_at                     | None                                 |\n| user_id                        | dfba230d76a8486287912da65d815769     |\n| volume_type                    | ceph                                 |\n+--------------------------------+--------------------------------------+\n[root@controller ~(keystone_admin)]#  lihat list volume:  [root@controller ~(keystone_admin)]# cinder list\n+--------------------------------------+-----------+----------------+------+-------------+----------+--------------------------------------+\n| ID                                   | Status    | Name           | Size | Volume Type | Bootable | Attached to                          |\n+--------------------------------------+-----------+----------------+------+-------------+----------+--------------------------------------+\n| 23d36d36-5969-49e2-a542-9f6350359b38 | available | testCephVold   | 5    | ceph        | false    |                                      |\n| 4897b2b4-c9eb-4c40-b3e8-f0fb75fed592 | available | testCephVolTut | 5    | ceph        | false    |                                      |\n| 88a95ab2-7f9b-4367-bee0-211926ab2bcc | error     | testaja        | 2    | ceph        | false    |                                      |\n| 8ec1920f-b3fe-4ce8-9a45-456645ac480c | in-use    |                | 40   | ceph        | true     | 45644d8c-4cf3-4faf-95c7-02a8bc9095c2 |\n| 8f7c693b-a32f-4c7e-9cf8-cc6b490687f8 | available | test           | 1    | ceph        | false    |                                      |\n| 9ffa5128-31d6-4ae9-a668-949ac49b5255 | available | testCephVasdol | 5    | ceph        | false    |                                      |\n| a711ee9e-418a-4b39-a661-d7a5990270d5 | available | testCephVol    | 5    | ceph        | false    |                                      |\n| b3e0396b-b346-42c7-9ff3-1058e839f870 | available | cephvol        | 2    | ceph        | false    |                                      |\n| dd948a95-6d6a-4624-a000-1949e4a915a4 | in-use    |                | 10   | ceph        | true     | bac4ed05-4c5d-458f-b6ec-6276d54b52e5 |\n| f9a9bb00-6f5a-4f57-ae16-3a6368d9ec5c | in-use    | freebsd        | 40   | ceph        | true     | 0736390f-3f9e-4ebb-a08e-05d9b0611703 |\n+--------------------------------------+-----------+----------------+------+-------------+----------+--------------------------------------+\n[root@controller ~(keystone_admin)]# openstack volume list\n+--------------------------------------+----------------+-----------+------+---------------------------------+\n| ID                                   | Name           | Status    | Size | Attached to                     |\n+--------------------------------------+----------------+-----------+------+---------------------------------+\n| 4897b2b4-c9eb-4c40-b3e8-f0fb75fed592 | testCephVolTut | available |    5 |                                 |\n| 8ec1920f-b3fe-4ce8-9a45-456645ac480c |                | in-use    |   40 | Attached to centos on /dev/vda  |\n| dd948a95-6d6a-4624-a000-1949e4a915a4 |                | in-use    |   10 | Attached to cirros on /dev/vda  |\n| f9a9bb00-6f5a-4f57-ae16-3a6368d9ec5c | freebsd        | in-use    |   40 | Attached to fbsd on /dev/vda    |\n| 23d36d36-5969-49e2-a542-9f6350359b38 | testCephVold   | available |    5 |                                 |\n| 9ffa5128-31d6-4ae9-a668-949ac49b5255 | testCephVasdol | available |    5 |                                 |\n| 88a95ab2-7f9b-4367-bee0-211926ab2bcc | testaja        | error     |    2 |                                 |\n| a711ee9e-418a-4b39-a661-d7a5990270d5 | testCephVol    | available |    5 |                                 |\n| b3e0396b-b346-42c7-9ff3-1058e839f870 | cephvol        | available |    2 |                                 |\n| 8f7c693b-a32f-4c7e-9cf8-cc6b490687f8 | test           | available |    1 |                                 |\n+--------------------------------------+----------------+-----------+------+---------------------------------+\n[root@controller ~(keystone_admin)]#  lihat  service-list  status dari  cinder :  [root@controller ~(keystone_admin)]# cinder service-list\n+------------------+-----------------+------+----------+-------+----------------------------+-----------------+\n| Binary           | Host            | Zone | Status   | State | Updated_at                 | Disabled Reason |\n+------------------+-----------------+------+----------+-------+----------------------------+-----------------+\n| cinder-backup    | controller      | nova | enabled  | down  | 2019-07-12T07:02:01.000000 | -               |\n| cinder-scheduler | controller      | nova | enabled  | up    | 2019-07-18T03:54:33.000000 | -               |\n| cinder-volume    | controller@ceph | nova | enabled  | up    | 2019-07-18T03:54:36.000000 | -               |\n| cinder-volume    | controller@lvm  | nova | disabled | down  | 2019-07-08T07:11:04.000000 | migratekeCeph   |\n+------------------+-----------------+------+----------+-------+----------------------------+-----------------+  jika ingin menonaktifkan  service-list :  openstack volume service set --disable --disable-reason migratekeCeph controller@lvm cinder-volume  melihat type storage dari cinder:  [root@controller ~(keystone_admin)]# cinder type-list\n\n+--------------------------------------+-------+-------------+-----------+\n| ID                                   | Name  | Description | Is_Public |\n+--------------------------------------+-------+-------------+-----------+\n| 16e4f895-3f64-4a3d-b9be-6accd740a3fc | ceph  | -           | True      |\n| 513f6ef6-58af-4db6-97c3-76911c812d55 | iscsi | -           | True      |\n+--------------------------------------+-------+-------------+-----------+\n[root@controller ~(keystone_admin)]# cinder extra-specs-list\n+--------------------------------------+-------+---------------------------------+\n| ID                                   | Name  | extra_specs                     |\n+--------------------------------------+-------+---------------------------------+\n| 16e4f895-3f64-4a3d-b9be-6accd740a3fc | ceph  | {'volume_backend_name': 'ceph'} |\n| 513f6ef6-58af-4db6-97c3-76911c812d55 | iscsi | {'volume_backend_name': 'lvm'}  |\n+--------------------------------------+-------+---------------------------------+  set ceph sebagai default backend:  openstack-config --set /etc/cinder/cinder.conf DEFAULT enabled_backends ceph", 
            "title": "Setup Cinder"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#setup-glance", 
            "text": "Glance digunakan untuk menyimpan iso ataupun images yang akan digunakan vm di OpenStack.  edit file  /etc/glance/glance-api.conf  dan tambahkan:  stores=rbd,file,http,swift\ndefault_store=rbd\n##file\nrbd_store_chunk_size = 8\nrbd_store_pool = images\nrbd_store_user = glance\nrbd_store_ceph_conf = /etc/ceph/ceph.conf  hasil akhir  glance-api.conf :   [DEFAULT]\nbind_host=0.0.0.0\nbind_port=9292\nworkers=4\nimage_cache_dir=/var/lib/glance/image-cache\nregistry_host=0.0.0.0\ndebug=False\nlog_file=/var/log/glance/api.log\nlog_dir=/var/log/glance\ntransport_url=rabbit://guest:guest@10.10.2.204:5672/\nenable_v1_api=False\n\n[cors]\n[database]\nconnection=mysql+pymysql://glance:4d819a8b65594569@10.10.2.204/glance\n\n[glance_store]\n\nstores=rbd,file,http,swift\n\ndefault_store=rbd\n##file\n\nrbd_store_chunk_size = 8\nrbd_store_pool = images\nrbd_store_user = glance\nrbd_store_ceph_conf = /etc/ceph/ceph.conf\n\nfilesystem_store_datadir=/var/lib/glance/images/\n\nos_region_name=RegionOne\n\n[image_format]\n\n[keystone_authtoken]\n\nwww_authenticate_uri=http://10.10.2.204:5000/v3\n\nauth_uri=http://10.10.2.204:5000/v3\n\nauth_type=password\n\nauth_url=http://10.10.2.204:35357\nusername=glance\npassword=21de7a56246541aa\nuser_domain_name=Default\nproject_name=services\nproject_domain_name=Default\n\n[matchmaker_redis]\n\n[oslo_concurrency]\n\n[oslo_messaging_amqp]\n\n[oslo_messaging_kafka]\n[oslo_messaging_notifications]\n\ndriver=messagingv2\n\ntopics=notifications\n\n[oslo_messaging_rabbit]\n\nssl=False\n\ndefault_notification_exchange=glance\n\n[oslo_messaging_zmq]\n\n[oslo_middleware]\n\n[oslo_policy]\n\npolicy_file=/etc/glance/policy.json\n\n[paste_deploy]\n\nflavor=keystone\n\n[profiler]\n\n[store_type_location_strategy]\n\n[task]\n\n[taskflow_executor]  restart service glance  service openstack-glance-api restart\nservice gpenstack-glance-registry restart  check images lewat rbd  [root@controller ~(keystone_admin)]# rbd --id glance ls images\n2019-07-18 13:29:24.350 7f4ebe2f1b00 -1 asok(0x55d34ebfb4f0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/guests/ceph-client.glance.24598.94366047655680.asok': (2) No such file or directory\n5759f626-32c2-45c7-b2e4-6972f606ae68\n9991376d-b436-437a-b76a-e9e68bb6e8e4\nca03be4c-d5ce-4a1a-b0a0-d769edd6b703\n[root@controller ~(keystone_admin)]#  check image list:  [root@controller ~(keystone_admin)]# glance image-list\n+--------------------------------------+---------------------+\n| ID                                   | Name                |\n+--------------------------------------+---------------------+\n| 5759f626-32c2-45c7-b2e4-6972f606ae68 | CentOS-7-x86_64     |\n| 9991376d-b436-437a-b76a-e9e68bb6e8e4 | Cirros              |\n| ca03be4c-d5ce-4a1a-b0a0-d769edd6b703 | FreeBSD-11.2-stable |\n+--------------------------------------+---------------------+  Jika masih kosong, bisa diisi sendiri:  wget -c https://download.freebsd.org/ftp/snapshots/VM-IMAGES/11.2-STABLE/amd64/Latest/FreeBSD-11.2-STABLE-amd64.qcow2.xz\ntar -xvf FreeBSD-11.2-STABLE-amd64.qcow2.xz\nopenstack image create --container-format bare --disk-format qcow2 --file FreeBSD-11.2-STABLE-amd64.qcow2 --public FreeBSD-11.2-stable  lalu check lagi:  [root@controller ~(keystone_admin)]# openstack image list\n+--------------------------------------+---------------------+--------+\n| ID                                   | Name                | Status |\n+--------------------------------------+---------------------+--------+\n| 5759f626-32c2-45c7-b2e4-6972f606ae68 | CentOS-7-x86_64     | active |\n| 9991376d-b436-437a-b76a-e9e68bb6e8e4 | Cirros              | active |\n| ca03be4c-d5ce-4a1a-b0a0-d769edd6b703 | FreeBSD-11.2-stable | active |\n+--------------------------------------+---------------------+--------+\n[root@controller ~(keystone_admin)]#  coba test dengan  centos image ;  wget -c \"http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2.xz\"\nunxz CentOS-7-x86_64-GenericCloud.qcow2.xz  create image lagi:  [root@controller ~(keystone_admin)]#  openstack image create --container-format bare --disk-format qcow2 --file CentOS-7-x86_64-GenericCloud.qcow2 --public CentOS-7-Test  lalu check:  [root@controller ~(keystone_admin)]# openstack image list\n+--------------------------------------+---------------------+--------+\n| ID                                   | Name                | Status |\n+--------------------------------------+---------------------+--------+\n| 0d9d18de-df05-46b0-96fc-10c9e1e8cc8a | CentOS-7-Test       | active |\n| 5759f626-32c2-45c7-b2e4-6972f606ae68 | CentOS-7-x86_64     | active |\n| 9991376d-b436-437a-b76a-e9e68bb6e8e4 | Cirros              | active |\n| ca03be4c-d5ce-4a1a-b0a0-d769edd6b703 | FreeBSD-11.2-stable | active |\n+--------------------------------------+---------------------+--------+\n[root@controller ~(keystone_admin)]#  ok done.", 
            "title": "Setup Glance"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#nova-compute", 
            "text": "Disetiap node  nova-compute  edit file  /etc/ceph/ceph.conf  dan tambahkan:  [client]\nrbd cache = true\nrbd cache writethrough until flush = true\nrbd concurrent management ops = 20\nadmin socket = /var/run/ceph/guests/$cluster-$type.$id.$pid.$cctid.asok\nlog file = /var/log/ceph/qemu-guest-$pid.log  hasil akhir  ceph.conf :   [global]\nfsid = ac9b148c-e413-48ae-8adc-93a5cca6e88a\nmon_initial_members = ceph1\nmon_host = 10.10.2.205\nauth_cluster_required = cephx\nauth_service_required = cephx\nauth_client_required = cephx\n\nosd pool default size = 2\nosd pool default min size = 1\nosd crush chooseleaf type = 1\nosd journal size  = 100\n\n[client]\nrbd cache = true\nrbd cache writethrough until flush = true\nrbd concurrent management ops = 20\nadmin socket = /var/run/ceph/guests/$cluster-$type.$id.$pid.$cctid.asok\nlog file = /var/log/ceph/qemu-guest-$pid.log  restart nova services  systemctl restart openstack-nova-compute  check  hypervisor  list:  [root@controller ~(keystone_admin)]# nova hypervisor-list\n\n+--------------------------------------+---------------------+-------+---------+\n| ID                                   | Hypervisor hostname | State | Status  |\n+--------------------------------------+---------------------+-------+---------+\n| 62391ec9-6b71-4b00-be98-1d89bee17129 | controller          | up    | enabled |\n| a3a253c0-10fe-464a-a77c-f85de9ff3720 | compute1            | up    | enabled |\n+--------------------------------------+---------------------+-------+---------+  via  openstack  cli  [root@controller ~(keystone_admin)]# openstack compute service list\n+----+------------------+------------+----------+---------+-------+----------------------------+\n| ID | Binary           | Host       | Zone     | Status  | State | Updated At                 |\n+----+------------------+------------+----------+---------+-------+----------------------------+\n|  3 | nova-conductor   | controller | internal | enabled | up    | 2019-07-18T06:55:09.000000 |\n|  5 | nova-scheduler   | controller | internal | enabled | up    | 2019-07-18T06:55:08.000000 |\n|  7 | nova-consoleauth | controller | internal | enabled | up    | 2019-07-18T06:55:15.000000 |\n|  9 | nova-compute     | controller | nova     | enabled | up    | 2019-07-18T06:55:09.000000 |\n| 13 | nova-compute     | compute1   | nova     | enabled | up    | 2019-07-18T06:55:17.000000 |\n+----+------------------+------------+----------+---------+-------+----------------------------+  via  nova  cli:  [root@controller ~(keystone_admin)]# nova service-list\n+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+\n| Id                                   | Binary           | Host       | Zone     | Status  | State | Updated_at                 | Disabled Reason | Forced down |\n+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+\n| b77d04ea-302d-4470-a171-9ccf04c6535b | nova-conductor   | controller | internal | enabled | up    | 2019-07-18T06:57:29.000000 | -               | False       |\n| 45a49f72-bce0-4800-b97e-2ec4f6b8ee54 | nova-scheduler   | controller | internal | enabled | up    | 2019-07-18T06:57:38.000000 | -               | False       |\n| bbe646df-3028-4e5a-a8bd-577cc6860b44 | nova-consoleauth | controller | internal | enabled | up    | 2019-07-18T06:57:35.000000 | -               | False       |\n| 77660dbd-a5ad-47c5-b93f-38e1bcf5045b | nova-compute     | controller | nova     | enabled | up    | 2019-07-18T06:57:29.000000 | -               | False       |\n| 98c1c43d-c78c-4445-b36f-91c8ffe4fde5 | nova-compute     | compute1   | nova     | enabled | up    | 2019-07-18T06:57:37.000000 | -               | False       |\n+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+\n[root@controller ~(keystone_admin)]#  cara hapus service via  nova  nova service-delete 0d770b47-d95d-4ba5-a366-5e5baa29aebd  cara  menonaktifkan  dan  mengaktifkan :  nova service-disable 0d770b47-d95d-4ba5-a366-5e5baa29aebd\nnova service-enable 0d770b47-d95d-4ba5-a366-5e5baa29aebd  cara hapus service lewat  openstack  cli:  openstack compute service delete 12  Note : Jika terjadi perbedaan antara compute node record di host openstack di horizon dengan versi cli, solusinya:  `delete service-list yang bersangkutan, hingga tersisa yg masih running well saja`  lalu discover lagi:  nova-manage discover_hosts  lihat list services:      openstack hypervisor list;nova hypervisor-list;nova service-list;openstack compute service list;   done.", 
            "title": "Nova compute"
        }, 
        {
            "location": "/openstack-integrasi-ceph-dengan-openstack/#hasil-openstack-yang-sudah-terkoneksi-dengan-ceph-cluster", 
            "text": "Referensi:   https://gist.github.com/zhanghui9700/9874686  https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/ceph_block_device_to_openstack_guide/configuring_openstack_to_use_ceph  http://docs.ceph.com/docs/master/rbd/rbd-openstack/  https://ask.openstack.org/en/question/119889/openstack-compute-node-not-recognized-as-hypervisor/", 
            "title": "Hasil OpenStack yang sudah terkoneksi dengan Ceph Cluster"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/", 
            "text": "OpenStack - Upgrade Ceph Mimic ke Nautilus\n\n\nKita bisa mengupgrade daemon di dalam Ceph cluster sementara cluster dalam keadaaan online. Ada beberapa tipe upgrade berdasarkan urutan dependensi. Untuk urutan upgrade direkomendasikan seperti berikut:\n\n\n1. Ceph Deploy\n2. Ceph Monitors\n3. Ceph OSD Daemons\n4. Ceph Metadata Servers\n5. Ceph Object Gateways\n\n\n\nCeph Deploy\n\n\nsebelum upgrade \nceph daemons\n, upgrade tool \nceph-deploy\n\n\n# yum install ceph-deploy\n\n\n\nProsedur Upgrade\n\n\nUpgrade Monitors\n\n\nUntuk mengupgrade \nmonitors\n, lakukan langkah berikut:\n\n\nUpgrade paket Ceph untuk setiap daemon atau bisa semua sekaligus:\n\n\n[stack@ceph1 ~]$ ceph-deploy install --release nautilus ceph-mon\n\n\n\nUpdate juga untuk binary ceph:\n\n\n[stack@ceph1 ~]$ sudo yum update \n sudo yum install ceph\n\n\n\nrestart \nceph mon services\n    \n\n\n[stack@ceph1 ~]$  systemctl restart ceph-mon@ceph1\n\n\n\n\n\ncek monitor ceph:\n\n\n[stack@ceph1 ~]$  ceph mon stat\n\n\n\nUpgrade OSD\n\n\nUntuk mengupgrade \nosd daemon\n, lakukan langkah berikut:\n\n\nGunakan tool \nceph-deploy\n untuk upgrade semua node \nOSD\n daemon:\n\n\n[stack@ceph1 ~]$ ceph-deploy install --release nautilus osd0 osd1\n\n\n\n\n\nUpdate juga untuk binary ceph:\n\n\n[stack@ceph1 ~]$ ssh osd0\n[stack@osd0 ~]$ sudo yum update \n sudo yum install ceph\n[stack@ceph1 ~]$ ssh osd1\n[stack@osd1 ~]$ sudo yum update \n sudo yum install ceph\n\n\n\nrestart \nOSD\n:\n\n\nsystemctl restart ceph-osd@1\nsystemctl restart ceph-osd@2\nsystemctl restart ceph-osd@3\n\n[stack@ceph1 ~]$ systemctl status ceph-osd@1\n\ufffd ceph-osd@1.service - Ceph object storage daemon osd.1\n   Loaded: loaded (/usr/lib/systemd/system/ceph-osd@.service; enabled-runtime; vendor preset: disabled)\n   Active: active (running) since Tue 2019-08-06 15:39:40 WIB; 24h ago\n  Process: 12624 ExecStartPre=/usr/lib/ceph/ceph-osd-prestart.sh --cluster ${CLUSTER} --id %i (code=exited, status=0/SUCCESS)\n Main PID: 12629 (ceph-osd)\n   CGroup: /system.slice/system-ceph\\x2dosd.slice/ceph-osd@1.service\n           \ufffd\ufffd12629 /usr/bin/ceph-osd -f --cluster ceph --id 1 --setuser ceph --setgroup ceph\n[stack@ceph1 ~]$\n\n\n\nUpgrade Metadata Server\n\n\njalankan:\n\n\n[stack@ceph1 ~]$ ceph-deploy install --release nautilus mds0\n[stack@ceph1 ~]$ sudo yum update \n sudo yum install ceph-mds\n[stack@ceph1 ~]$ systemctl restart ceph-mgr@ceph1\n\n\n\njika metadata server diinstall satu server dengan ceph-mon. maka langkah ini tidak diperlukan lagi.\n\n\nsampai dengan disini \nceph\n server seharusnya sudah menjadi versi \nnautilus\n. cek dengan command \nceph -s\n untuk melihat status cluster.\n\n\nTroubleshoot:\n\n\nMonitor not have enabled msgr2\n\n\nError Log:\n\n\nMonitor not have enabled msgr2\n\n\n\n\n\nJalankan:\n\n\nceph mon enable-msgr2\n\n\n\nlalu cek lagi \nceph -s\n\n\n\n\nLegacy BlueStore stats reporting detected\n\n\nError Log:\n\n\n\n\nHow to solve:\n\n\nrepair \nOSD\n satu per satu:\n\n\nContoh:\n\n\nsudo ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-1/\nsudo ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-2/\nsudo ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-3/\n\n\n\n\n\n\n\nsolved:\n\n\n\n\nSummary Code\n\n\n!/bin/bash\n\n\nceph-deploy install --release nautilus ceph-mon\nsudo yum update -y \n sudo yum install ceph -y\nsudo systemctl restart ceph-mon@ceph1\n\n#osd upgrade\nceph-deploy install --release nautilus osd0 osd1\n\n\nssh osd0 \"sudo yum update -y \n sudo yum install ceph -y\"\nssh osd1 \"sudo yum update -y \n sudo yum install ceph -y\"\n\n\nceph-deploy install --release nautilus mds0\nsudo yum update -y \n sudo yum install ceph-mds -y\n\nsystemctl restart ceph-mgr@ceph1\nceph --version\nssh osd0 \"ceph --version\"\nssh osd1 \"ceph --version\"\n\n\n\nRef:\n\n\n\n\nCeph Docs", 
            "title": "OpenStack - Upgrade Ceph Mimic ke Nautilus"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#ceph-deploy", 
            "text": "sebelum upgrade  ceph daemons , upgrade tool  ceph-deploy  # yum install ceph-deploy", 
            "title": "Ceph Deploy"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#prosedur-upgrade", 
            "text": "", 
            "title": "Prosedur Upgrade"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#upgrade-monitors", 
            "text": "Untuk mengupgrade  monitors , lakukan langkah berikut:  Upgrade paket Ceph untuk setiap daemon atau bisa semua sekaligus:  [stack@ceph1 ~]$ ceph-deploy install --release nautilus ceph-mon  Update juga untuk binary ceph:  [stack@ceph1 ~]$ sudo yum update   sudo yum install ceph  restart  ceph mon services       [stack@ceph1 ~]$  systemctl restart ceph-mon@ceph1   cek monitor ceph:  [stack@ceph1 ~]$  ceph mon stat", 
            "title": "Upgrade Monitors"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#upgrade-osd", 
            "text": "Untuk mengupgrade  osd daemon , lakukan langkah berikut:  Gunakan tool  ceph-deploy  untuk upgrade semua node  OSD  daemon:  [stack@ceph1 ~]$ ceph-deploy install --release nautilus osd0 osd1   Update juga untuk binary ceph:  [stack@ceph1 ~]$ ssh osd0\n[stack@osd0 ~]$ sudo yum update   sudo yum install ceph\n[stack@ceph1 ~]$ ssh osd1\n[stack@osd1 ~]$ sudo yum update   sudo yum install ceph  restart  OSD :  systemctl restart ceph-osd@1\nsystemctl restart ceph-osd@2\nsystemctl restart ceph-osd@3\n\n[stack@ceph1 ~]$ systemctl status ceph-osd@1\n\ufffd ceph-osd@1.service - Ceph object storage daemon osd.1\n   Loaded: loaded (/usr/lib/systemd/system/ceph-osd@.service; enabled-runtime; vendor preset: disabled)\n   Active: active (running) since Tue 2019-08-06 15:39:40 WIB; 24h ago\n  Process: 12624 ExecStartPre=/usr/lib/ceph/ceph-osd-prestart.sh --cluster ${CLUSTER} --id %i (code=exited, status=0/SUCCESS)\n Main PID: 12629 (ceph-osd)\n   CGroup: /system.slice/system-ceph\\x2dosd.slice/ceph-osd@1.service\n           \ufffd\ufffd12629 /usr/bin/ceph-osd -f --cluster ceph --id 1 --setuser ceph --setgroup ceph\n[stack@ceph1 ~]$", 
            "title": "Upgrade OSD"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#upgrade-metadata-server", 
            "text": "jalankan:  [stack@ceph1 ~]$ ceph-deploy install --release nautilus mds0\n[stack@ceph1 ~]$ sudo yum update   sudo yum install ceph-mds\n[stack@ceph1 ~]$ systemctl restart ceph-mgr@ceph1  jika metadata server diinstall satu server dengan ceph-mon. maka langkah ini tidak diperlukan lagi.  sampai dengan disini  ceph  server seharusnya sudah menjadi versi  nautilus . cek dengan command  ceph -s  untuk melihat status cluster.", 
            "title": "Upgrade Metadata Server"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#troubleshoot", 
            "text": "Monitor not have enabled msgr2  Error Log:  Monitor not have enabled msgr2   Jalankan:  ceph mon enable-msgr2  lalu cek lagi  ceph -s   Legacy BlueStore stats reporting detected  Error Log:   How to solve:  repair  OSD  satu per satu:  Contoh:  sudo ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-1/\nsudo ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-2/\nsudo ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-3/    solved:", 
            "title": "Troubleshoot:"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#summary-code", 
            "text": "", 
            "title": "Summary Code"
        }, 
        {
            "location": "/openstack-upgrade-ceph-mimic-ke-nautilus/#binbash", 
            "text": "ceph-deploy install --release nautilus ceph-mon\nsudo yum update -y   sudo yum install ceph -y\nsudo systemctl restart ceph-mon@ceph1\n\n#osd upgrade\nceph-deploy install --release nautilus osd0 osd1\n\n\nssh osd0 \"sudo yum update -y   sudo yum install ceph -y\"\nssh osd1 \"sudo yum update -y   sudo yum install ceph -y\"\n\n\nceph-deploy install --release nautilus mds0\nsudo yum update -y   sudo yum install ceph-mds -y\n\nsystemctl restart ceph-mgr@ceph1\nceph --version\nssh osd0 \"ceph --version\"\nssh osd1 \"ceph --version\"  Ref:   Ceph Docs", 
            "title": "!/bin/bash"
        }, 
        {
            "location": "/openstack-install-with-packstack-puppet/", 
            "text": "OpenStack - Install OpenStack dengan PackStack\n\n\nDalam skenario ini, kita asumsikan kita melakukannya di dalam baremetal server, walaupun tidak sama namun setidaknya mendekati dengan baremetal server. Percobaan kali ini dilakukan diatas mesin kvm Proxmox, dengan nested virtualisation.\n\n\nTopology:\n\n\nTopology sederhana yang akan kita deploy:\n\n\n                                                          +--------------------------+\n                                                          |                          |\n                                                          |                          |\n                                                          |   - Compute (Nova)       |\n                                +-----------------------\n |                          |\n                                |                         |                          |\n+---------------------------+   |                         |                          |\n|                           |   |                         |                          |\n| - Controller              |   |                         +--------------------------+\n| | Compute (Nova)          | +-^\n| | Images Storage (glance) |\n| - Block Storage (cinder)  |\n|                           |\n|                           |\n+---------------------------+\n\n\n\nSecara sederhana Dua bagian diatas adalah Baremetal Server yang akan menjalankan masing-masing services:\n\n\n\n\nBaremetal Controller\n\n\nCompute (nova), untuk komputasi instances.\n\n\nImage Storage (glance), untuk penyimpanan images iso operating system/os.\n\n\nBlock Storage (cinder), sebagai penyimpanan disk yang akan digunakan oleh sistem operasi/os.\n\n\n\n\n\n\n\n\nPada server ini kita akan memakai ip address \n10.10.2.204\n\n\n\n\nBaremetal Compute\n\n\nCompute (nova), untuk komputasi instances.\n\n\n\n\n\n\n\n\nPada server ini kita akan memakai ip address \n10.10.2.202\n\n\nSehingga hasil akhir semua ip address yang akan kita pakai:\n\n\n10.10.2.204 controller compute0\n10.10.2.202 compute1\n\n\n\nKebutuhan\n\n\nMasing-masing server baremetal setidaknya memiliki kapasitas ram yang cukup sebesar 16GB dan Core CPU yang memadai. Karena dalam skenario kali ini kita menggunakan packstack, maka pastikan terlebih dahulu packstack sudah terinstall dengan baik.\n\n\nInstall PackStack\n\n\nPackStack memang dikhususkan untuk distribusi linux CentOs, untuk distribusi debian atau yang lain mungkin bisa menggunakan \nopenstack-ansible\n.\n\n\n$ sudo yum update -y\n$ sudo yum install -y centos-release-openstack-rocky\n$ sudo yum update -y\n$ sudo yum install -y openstack-packstack\n\n\n\nKonfigurasi file PackStack\n\n\nEdit file \npackstack\n . lalu edit sesuai kebutuhan:\n\n\nCONFIG_CONTROLLER_HOST=10.10.2.204\n\n# List the servers on which to install the Compute service.\nCONFIG_COMPUTE_HOSTS=10.10.2.204,10.10.2.202\n\n# List of servers on which to install the network service such as\n# Compute networking (nova network) or OpenStack Networking (neutron).\nCONFIG_NETWORK_HOSTS=10.10.2.204\n\n\n\njika sudah lalu jalankan packstack dengan perintah:\n\n\n# packstack -d --answer-file=gitlab.packstack.openstack.txt)\n\n\n\n\n\ndone.\n\n\nRef:\n\n\nhttps://www.rdoproject.org/install/packstack/", 
            "title": "OpenStack - Install OpenStack dengan PackStack"
        }, 
        {
            "location": "/openstack-install-with-packstack-puppet/#openstack-install-openstack-dengan-packstack", 
            "text": "Dalam skenario ini, kita asumsikan kita melakukannya di dalam baremetal server, walaupun tidak sama namun setidaknya mendekati dengan baremetal server. Percobaan kali ini dilakukan diatas mesin kvm Proxmox, dengan nested virtualisation.", 
            "title": "OpenStack - Install OpenStack dengan PackStack"
        }, 
        {
            "location": "/openstack-install-with-packstack-puppet/#topology", 
            "text": "Topology sederhana yang akan kita deploy:                                                            +--------------------------+\n                                                          |                          |\n                                                          |                          |\n                                                          |   - Compute (Nova)       |\n                                +-----------------------  |                          |\n                                |                         |                          |\n+---------------------------+   |                         |                          |\n|                           |   |                         |                          |\n| - Controller              |   |                         +--------------------------+\n| | Compute (Nova)          | +-^\n| | Images Storage (glance) |\n| - Block Storage (cinder)  |\n|                           |\n|                           |\n+---------------------------+  Secara sederhana Dua bagian diatas adalah Baremetal Server yang akan menjalankan masing-masing services:   Baremetal Controller  Compute (nova), untuk komputasi instances.  Image Storage (glance), untuk penyimpanan images iso operating system/os.  Block Storage (cinder), sebagai penyimpanan disk yang akan digunakan oleh sistem operasi/os.     Pada server ini kita akan memakai ip address  10.10.2.204   Baremetal Compute  Compute (nova), untuk komputasi instances.     Pada server ini kita akan memakai ip address  10.10.2.202  Sehingga hasil akhir semua ip address yang akan kita pakai:  10.10.2.204 controller compute0\n10.10.2.202 compute1", 
            "title": "Topology:"
        }, 
        {
            "location": "/openstack-install-with-packstack-puppet/#kebutuhan", 
            "text": "Masing-masing server baremetal setidaknya memiliki kapasitas ram yang cukup sebesar 16GB dan Core CPU yang memadai. Karena dalam skenario kali ini kita menggunakan packstack, maka pastikan terlebih dahulu packstack sudah terinstall dengan baik.  Install PackStack  PackStack memang dikhususkan untuk distribusi linux CentOs, untuk distribusi debian atau yang lain mungkin bisa menggunakan  openstack-ansible .  $ sudo yum update -y\n$ sudo yum install -y centos-release-openstack-rocky\n$ sudo yum update -y\n$ sudo yum install -y openstack-packstack  Konfigurasi file PackStack  Edit file  packstack  . lalu edit sesuai kebutuhan:  CONFIG_CONTROLLER_HOST=10.10.2.204\n\n# List the servers on which to install the Compute service.\nCONFIG_COMPUTE_HOSTS=10.10.2.204,10.10.2.202\n\n# List of servers on which to install the network service such as\n# Compute networking (nova network) or OpenStack Networking (neutron).\nCONFIG_NETWORK_HOSTS=10.10.2.204  jika sudah lalu jalankan packstack dengan perintah:  # packstack -d --answer-file=gitlab.packstack.openstack.txt)   done.  Ref:  https://www.rdoproject.org/install/packstack/", 
            "title": "Kebutuhan"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/", 
            "text": "How to upgrade Esxi 5.5 to 6.7\n\n\nLangkah ini adalah langkah yang paling mudah untuk upgrade Esxi dari versi 5.5 ke 6.7.\n\n\nProses upgrade:\n\n\n\n\nUpgrade Esxi 5.5 ke versi 6.0\n\n\nUpgrade Esxi 6.0 ke versi 6.5\n\n\nUpgrade Esxi 6.5 ke versi 6.7\n\n\n\n\nRequierements:\n\n\n\n\nenable ssh server host dari Esxi.\n\n\n\n\nUpgrade Esxi 5.5 ke versi 6.0\n\n\nlogin ke host Esxi lalu aktifkan \nmaintenance mode on\n\n\nvim-cmd /hostsvc/maintenanc_mode_enter\n\n\n\njalankan perintah berikut untuk Upgrade:\n\n\nesxcli network firewall ruleset set -e true -r httpClient\nesxcli software profile update -p ESXi-6.0.0-20190904001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\nesxcli network firewall ruleset set -e false -r httpClient\n\n\n\n\n\n\n\nperintah awal adalah membuka firewall untuk koneksi httpclient\n\n\nperintah kedua untuk proses upgrade dengan sistem update profile vib\n\n\nperintah terakhir untuk menutup firewall koneksi httpclient.\n\n\n\n\nketiga perintah tersebut konsep upgrade yang akan kita terapkan sampai proses upgrade ke versi 6.7.\n\n\nhasil proses upgrade ke versi 6.0:\n\n\n\n\nsetelah itu bisa matikan maintenance mode on:\n\n\nvim-cmd /hostsvc/maintenanc_mode_exit\n\n\n\njika ada kendala issue atau error bisa merujuk bagian paling akhir dari halaman ini.\n\n\nUpgrade Esxi 6.0 ke versi 6.5\n\n\nlogin ke host Esxi lalu aktifkan \nmaintenance mode on\n\n\nvim-cmd /hostsvc/maintenanc_mode_enter\n\n\n\njalankan perintah berikut untuk Upgrade:\n\n\nesxcli network firewall ruleset set -e true -r httpClient\nesxcli software profile update -p ESXi-6.5.0-20190804001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\nesxcli network firewall ruleset set -e false -r httpClient\n\n\n\n\n\nhasil proses upgrade versi 6.0\n\n\n\n\nsetelah itu bisa matikan maintenance mode on:\n\n\nvim-cmd /hostsvc/maintenanc_mode_exit\n\n\n\njika ada kendala issue atau error bisa merujuk bagian paling akhir dari halaman ini.\n\n\nUpgrade Esxi 6.0 ke versi 6.7\n\n\nlogin ke host Esxi lalu aktifkan \nmaintenance mode on\n\n\nvim-cmd /hostsvc/maintenanc_mode_enter\n\n\n\njalankan perintah berikut untuk Upgrade:\n\n\nesxcli network firewall ruleset set -e true -r httpClient\nesxcli software profile update -p ESXi-6.7.0-20190802001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\nesxcli network firewall ruleset set -e false -r httpClient\n\n\n\n\n\nhasil proses upgrade versi 6.7\n\n\n\n\nsetelah itu bisa matikan maintenance mode on:\n\n\nvim-cmd /hostsvc/maintenanc_mode_exit\n\n\n\njika ada kendala issue atau error bisa dilihat cara troubleshooting dibawah ini.\n\n\nTroubleshoot\n\n\nError keyword:\n\n\nVIB Mellanox_bootbank_net-mlx4-en_1.9.9.0-1OEM.550.0.0.1331820 requires com.mellanox.mlx4_core-9.2.2.0, but the requirement cannot be satisfied within the ImageProfile\n\n\n\nHow to solve:\n\n\nesxcli software vib remove -n=net-mlx4-en -n=net-mlx4-core\n\n\n\nresults:\n\n\n\n\nError keyword:\n\n\nVMware_locker_tools-light_6.0.0-3.125.14475122', '[Errno 28] No space left on device')\n\n\nHow to solve:\n\n\nDownload vmware light tools vib first dan kemudian jalankan:\n\n\nesxcli software vib install -f -v /vms/volumes/path/location/tmp/VMware_locker_tools-light_6.0.0-3.125.14475122.vib\n\n\n\natau via http client:\n\n\n\n\nresults:\n\n\n\n\nError keyword:\n\n\nDependency VMware locker tools light saat upgrade ke versi 6.5:\n\n\n\n\nHow to solve:\n\n\n\n\nRef:\n\n\n\n\nscaleway community\n\n\nhttps://esxi-patches.v-front.de/ESXi-6.7.0.html", 
            "title": "VMWare  - How to upgrade Esxi 5.5 to 6.7 "
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#how-to-upgrade-esxi-55-to-67", 
            "text": "Langkah ini adalah langkah yang paling mudah untuk upgrade Esxi dari versi 5.5 ke 6.7.  Proses upgrade:   Upgrade Esxi 5.5 ke versi 6.0  Upgrade Esxi 6.0 ke versi 6.5  Upgrade Esxi 6.5 ke versi 6.7   Requierements:   enable ssh server host dari Esxi.", 
            "title": "How to upgrade Esxi 5.5 to 6.7"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#upgrade-esxi-55-ke-versi-60", 
            "text": "login ke host Esxi lalu aktifkan  maintenance mode on  vim-cmd /hostsvc/maintenanc_mode_enter  jalankan perintah berikut untuk Upgrade:  esxcli network firewall ruleset set -e true -r httpClient\nesxcli software profile update -p ESXi-6.0.0-20190904001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\nesxcli network firewall ruleset set -e false -r httpClient    perintah awal adalah membuka firewall untuk koneksi httpclient  perintah kedua untuk proses upgrade dengan sistem update profile vib  perintah terakhir untuk menutup firewall koneksi httpclient.   ketiga perintah tersebut konsep upgrade yang akan kita terapkan sampai proses upgrade ke versi 6.7.  hasil proses upgrade ke versi 6.0:   setelah itu bisa matikan maintenance mode on:  vim-cmd /hostsvc/maintenanc_mode_exit  jika ada kendala issue atau error bisa merujuk bagian paling akhir dari halaman ini.", 
            "title": "Upgrade Esxi 5.5 ke versi 6.0"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#upgrade-esxi-60-ke-versi-65", 
            "text": "login ke host Esxi lalu aktifkan  maintenance mode on  vim-cmd /hostsvc/maintenanc_mode_enter  jalankan perintah berikut untuk Upgrade:  esxcli network firewall ruleset set -e true -r httpClient\nesxcli software profile update -p ESXi-6.5.0-20190804001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\nesxcli network firewall ruleset set -e false -r httpClient   hasil proses upgrade versi 6.0   setelah itu bisa matikan maintenance mode on:  vim-cmd /hostsvc/maintenanc_mode_exit  jika ada kendala issue atau error bisa merujuk bagian paling akhir dari halaman ini.", 
            "title": "Upgrade Esxi 6.0 ke versi 6.5"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#upgrade-esxi-60-ke-versi-67", 
            "text": "login ke host Esxi lalu aktifkan  maintenance mode on  vim-cmd /hostsvc/maintenanc_mode_enter  jalankan perintah berikut untuk Upgrade:  esxcli network firewall ruleset set -e true -r httpClient\nesxcli software profile update -p ESXi-6.7.0-20190802001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\nesxcli network firewall ruleset set -e false -r httpClient   hasil proses upgrade versi 6.7   setelah itu bisa matikan maintenance mode on:  vim-cmd /hostsvc/maintenanc_mode_exit  jika ada kendala issue atau error bisa dilihat cara troubleshooting dibawah ini.", 
            "title": "Upgrade Esxi 6.0 ke versi 6.7"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#troubleshoot", 
            "text": "", 
            "title": "Troubleshoot"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#error-keyword", 
            "text": "VIB Mellanox_bootbank_net-mlx4-en_1.9.9.0-1OEM.550.0.0.1331820 requires com.mellanox.mlx4_core-9.2.2.0, but the requirement cannot be satisfied within the ImageProfile  How to solve:  esxcli software vib remove -n=net-mlx4-en -n=net-mlx4-core  results:", 
            "title": "Error keyword:"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#error-keyword_1", 
            "text": "VMware_locker_tools-light_6.0.0-3.125.14475122', '[Errno 28] No space left on device')  How to solve:  Download vmware light tools vib first dan kemudian jalankan:  esxcli software vib install -f -v /vms/volumes/path/location/tmp/VMware_locker_tools-light_6.0.0-3.125.14475122.vib  atau via http client:   results:", 
            "title": "Error keyword:"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7/#error-keyword_2", 
            "text": "Dependency VMware locker tools light saat upgrade ke versi 6.5:   How to solve:   Ref:   scaleway community  https://esxi-patches.v-front.de/ESXi-6.7.0.html", 
            "title": "Error keyword:"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7-vum/", 
            "text": "How to upgrade Esxi 5.5 to 6.7 with VCenter Update Manager\n\n\nLangkah ini adalah langkah yang paling mudah untuk upgrade Esxi dari versi 5.5 ke 6.7 dengan VCenter Update Manager\nProses upgrade:\n\n\n\n\nUpgrade Esxi 5.5 ke versi 6.5\n\n\nUpgrade Esxi 6.5 ke versi 6.7\n\n\n\n\nRequierements:\n\n\n\n\n\n\nVCenter 6.5\n\n\n\n\nISO ESXi 6.5 \nVMware-VMvisor-Installer-6.5.0.update02-8294253.x86_64.iso\n\n\nISO VCenter 6.5 \nVMware-VCSA-all-6.5.0-4602587.iso\n\n\n\n\n\n\n\n\nVCenter 6.7\n\n\n\n\nISO ESxi 6.7 \nVMware-VMvisor-Installer-6.7.0.update02-13006603.x86_64.iso\n\n\nISO VCenter 6.7 \nVMware-VCSA-all-6.7.0-14367737.iso\n\n\n\n\n\n\n\n\nUpgrade Esxi 5.5 ke versi 6.5\n\n\nInstall ESXi 6.5\n\n\nInstall ESXi 6.5 seperti biasa:\n\n\nlalu install VCenter 6.5 dg custom date client installer: \n17 Nov 2016\n dan Host ESXi dengan date: \n17 Nov 2016\n\n\n\n\npastikan VCenter 6.5 running well, bisa diakses via ui dan flash\n\n\n\nbisa menambahkan host esxi di datacenter,dll:\n\n\n\n\nuntuk keperluan akses vcenter, sesuaikan dns, fqdn dengan ip address yg dibutuhkan.\n\n\nProses Upgrade ESXi 5.5 ke 6.5\n\n\nKlik Host yang akan diupgrade lalu cari menu \nUpdate Manager\n, terus klik `Go To Admin View\", klik \"Import Image ESXi\":\n\n\n\n\nSetelah terupload, \nCreate Baseline\n:\n\n\n\n\n\n\nSetelah itu klik next sampai selesai, klik  \nCompliance View\n\n\nklik \nAttach Baseline\n, dan klik upgrade Baseline\n\n\n\n\nlalu scan Upgrade:\n\n\n\n\nlangkah terakhir \nRemediate\n:\n\n\n\n\nCompleted:\n\n\n\n\n\n\nUpgrade Esxi 6.5 ke versi 6.7\n\n\nInstall ESXi 6.7\n\n\nInstall ESXi 6.7 seperti biasa:\n\n\n\n\nlalu install VCenter 6.7 sampai running well:\n\n\n\n\nProses Upgrade ESXi 6.5 ke 6.7\n\n\nUpload ISO Image 6.7 dengan cara seperti pada langkah upgrade 5.5 ke 6.5:\n\n\n\n\nSetelah ISO Image terupload, lakukan \ncreate new baseline\n, lalu \nattach\n, \nscan\n, dan yang terakhir \nremediate\n:\n\n\n\n\nHasil completed setelah berhasil upgrade:\n\n\n\n\nRef:\n\n\n\n\nhttp://www.itingredients.com/add-vmware-esxi-host-vcenter-6/\n\n\nhttps://nolabnoparty.com/en/esxi-upgrade-from-5-5-to-6-5-conflicting-vibs-with-hpe-image/\n\n\nhttps://nolabnoparty.com/en/vmware-esxi-5-5-upgrade-to-6-0-with-vum/\n\n\nhttp://www.virtubytes.com/2017/03/24/upgrade-esxi-6-5-using-update-manager/\n\n\n\n\nThis license isn\u2019t use for commercial purposes. Please buy a license if you can!\n\n\n\n\nvCenter: 0A0FF-403EN-RZ848-ZH3QH-2A73P\n\n\nvSphere: JV425-4h100-vzhh8-q23np-3a9pp\n\n\n\n\nVMware vSpher 5.0 Enterprise Plus (Unlimited CPU)\n\n\n\n\nJA46K-4M1EQ-YZ581-PU2N4-2C81V\n\n\n1Y0ZK-AA25J-PZFJ0-GUAZM-23WJ3\n\n\nNY0KH-FJL93-TZFG1-LA1G4-02T0E\n\n\n\n\nVMware vSpher 5.0 Enterprise Plus (Unlimited VM)\n\n\n\n\n0G03V-2F1EL-ZZCY8-QT27P-93421\n\n\n1F0RM-2HL8N-4ZKP1-J185K-1AT2L\n\n\nMV2JW-090E5-KZP19-D02Z4-A325U", 
            "title": "VMWare  - How to upgrade Esxi 5.5 to 6.7 with VCenter Update Manager"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7-vum/#how-to-upgrade-esxi-55-to-67-with-vcenter-update-manager", 
            "text": "Langkah ini adalah langkah yang paling mudah untuk upgrade Esxi dari versi 5.5 ke 6.7 dengan VCenter Update Manager\nProses upgrade:   Upgrade Esxi 5.5 ke versi 6.5  Upgrade Esxi 6.5 ke versi 6.7   Requierements:    VCenter 6.5   ISO ESXi 6.5  VMware-VMvisor-Installer-6.5.0.update02-8294253.x86_64.iso  ISO VCenter 6.5  VMware-VCSA-all-6.5.0-4602587.iso     VCenter 6.7   ISO ESxi 6.7  VMware-VMvisor-Installer-6.7.0.update02-13006603.x86_64.iso  ISO VCenter 6.7  VMware-VCSA-all-6.7.0-14367737.iso", 
            "title": "How to upgrade Esxi 5.5 to 6.7 with VCenter Update Manager"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7-vum/#upgrade-esxi-55-ke-versi-65", 
            "text": "Install ESXi 6.5  Install ESXi 6.5 seperti biasa:  lalu install VCenter 6.5 dg custom date client installer:  17 Nov 2016  dan Host ESXi dengan date:  17 Nov 2016   pastikan VCenter 6.5 running well, bisa diakses via ui dan flash  bisa menambahkan host esxi di datacenter,dll:   untuk keperluan akses vcenter, sesuaikan dns, fqdn dengan ip address yg dibutuhkan.  Proses Upgrade ESXi 5.5 ke 6.5  Klik Host yang akan diupgrade lalu cari menu  Update Manager , terus klik `Go To Admin View\", klik \"Import Image ESXi\":   Setelah terupload,  Create Baseline :    Setelah itu klik next sampai selesai, klik   Compliance View  klik  Attach Baseline , dan klik upgrade Baseline   lalu scan Upgrade:   langkah terakhir  Remediate :   Completed:", 
            "title": "Upgrade Esxi 5.5 ke versi 6.5"
        }, 
        {
            "location": "/vmware-esxi-upgrade-5.5-to-6.7-vum/#upgrade-esxi-65-ke-versi-67", 
            "text": "Install ESXi 6.7  Install ESXi 6.7 seperti biasa:   lalu install VCenter 6.7 sampai running well:   Proses Upgrade ESXi 6.5 ke 6.7  Upload ISO Image 6.7 dengan cara seperti pada langkah upgrade 5.5 ke 6.5:   Setelah ISO Image terupload, lakukan  create new baseline , lalu  attach ,  scan , dan yang terakhir  remediate :   Hasil completed setelah berhasil upgrade:   Ref:   http://www.itingredients.com/add-vmware-esxi-host-vcenter-6/  https://nolabnoparty.com/en/esxi-upgrade-from-5-5-to-6-5-conflicting-vibs-with-hpe-image/  https://nolabnoparty.com/en/vmware-esxi-5-5-upgrade-to-6-0-with-vum/  http://www.virtubytes.com/2017/03/24/upgrade-esxi-6-5-using-update-manager/   This license isn\u2019t use for commercial purposes. Please buy a license if you can!   vCenter: 0A0FF-403EN-RZ848-ZH3QH-2A73P  vSphere: JV425-4h100-vzhh8-q23np-3a9pp   VMware vSpher 5.0 Enterprise Plus (Unlimited CPU)   JA46K-4M1EQ-YZ581-PU2N4-2C81V  1Y0ZK-AA25J-PZFJ0-GUAZM-23WJ3  NY0KH-FJL93-TZFG1-LA1G4-02T0E   VMware vSpher 5.0 Enterprise Plus (Unlimited VM)   0G03V-2F1EL-ZZCY8-QT27P-93421  1F0RM-2HL8N-4ZKP1-J185K-1AT2L  MV2JW-090E5-KZP19-D02Z4-A325U", 
            "title": "Upgrade Esxi 6.5 ke versi 6.7"
        }, 
        {
            "location": "/Patch-Upgrade-ESXi-15018017-to-latest-build/", 
            "text": "Cara Patch Upgrade ESXi 15018017 ke latest version\n\n\nPada Upgrade kali ini kita akan melakukan dari versi \n15018017\n ke latest version saat ini \n15160138\n. sesuai referensi \nhttps://docs.vmware.com/en/VMware-vSphere/6.7/rn/esxi670-201912001.html\n, maka ada 2 tahapan:\n\n\n\n\n\n\nUpgrade dari build \n#15018017\n ke build \n#15160134\n.\n\n\nBuka Firewall dahulu untuk membukak koneksi http:\n\n\nesxcli network firewall ruleset set -e true -r httpClient\n\n\n\nlakukan patch upgrade ke versi \nbuild 15160134\n.\n\n\nesxcli software profile update -p ESXi-6.7.0-20191201001s-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\n\n\n\nsetelah patch selesai lalu reboot.\n\n\n\n\n\n\nUpgrade dari build \n#15160134\n ke build \n#15160138\n\n\nesxcli software profile update -p ESXi-6.7.0-20191204001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml\n\n\n\nreboot untuk applied.\n\n\ntutup koneksi http:\n\n\nesxcli network firewall ruleset set -e false -r httpClient\n\n\n\ncheck version untuk make sure:\n\n\n\n\n\n\n\n\nselesai", 
            "title": "VMWare - Patch Upgrade ESXi 15018017 ke latest version"
        }, 
        {
            "location": "/Patch-Upgrade-ESXi-15018017-to-latest-build/#cara-patch-upgrade-esxi-15018017-ke-latest-version", 
            "text": "Pada Upgrade kali ini kita akan melakukan dari versi  15018017  ke latest version saat ini  15160138 . sesuai referensi  https://docs.vmware.com/en/VMware-vSphere/6.7/rn/esxi670-201912001.html , maka ada 2 tahapan:    Upgrade dari build  #15018017  ke build  #15160134 .  Buka Firewall dahulu untuk membukak koneksi http:  esxcli network firewall ruleset set -e true -r httpClient  lakukan patch upgrade ke versi  build 15160134 .  esxcli software profile update -p ESXi-6.7.0-20191201001s-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml  setelah patch selesai lalu reboot.    Upgrade dari build  #15160134  ke build  #15160138  esxcli software profile update -p ESXi-6.7.0-20191204001-standard \\\n-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml  reboot untuk applied.  tutup koneksi http:  esxcli network firewall ruleset set -e false -r httpClient  check version untuk make sure:     selesai", 
            "title": "Cara Patch Upgrade ESXi 15018017 ke latest version"
        }, 
        {
            "location": "/proxmox-extend-lvm-partition/", 
            "text": "Proxmox - How to extend LVM Partition on Proxmox\n\n\ncase: \nlv_root akan diextend dari 40GB menjadi 50GB\n\n\nSiapkan CD Image ISO Centos atau yang lain dan setup ke boot order. Setelah itu tambahkan disk ke dalam guest vm proxmox dan jangan lupa dibuat partisi dengan tipe lvm (8e).\n\n\nlalu ikuti command berikut:\n\n\nCreate Phisical Volume\n\n\n    pvcreate /dev/sdb1\n\n\n\ncek dengan perintah \npvs\n.\n\n\nExtend Root Partition Volume Group\n\n\n    vgextend vg_cpan1 /dev/sdb1\n\n\n\ndimana vg_cpan1 adalah nama volume group lvm yang akan diextend\n\n\nsetelah extend berhasil langkah selanjutnya adalah mengalokasikan disk free dalam volume group kedalam partisi logical volume.\n\n\nAllocate Logical Volume\n\n\ncek dulu dengan perintah \nlvdisplay\n\n\n    lvdisplay\n    ...8\n...\n\n    Free  PE / Size       xxxx / yyyy\n\n    ...8\n...cut\n\n\n\nalokasikan dengan perintah\n\n\n    lvextend -l +xxxx /dev/vg_cpan1/lv_root\n\n\n\nsetelah sukses extend filesystem os agar sesuai dengan logical volume. reboot dahulu dan jalankan perintah no 4 langsung on the fly os.\n\n\nAllocate / Resize Filesystem\n\n\n    resize2fs /dev/vg_cpan1/lv_root\n\n\n\nresults:\n\n\n\n\nref: \ntechmint", 
            "title": "Proxmox - How to extend LVM Partition on Proxmox"
        }, 
        {
            "location": "/proxmox-extend-lvm-partition/#proxmox-how-to-extend-lvm-partition-on-proxmox", 
            "text": "case:  lv_root akan diextend dari 40GB menjadi 50GB  Siapkan CD Image ISO Centos atau yang lain dan setup ke boot order. Setelah itu tambahkan disk ke dalam guest vm proxmox dan jangan lupa dibuat partisi dengan tipe lvm (8e).  lalu ikuti command berikut:  Create Phisical Volume      pvcreate /dev/sdb1  cek dengan perintah  pvs .  Extend Root Partition Volume Group      vgextend vg_cpan1 /dev/sdb1  dimana vg_cpan1 adalah nama volume group lvm yang akan diextend  setelah extend berhasil langkah selanjutnya adalah mengalokasikan disk free dalam volume group kedalam partisi logical volume.  Allocate Logical Volume  cek dulu dengan perintah  lvdisplay      lvdisplay\n    ...8 ...\n\n    Free  PE / Size       xxxx / yyyy\n\n    ...8 ...cut  alokasikan dengan perintah      lvextend -l +xxxx /dev/vg_cpan1/lv_root  setelah sukses extend filesystem os agar sesuai dengan logical volume. reboot dahulu dan jalankan perintah no 4 langsung on the fly os.  Allocate / Resize Filesystem      resize2fs /dev/vg_cpan1/lv_root  results:   ref:  techmint", 
            "title": "Proxmox - How to extend LVM Partition on Proxmox"
        }, 
        {
            "location": "/promox-extend-lvm-partition-ofly/", 
            "text": "Promox - How to extend LVM Partition VM Proxmox on the Fly\n\n\nat \nprevious\n tutorial, we've been extended lvm partition vm on promox with Live CD by using add new disk. But now, we can extend lvm partition on the fly without live cd or reboot the system, by resize lvm size only.\n\n\nRequierement:\n\n\n1. Use XFS as Filesystem at VM.\n\nAs far i know, only XFS filesystem can doing this method.\n\n\n\nConfigure\n\n\nResize Disk VM via qm cli\n\n\nroot@alpha:~# qm list\n  VMID NAME                 STATUS     MEM(MB)    BOOTDISK(GB) PID\n   201 alpha                stopped    8196              32.00 0\nroot@alpha:~# qm resize 201 scsi0 +168G\nImage resized.\nroot@alpha:~#\nroot@alpha:~# qm list\n      VMID NAME                 STATUS     MEM(MB)    BOOTDISK(GB) PID\n       201 alpha                stopped    8196             200.00 0\nroot@alpha:~#\n\n\n\nResize Partition\n\n\n[root@localhost ~]# parted /dev/sda\nGNU Parted 3.1\nUsing /dev/sda\nWelcome to GNU Parted! Type 'help' to view a list of commands.\n(parted) print\nModel: QEMU QEMU HARDDISK (scsi)\nDisk /dev/sda: 215GB\nSector size (logical/physical): 512B/512B\nPartition Table: msdos\nDisk Flags:\n\nNumber  Start   End     Size    Type     File system  Flags\n 1      1049kB  1075MB  1074MB  primary  xfs          boot\n 2      1075MB  34.4GB  33.3GB  primary               lvm\n\n(parted) resizepart 2 100%\n(parted) print\nModel: QEMU QEMU HARDDISK (scsi)\nDisk /dev/sda: 215GB\nSector size (logical/physical): 512B/512B\nPartition Table: msdos\nDisk Flags:\n\nNumber  Start   End     Size    Type     File system  Flags\n 1      1049kB  1075MB  1074MB  primary  xfs          boot\n 2      1075MB  215GB   214GB   primary               lvm\n\n(parted) quit\n\n[root@localhost ~]#\n\n\n\nShow current disk at VM\n\n\n[root@localhost ~]# df -h\nFilesystem               Size  Used Avail Use% Mounted on\n/dev/mapper/centos-root   30G  1.1G   29G   4% /\ndevtmpfs                 3.9G     0  3.9G   0% /dev\ntmpfs                    3.9G     0  3.9G   0% /dev/shm\ntmpfs                    3.9G  8.5M  3.9G   1% /run\ntmpfs                    3.9G     0  3.9G   0% /sys/fs/cgroup\n/dev/sda1               1014M  142M  873M  14% /boot\ntmpfs                    783M     0  783M   0% /run/user/1000\n[root@localhost ~]#\n\n\n\nshow current Phisycal Volume\n\n\n[root@localhost ~]# pvdisplay\n  --- Physical volume ---\n  PV Name               /dev/sda2\n  VG Name               centos\n  PV Size               \n31.00 GiB / not usable 3.00 MiB\n  Allocatable           yes (but full)\n  PE Size               4.00 MiB\n  Total PE              7935\n  Free PE               0\n  Allocated PE          7935\n  PV UUID               dWzC8B-TkO9-hiHN-Oodx-8c2d-6nzQ-zrJfGN\n\n[root@localhost ~]#\n\n\n\nResize Phisycal Volume\n\n\n[root@localhost ~]# pvresize /dev/sda2\n  Physical volume \"/dev/sda2\" changed\n  1 physical volume(s) resized / 0 physical volume(s) not resized\n[root@localhost ~]# \n[root@localhost ~]# pvdisplay\n  --- Physical volume ---\n  PV Name               /dev/sda2\n  VG Name               centos\n  PV Size               \n199.00 GiB / not usable 2.00 MiB\n  Allocatable           yes\n  PE Size               4.00 MiB\n  Total PE              50943\n  Free PE               43008\n  Allocated PE          7935\n  PV UUID               dWzC8B-TkO9-hiHN-Oodx-8c2d-6nzQ-zrJfGN\n\n[root@localhost ~]#\n\n\n\nResize Logical Volume\n\n\n[root@localhost ~]# lvresize --extents +100%FREE --resizefs /dev/centos/root\n  Size of logical volume centos/root changed from \n30.00 GiB (7679 extents) to \n198.00 GiB (50687 extents).\n  Logical volume centos/root successfully resized.\nmeta-data=/dev/mapper/centos-root isize=512    agcount=5, agsize=1965568 blks\n         =                       sectsz=512   attr=2, projid32bit=1\n         =                       crc=1        finobt=0 spinodes=0\ndata     =                       bsize=4096   blocks=7863296, imaxpct=25\n         =                       sunit=0      swidth=0 blks\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\nlog      =internal               bsize=4096   blocks=3839, version=2\n         =                       sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none                   extsz=4096   blocks=0, rtextents=0\ndata blocks changed from 7863296 to 51903488\n[root@localhost ~]#\n\n\n\nTest\n\n\nshow current disk\n\n\n[root@localhost ~]# df -Th\nFilesystem              Type      Size  Used Avail Use% Mounted on\n/dev/mapper/centos-root xfs       198G  1.1G  197G   1% /\ndevtmpfs                devtmpfs  3.9G     0  3.9G   0% /dev\ntmpfs                   tmpfs     3.9G     0  3.9G   0% /dev/shm\ntmpfs                   tmpfs     3.9G  8.5M  3.9G   1% /run\ntmpfs                   tmpfs     3.9G     0  3.9G   0% /sys/fs/cgroup\n/dev/sda1               xfs      1014M  142M  873M  14% /boot\ntmpfs                   tmpfs     783M     0  783M   0% /run/user/1000\n[root@localhost ~]#\n\n\n\ndisk partition centos-root mapper now changed from 30GB to 198GB. yay !", 
            "title": "Promox - How to extend LVM Partition VM Proxmox on the Fly"
        }, 
        {
            "location": "/promox-extend-lvm-partition-ofly/#promox-how-to-extend-lvm-partition-vm-proxmox-on-the-fly", 
            "text": "at  previous  tutorial, we've been extended lvm partition vm on promox with Live CD by using add new disk. But now, we can extend lvm partition on the fly without live cd or reboot the system, by resize lvm size only.", 
            "title": "Promox - How to extend LVM Partition VM Proxmox on the Fly"
        }, 
        {
            "location": "/promox-extend-lvm-partition-ofly/#requierement", 
            "text": "1. Use XFS as Filesystem at VM.\n\nAs far i know, only XFS filesystem can doing this method.", 
            "title": "Requierement:"
        }, 
        {
            "location": "/promox-extend-lvm-partition-ofly/#configure", 
            "text": "Resize Disk VM via qm cli  root@alpha:~# qm list\n  VMID NAME                 STATUS     MEM(MB)    BOOTDISK(GB) PID\n   201 alpha                stopped    8196              32.00 0\nroot@alpha:~# qm resize 201 scsi0 +168G\nImage resized.\nroot@alpha:~#\nroot@alpha:~# qm list\n      VMID NAME                 STATUS     MEM(MB)    BOOTDISK(GB) PID\n       201 alpha                stopped    8196             200.00 0\nroot@alpha:~#  Resize Partition  [root@localhost ~]# parted /dev/sda\nGNU Parted 3.1\nUsing /dev/sda\nWelcome to GNU Parted! Type 'help' to view a list of commands.\n(parted) print\nModel: QEMU QEMU HARDDISK (scsi)\nDisk /dev/sda: 215GB\nSector size (logical/physical): 512B/512B\nPartition Table: msdos\nDisk Flags:\n\nNumber  Start   End     Size    Type     File system  Flags\n 1      1049kB  1075MB  1074MB  primary  xfs          boot\n 2      1075MB  34.4GB  33.3GB  primary               lvm\n\n(parted) resizepart 2 100%\n(parted) print\nModel: QEMU QEMU HARDDISK (scsi)\nDisk /dev/sda: 215GB\nSector size (logical/physical): 512B/512B\nPartition Table: msdos\nDisk Flags:\n\nNumber  Start   End     Size    Type     File system  Flags\n 1      1049kB  1075MB  1074MB  primary  xfs          boot\n 2      1075MB  215GB   214GB   primary               lvm\n\n(parted) quit\n\n[root@localhost ~]#  Show current disk at VM  [root@localhost ~]# df -h\nFilesystem               Size  Used Avail Use% Mounted on\n/dev/mapper/centos-root   30G  1.1G   29G   4% /\ndevtmpfs                 3.9G     0  3.9G   0% /dev\ntmpfs                    3.9G     0  3.9G   0% /dev/shm\ntmpfs                    3.9G  8.5M  3.9G   1% /run\ntmpfs                    3.9G     0  3.9G   0% /sys/fs/cgroup\n/dev/sda1               1014M  142M  873M  14% /boot\ntmpfs                    783M     0  783M   0% /run/user/1000\n[root@localhost ~]#  show current Phisycal Volume  [root@localhost ~]# pvdisplay\n  --- Physical volume ---\n  PV Name               /dev/sda2\n  VG Name               centos\n  PV Size                31.00 GiB / not usable 3.00 MiB\n  Allocatable           yes (but full)\n  PE Size               4.00 MiB\n  Total PE              7935\n  Free PE               0\n  Allocated PE          7935\n  PV UUID               dWzC8B-TkO9-hiHN-Oodx-8c2d-6nzQ-zrJfGN\n\n[root@localhost ~]#  Resize Phisycal Volume  [root@localhost ~]# pvresize /dev/sda2\n  Physical volume \"/dev/sda2\" changed\n  1 physical volume(s) resized / 0 physical volume(s) not resized\n[root@localhost ~]# \n[root@localhost ~]# pvdisplay\n  --- Physical volume ---\n  PV Name               /dev/sda2\n  VG Name               centos\n  PV Size                199.00 GiB / not usable 2.00 MiB\n  Allocatable           yes\n  PE Size               4.00 MiB\n  Total PE              50943\n  Free PE               43008\n  Allocated PE          7935\n  PV UUID               dWzC8B-TkO9-hiHN-Oodx-8c2d-6nzQ-zrJfGN\n\n[root@localhost ~]#  Resize Logical Volume  [root@localhost ~]# lvresize --extents +100%FREE --resizefs /dev/centos/root\n  Size of logical volume centos/root changed from  30.00 GiB (7679 extents) to  198.00 GiB (50687 extents).\n  Logical volume centos/root successfully resized.\nmeta-data=/dev/mapper/centos-root isize=512    agcount=5, agsize=1965568 blks\n         =                       sectsz=512   attr=2, projid32bit=1\n         =                       crc=1        finobt=0 spinodes=0\ndata     =                       bsize=4096   blocks=7863296, imaxpct=25\n         =                       sunit=0      swidth=0 blks\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\nlog      =internal               bsize=4096   blocks=3839, version=2\n         =                       sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none                   extsz=4096   blocks=0, rtextents=0\ndata blocks changed from 7863296 to 51903488\n[root@localhost ~]#", 
            "title": "Configure"
        }, 
        {
            "location": "/promox-extend-lvm-partition-ofly/#test", 
            "text": "show current disk  [root@localhost ~]# df -Th\nFilesystem              Type      Size  Used Avail Use% Mounted on\n/dev/mapper/centos-root xfs       198G  1.1G  197G   1% /\ndevtmpfs                devtmpfs  3.9G     0  3.9G   0% /dev\ntmpfs                   tmpfs     3.9G     0  3.9G   0% /dev/shm\ntmpfs                   tmpfs     3.9G  8.5M  3.9G   1% /run\ntmpfs                   tmpfs     3.9G     0  3.9G   0% /sys/fs/cgroup\n/dev/sda1               xfs      1014M  142M  873M  14% /boot\ntmpfs                   tmpfs     783M     0  783M   0% /run/user/1000\n[root@localhost ~]#  disk partition centos-root mapper now changed from 30GB to 198GB. yay !", 
            "title": "Test"
        }, 
        {
            "location": "/postfix-build-native-smtp-server-dengan-support-submission-authentication/", 
            "text": "Postfix - Build native Postix smtp server dengan support submission authentication\n\n\nPada langkah ini kita mencoba membangun native smtp server dengan postfix yang \ndisupport autentikasi dengan metode submission atau via port 587. Dan pada percobaan \nkali ini menggunakan CentOs 6, postfix biasanya sudah terinstall secara default. \njika belum terinstall, bisa diinstall dengan perintah yum install postfix.\n\n\nKonfigurasi Main.cf\n\n\nrelay_domains =\nhome_mailbox = Maildir/\nmydomain = nws1.coabc.co.id\nsmtpd_use_tls = yes\nsmtpd_tls_key_file = /root/coabc.co.id/coabc.co.id.key\nsmtpd_tls_cert_file = /root/coabc.co.id/chained.crt\nsmtpd_tls_auth_only=yes\nsmtp_tls_security_level=may\nsmtpd_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtpd_tls_protocols = !SSLv2, !SSLv3\nsmtp_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtp_tls_protocols = !SSLv2, !SSLv3\n\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\nmailbox_size_limit = 256000000\nmyorigin = coabc.co.id\nmyhostname = coabc.co.id\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128 10.15.0.6 1x.x.x 10.x.x.179\nmydestination = newsletter.coabc.co.id, localhost.localdomain, localhost\nrecipient_delimiter = +\ninet_interfaces = all\n\n\n\ntambahkan user untuk account smtp:\n\n\nadduser uuuuu\n\n\n\nset password:\n\n\npasswd pppp\n\n\n\nganti shell account diatas agar tidak bisa login ke console:\n\n\nchsh -s /sbin/nologin uuuuu\n\n\n\ntambahkan opsi submission di master.cf\n\n\nsubmission inet n       -       n       -       -       smtpd\n  -o smtpd_tls_security_level=encrypt\n  -o smtpd_sasl_auth_enable=yes\n  -o smtpd_reject_unlisted_sender=yes\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o broken_sasl_auth_clients=yes\n  -o smtpd_client_restrictions=permit_sasl_authenticated,reject\n\n\n\nfinal konfig master.cf:\n\n\nsmtp      inet  n       -       n       -       -       smtpd\nsubmission inet n       -       n       -       -       smtpd\n  -o smtpd_tls_security_level=encrypt\n  -o smtpd_sasl_auth_enable=yes\n  -o smtpd_reject_unlisted_sender=yes\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o broken_sasl_auth_clients=yes\n  -o smtpd_client_restrictions=permit_sasl_authenticated,reject\npickup    fifo  n       -       n       60      1       pickup\ncleanup   unix  n       -       n       -       0       cleanup\nqmgr      fifo  n       -       n       300     1       qmgr\ntlsmgr    unix  -       -       n       1000?   1       tlsmgr\nrewrite   unix  -       -       n       -       -       trivial-rewrite\nbounce    unix  -       -       n       -       0       bounce\ndefer     unix  -       -       n       -       0       bounce\ntrace     unix  -       -       n       -       0       bounce\nverify    unix  -       -       n       -       1       verify\nflush     unix  n       -       n       1000?   0       flush\nproxymap  unix  -       -       n       -       -       proxymap\nproxywrite unix -       -       n       -       1       proxymap\nsmtp      unix  -       -       n       -       -       smtp\nrelay     unix  -       -       n       -       -       smtp\n    -o smtp_fallback_relay=\nshowq     unix  n       -       n       -       -       showq\nerror     unix  -       -       n       -       -       error\nretry     unix  -       -       n       -       -       error\ndiscard   unix  -       -       n       -       -       discard\nlocal     unix  -       n       n       -       -       local\nvirtual   unix  -       n       n       -       -       virtual\nlmtp      unix  -       -       n       -       -       lmtp\nanvil     unix  -       -       n       -       1       anvil\nscache    unix  -       -       n       -       1       scache\n\n\n\ninstall cyrus sasl support plain tex dan md5t:\n\n\nyum install cyrus-sasl-md5 cyrus-sasl-plain\n\n\n\nkonfig smtpd.conf \n\n\nvim /etc/sasl2/smtpd.conf\npwcheck_method: saslauthd\nmech_list: plain login\n\n\n\nrestart postfix dan saslauth daemon:\n\n\nservice saslauthd restart;service postfix restart\n\n\n\nlalu test dengan php mailer (github.com/PHPMailer/PHPMailer)\n\n\n?php\n\n//require_once('class.phpmailer.php');\n\nrequire 'PHPMailerAutoload.php';\n\n$mail = new PHPMailer(); // create a new object\n$mail-\nIsSMTP(); // enable SMTP\n$mail-\nSMTPDebug = 1; // debugging: 1 = errors and messages, 2 = messages only\n$mail-\nSMTPAuth = true; // authentication enabled\n//$mail-\nSMTPSecure = ''; // secure transfer enabled REQUIRED for GMail\n$mail-\nHost = \"nws1.coabc.co.id\";\n$mail-\nPort = 587; // or 587\n$mail-\nIsHTML(true);\n//$mail-\nUsername = \"dian@infra.abc.co.id\";\n//$mail-\nUsername = \"oksoft@infra.abc.co.id\";\n$mail-\nUsername = \"userid\";\n//$mail-\nPassword = \"\";\n$mail-\nPassword = \"%pass\";\n$mail-\nSetFrom(\"noreply@coabc.co.id\");\n$mail-\nSender=\"newsletter@coabc.co.id\";\n$mail-\nSubject = \"Maju ED Lisensi\";\n$mail-\nBody = \"Mohon Maju ED Lisensi, 23 Agustus 2016 ; dikarenakan belum melakukan pembayaran royalty Juli 2016\\n\\n\nTerima Kasih\\n\n\";\n$mail-\nAddAddress(\"user@abc.co.id\");\n if(!$mail-\nSend())\n    {\n    echo \"Mailer Error: \" . $mail-\nErrorInfo;\n    }\n    else\n    {\n    echo \"Message has been sent\";\n    }\n?\n\n\n\n\njalankan via php cli:\n\n\ndgp@it-infra ~/Downloads/PHPMailer-master $ php nws1.apotekk24coid.php \n2016-08-23 03:07:06 CLIENT -\n SERVER: EHLO it-infra\n2016-08-23 03:07:06 CLIENT -\n SERVER: STARTTLS\n2016-08-23 03:07:06 CLIENT -\n SERVER: EHLO it-infra\n2016-08-23 03:07:06 CLIENT -\n SERVER: AUTH LOGIN\n2016-08-23 03:07:07 CLIENT -\n SERVER: ZVFK\n2016-08-23 03:07:07 CLIENT -\n SERVER: OFI=\n2016-08-23 03:07:07 CLIENT -\n SERVER: MAIL FROM:\nnewsletter@coabc.co.id\n\n2016-08-23 03:07:07 CLIENT -\n SERVER: RCPT TO:\nuser@abc.co.id\n\n2016-08-23 03:07:07 CLIENT -\n SERVER: DATA\n2016-08-23 03:07:07 CLIENT -\n SERVER: Date: Tue, 23 Aug 2016 11:07:05 +0800\n2016-08-23 03:07:07 CLIENT -\n SERVER: To: user@abc.co.id\n2016-08-23 03:07:07 CLIENT -\n SERVER: From: noreply@coabc.co.id\n2016-08-23 03:07:07 CLIENT -\n SERVER: Subject: Maju ED Lisensi\n2016-08-23 03:07:07 CLIENT -\n SERVER: Message-ID: \n7386bf71ad887e332566581c7aab9e5d@it-infra\n\n2016-08-23 03:07:07 CLIENT -\n SERVER: X-Mailer: PHPMailer 5.2.13 (https://github.com/PHPMailer/PHPMailer)\n2016-08-23 03:07:07 CLIENT -\n SERVER: MIME-Version: 1.0\n2016-08-23 03:07:07 CLIENT -\n SERVER: Content-Type: text/html; charset=iso-8859-1\n2016-08-23 03:07:07 CLIENT -\n SERVER: Content-Transfer-Encoding: 8bit\n2016-08-23 03:07:07 CLIENT -\n SERVER:\n2016-08-23 03:07:07 CLIENT -\n SERVER: Mohon Maju ED Lisensi, 23 Agustus 2016 ; dikarenakan belum melakukan pembayaran royalty Juli 2016\n2016-08-23 03:07:07 CLIENT -\n SERVER:\n2016-08-23 03:07:07 CLIENT -\n SERVER:\n2016-08-23 03:07:07 CLIENT -\n SERVER: Terima Kasih\n2016-08-23 03:07:07 CLIENT -\n SERVER:\n2016-08-23 03:07:07 CLIENT -\n SERVER:\n2016-08-23 03:07:07 CLIENT -\n SERVER: .\n2016-08-23 03:07:07 CLIENT -\n SERVER: QUIT\nMessage has been sent\ndgp@it-infra ~/Downloads/PHPMailer-master $\n\n\n\ndone.", 
            "title": "Postfix - Build native Postix smtp server dengan support submission authentication"
        }, 
        {
            "location": "/postfix-build-native-smtp-server-dengan-support-submission-authentication/#postfix-build-native-postix-smtp-server-dengan-support-submission-authentication", 
            "text": "Pada langkah ini kita mencoba membangun native smtp server dengan postfix yang \ndisupport autentikasi dengan metode submission atau via port 587. Dan pada percobaan \nkali ini menggunakan CentOs 6, postfix biasanya sudah terinstall secara default. \njika belum terinstall, bisa diinstall dengan perintah yum install postfix.", 
            "title": "Postfix - Build native Postix smtp server dengan support submission authentication"
        }, 
        {
            "location": "/postfix-build-native-smtp-server-dengan-support-submission-authentication/#konfigurasi-maincf", 
            "text": "relay_domains =\nhome_mailbox = Maildir/\nmydomain = nws1.coabc.co.id\nsmtpd_use_tls = yes\nsmtpd_tls_key_file = /root/coabc.co.id/coabc.co.id.key\nsmtpd_tls_cert_file = /root/coabc.co.id/chained.crt\nsmtpd_tls_auth_only=yes\nsmtp_tls_security_level=may\nsmtpd_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtpd_tls_protocols = !SSLv2, !SSLv3\nsmtp_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtp_tls_protocols = !SSLv2, !SSLv3\n\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\nmailbox_size_limit = 256000000\nmyorigin = coabc.co.id\nmyhostname = coabc.co.id\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128 10.15.0.6 1x.x.x 10.x.x.179\nmydestination = newsletter.coabc.co.id, localhost.localdomain, localhost\nrecipient_delimiter = +\ninet_interfaces = all  tambahkan user untuk account smtp:  adduser uuuuu  set password:  passwd pppp  ganti shell account diatas agar tidak bisa login ke console:  chsh -s /sbin/nologin uuuuu  tambahkan opsi submission di master.cf  submission inet n       -       n       -       -       smtpd\n  -o smtpd_tls_security_level=encrypt\n  -o smtpd_sasl_auth_enable=yes\n  -o smtpd_reject_unlisted_sender=yes\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o broken_sasl_auth_clients=yes\n  -o smtpd_client_restrictions=permit_sasl_authenticated,reject  final konfig master.cf:  smtp      inet  n       -       n       -       -       smtpd\nsubmission inet n       -       n       -       -       smtpd\n  -o smtpd_tls_security_level=encrypt\n  -o smtpd_sasl_auth_enable=yes\n  -o smtpd_reject_unlisted_sender=yes\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o broken_sasl_auth_clients=yes\n  -o smtpd_client_restrictions=permit_sasl_authenticated,reject\npickup    fifo  n       -       n       60      1       pickup\ncleanup   unix  n       -       n       -       0       cleanup\nqmgr      fifo  n       -       n       300     1       qmgr\ntlsmgr    unix  -       -       n       1000?   1       tlsmgr\nrewrite   unix  -       -       n       -       -       trivial-rewrite\nbounce    unix  -       -       n       -       0       bounce\ndefer     unix  -       -       n       -       0       bounce\ntrace     unix  -       -       n       -       0       bounce\nverify    unix  -       -       n       -       1       verify\nflush     unix  n       -       n       1000?   0       flush\nproxymap  unix  -       -       n       -       -       proxymap\nproxywrite unix -       -       n       -       1       proxymap\nsmtp      unix  -       -       n       -       -       smtp\nrelay     unix  -       -       n       -       -       smtp\n    -o smtp_fallback_relay=\nshowq     unix  n       -       n       -       -       showq\nerror     unix  -       -       n       -       -       error\nretry     unix  -       -       n       -       -       error\ndiscard   unix  -       -       n       -       -       discard\nlocal     unix  -       n       n       -       -       local\nvirtual   unix  -       n       n       -       -       virtual\nlmtp      unix  -       -       n       -       -       lmtp\nanvil     unix  -       -       n       -       1       anvil\nscache    unix  -       -       n       -       1       scache  install cyrus sasl support plain tex dan md5t:  yum install cyrus-sasl-md5 cyrus-sasl-plain  konfig smtpd.conf   vim /etc/sasl2/smtpd.conf\npwcheck_method: saslauthd\nmech_list: plain login  restart postfix dan saslauth daemon:  service saslauthd restart;service postfix restart  lalu test dengan php mailer (github.com/PHPMailer/PHPMailer)  ?php\n\n//require_once('class.phpmailer.php');\n\nrequire 'PHPMailerAutoload.php';\n\n$mail = new PHPMailer(); // create a new object\n$mail- IsSMTP(); // enable SMTP\n$mail- SMTPDebug = 1; // debugging: 1 = errors and messages, 2 = messages only\n$mail- SMTPAuth = true; // authentication enabled\n//$mail- SMTPSecure = ''; // secure transfer enabled REQUIRED for GMail\n$mail- Host = \"nws1.coabc.co.id\";\n$mail- Port = 587; // or 587\n$mail- IsHTML(true);\n//$mail- Username = \"dian@infra.abc.co.id\";\n//$mail- Username = \"oksoft@infra.abc.co.id\";\n$mail- Username = \"userid\";\n//$mail- Password = \"\";\n$mail- Password = \"%pass\";\n$mail- SetFrom(\"noreply@coabc.co.id\");\n$mail- Sender=\"newsletter@coabc.co.id\";\n$mail- Subject = \"Maju ED Lisensi\";\n$mail- Body = \"Mohon Maju ED Lisensi, 23 Agustus 2016 ; dikarenakan belum melakukan pembayaran royalty Juli 2016\\n\\n\nTerima Kasih\\n\n\";\n$mail- AddAddress(\"user@abc.co.id\");\n if(!$mail- Send())\n    {\n    echo \"Mailer Error: \" . $mail- ErrorInfo;\n    }\n    else\n    {\n    echo \"Message has been sent\";\n    }\n?   jalankan via php cli:  dgp@it-infra ~/Downloads/PHPMailer-master $ php nws1.apotekk24coid.php \n2016-08-23 03:07:06 CLIENT -  SERVER: EHLO it-infra\n2016-08-23 03:07:06 CLIENT -  SERVER: STARTTLS\n2016-08-23 03:07:06 CLIENT -  SERVER: EHLO it-infra\n2016-08-23 03:07:06 CLIENT -  SERVER: AUTH LOGIN\n2016-08-23 03:07:07 CLIENT -  SERVER: ZVFK\n2016-08-23 03:07:07 CLIENT -  SERVER: OFI=\n2016-08-23 03:07:07 CLIENT -  SERVER: MAIL FROM: newsletter@coabc.co.id \n2016-08-23 03:07:07 CLIENT -  SERVER: RCPT TO: user@abc.co.id \n2016-08-23 03:07:07 CLIENT -  SERVER: DATA\n2016-08-23 03:07:07 CLIENT -  SERVER: Date: Tue, 23 Aug 2016 11:07:05 +0800\n2016-08-23 03:07:07 CLIENT -  SERVER: To: user@abc.co.id\n2016-08-23 03:07:07 CLIENT -  SERVER: From: noreply@coabc.co.id\n2016-08-23 03:07:07 CLIENT -  SERVER: Subject: Maju ED Lisensi\n2016-08-23 03:07:07 CLIENT -  SERVER: Message-ID:  7386bf71ad887e332566581c7aab9e5d@it-infra \n2016-08-23 03:07:07 CLIENT -  SERVER: X-Mailer: PHPMailer 5.2.13 (https://github.com/PHPMailer/PHPMailer)\n2016-08-23 03:07:07 CLIENT -  SERVER: MIME-Version: 1.0\n2016-08-23 03:07:07 CLIENT -  SERVER: Content-Type: text/html; charset=iso-8859-1\n2016-08-23 03:07:07 CLIENT -  SERVER: Content-Transfer-Encoding: 8bit\n2016-08-23 03:07:07 CLIENT -  SERVER:\n2016-08-23 03:07:07 CLIENT -  SERVER: Mohon Maju ED Lisensi, 23 Agustus 2016 ; dikarenakan belum melakukan pembayaran royalty Juli 2016\n2016-08-23 03:07:07 CLIENT -  SERVER:\n2016-08-23 03:07:07 CLIENT -  SERVER:\n2016-08-23 03:07:07 CLIENT -  SERVER: Terima Kasih\n2016-08-23 03:07:07 CLIENT -  SERVER:\n2016-08-23 03:07:07 CLIENT -  SERVER:\n2016-08-23 03:07:07 CLIENT -  SERVER: .\n2016-08-23 03:07:07 CLIENT -  SERVER: QUIT\nMessage has been sent\ndgp@it-infra ~/Downloads/PHPMailer-master $  done.", 
            "title": "Konfigurasi Main.cf"
        }, 
        {
            "location": "/postfix-build-load-balancer-native-smtp-server-dengan-postfix-dan-saslauth/", 
            "text": "Build load balancer native smtp server dengan postfix dan saslauth\n\n\nSetelah bisa build native smtp server dengan postfix, dengan autentikasi model \nsubmission port 587. selanjutnya kita akan membuat smtp tersebut mempunyai 2 ip public sebagai sendernya.\n\n\nada beberapa cara agar kita bisa sending email dengan beberapa ip public:\n1.  Assign ip public ke dalam smtp server tersebut, lalu binding ip addressnya dan gunakan ip public tersebut ( \nhttp://marinovl.blogspot.co.id/2012/09/postfix-how-to-balance-outgoing-emails.html\n ). \nCara ini tidak bisa, karena digital ocean hanya menerapkan floating ip (forwarding). ip public tidak bisa diassign langsung via interface os.\n2.  Dengan cara relay ke dalam 2 ip public tersebut dari mesin yang lain. \nTentunya kita harus menyiapkan 3 buah mesin os. 2 mesin untuk sender, 1 mesin sebagai load balance. masing2 mesin os mempunyai ip public sendiri. untuk konsep load balance, cukup dengan dns round robin saja yang paling mudah.\n\n\nPersiapan:\n\n\n\n\nClone droplets / mesin os yang sudah kita build dari tutorial \n\"build native smtp server dengan support submission authentication\"\n\n\nEnable masing2 private ip.\n\n\n\n\nsetting hostname mesin:\n\n\n\n\nnws1.abc.co.id , dan cek semua yg berkaitan dengan hostname di postfix nya. set spf dari domain abc.co.id ke ip hostname ini.\n\n\nnws2.abc.co.id , dan cek semua yg berkaitan dengan hostname di postfix nya. set spf dari domain abc.co.id ke ip hostname ini.\n\n\n\n\ntest 2 droplet tersebut dengan phpmailer , pastikan spf, rdns sudha diset dengan baik. \njika 2 mesin tersebut sudah ok maka bisa build untuk load balancernya.\n\n\nSetup Load Balancer\n\n\nLoad balancer smtp dibuild dengan os ubuntu based debian, dengan enable ip private dan dengan hostname blsmtp.abc.co.id\n\n\ninstall smtp server postfix.\n\n\napt-get install postfix sasl2-bin\n\n\n\nconfig main.cf\n\n\nrelayhost = [mpl.abc.co.id]:587\nsmtp_sasl_auth_enable = yes\nsmtp_sasl_security_options = noanonymous\n\nrelay_domains =\nhome_mailbox = Maildir/\nmydomain = blsmtp.abc.co.id\nsmtpd_use_tls = yes\nsmtpd_tls_key_file = /root/abc.co.id/abc.co.id.key\nsmtpd_tls_cert_file = /root/abc.co.id/chained.crt\nsmtpd_tls_auth_only=yes\nsmtp_tls_security_level=may\n\nsmtpd_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtpd_tls_protocols = !SSLv2, !SSLv3\nsmtp_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtp_tls_protocols = !SSLv2, !SSLv3\n\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\n\n\nmailbox_size_limit = 256000000\nmyorigin = abc.co.id\nmyhostname = abc.co.id\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128 10.15.0.8 128.199.193.151\nmydestination = newsletter.abc.co.id, localhost.localdomain, localhost\nrecipient_delimiter = +\ninet_interfaces = all\nsmtp_tls_CApath = /etc/ssl/certs\nsmtpd_sasl_local_domain = $myhostname\n\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd\n\n\n\ndefine sasl user password untuk relay ke 2 mesin smtp:\n\n\nvim /etc/postfix/sasl_passwd\n[mpl.abc.co.id]:587 u:p\n[10.130.11.5]:587 u@blsmtp.abc.co.id:p\n\n\n\njangan lupa set dns untuk  mpl.abc.co.id ke ip private masing2 mesin smtp server.\n\n\nset master.cf seperti berikut\n\n\nsmtp      inet  n       -       -       -       -       smtpd\nsubmission inet n       -       -       -       -       smtpd\n  -o smtpd_tls_security_level=encrypt\n  -o smtpd_sasl_auth_enable=yes\n  -o smtpd_reject_unlisted_sender=yes\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o broken_sasl_auth_clients=yes\n  -o smtpd_client_restrictions=permit_sasl_authenticated,reject\nsmtps     inet  n       -       -       -       -       smtpd\n  -o smtpd_tls_wrappermode=yes\n  -o smtpd_sasl_auth_enable=yes\n  -o broken_sasl_auth_clients=yes\n  -o content_filter=\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o milter_macro_daemon_name=ORIGINATING\npickup    unix  n       -       -       60      1       pickup\ncleanup   unix  n       -       -       -       0       cleanup\nqmgr      unix  n       -       n       300     1       qmgr\ntlsmgr    unix  -       -       -       1000?   1       tlsmgr\nrewrite   unix  -       -       -       -       -       trivial-rewrite\nbounce    unix  -       -       -       -       0       bounce\ndefer     unix  -       -       -       -       0       bounce\ntrace     unix  -       -       -       -       0       bounce\nverify    unix  -       -       -       -       1       verify\nflush     unix  n       -       -       1000?   0       flush\nproxymap  unix  -       -       n       -       -       proxymap\nproxywrite unix -       -       n       -       1       proxymap\nsmtp      unix  -       -       -       -       -       smtp\nrelay     unix  -       -       -       -       -       smtp\nshowq     unix  n       -       -       -       -       showq\nerror     unix  -       -       -       -       -       error\nretry     unix  -       -       -       -       -       error\ndiscard   unix  -       -       -       -       -       discard\nlocal     unix  -       n       n       -       -       local\nvirtual   unix  -       n       n       -       -       virtual\nlmtp      unix  -       -       -       -       -       lmtp\nanvil     unix  -       -       -       -       1       anvil\nscache    unix  -       -       -       -       1       scache\nmaildrop  unix  -       n       n       -       -       pipe\n  flags=DRhu user=vmail argv=/usr/bin/maildrop -d ${recipient}\nuucp      unix  -       n       n       -       -       pipe\n  flags=Fqhu user=uucp argv=uux -r -n -z -a$sender - $nexthop!rmail ($recipient)\nifmail    unix  -       n       n       -       -       pipe\n  flags=F user=ftn argv=/usr/lib/ifmail/ifmail -r $nexthop ($recipient)\nbsmtp     unix  -       n       n       -       -       pipe\n  flags=Fq. user=bsmtp argv=/usr/lib/bsmtp/bsmtp -t$nexthop -f$sender $recipient\nscalemail-backend unix  -   n   n   -   2   pipe\n  flags=R user=scalemail argv=/usr/lib/scalemail/bin/scalemail-store ${nexthop} ${user} ${extension}\nmailman   unix  -       n       n       -       -       pipe\n  flags=FR user=list argv=/usr/lib/mailman/bin/postfix-to-mailman.py\n  ${nexthop} ${user}\n\n\n\nset /etc/postfix/sasl/smtpd.conf\n\n\npwcheck_method: auxprop\nauxprop_plugin: sasldb\nmech_list: PLAIN LOGIN\n\n\n\nset /etc/default/saslauthd:\n\n\nSTART=yes\nDESC=\"SASL Authentication Daemon\"\nNAME=\"saslauthd\"\nMECHANISMS=\"shadow\"\nMECH_OPTIONS=\"PLAIN LOGIN\"\nTHREADS=5\nOPTIONS=\"-c -m /var/run/saslauthd\"\n\n\n\ncreate user via sasl\n\n\nsaslpasswd2 -c -u domain user\n\n\n\nuntuk check user:\n\n\nsasldblistusers2\n\n\n\nsetelah selesai, tinggal test ke smtp load balancer dengan user dan password yg telah dibuat:\n\n\nvim blsmtp.php\n\n\n?php\n//require_once('class.phpmailer.php');\nrequire 'PHPMailerAutoload.php';\n\n$imeladdress = \"userp@k24.co.id\";\n$mail = new PHPMailer(); // create a new object\n$mail-\nIsSMTP(); // enable SMTP\n$mail-\nSMTPDebug = 1; // debugging: 1 = errors and messages, 2 = messages only\n$mail-\nSMTPAuth = true; // authentication enabled\n//$mail-\nSMTPSecure = ''; // secure transfer enabled REQUIRED for GMail\n$mail-\nHost = \"blsmtp.abc.co.id\";\n$mail-\nPort = 587; // or 587\n$mail-\nIsHTML(true);\n$mail-\nXMailer = ' ';\n//$mail-\nUsername = \"user@i.abc.co.id\";\n//$mail-\nUsername = \"oksoft@i.abc.co.id\";\n$mail-\nUsername = \"useren@blsmtp.abc.co.id\";\n$mail-\nPassword = \"p%\";\n$mail-\nSetFrom('newsletter@abc.co.id', 'abc.co.id');\n//$mail-\nAddReplyTo('user@abc.co.id', 'abc.co.id');\n$mail-\nSender=\"newsletter@abc.co.id\";\n$mail-\nSubject = \"Inspirasi sehat\";\n//$mail-\naddCustomHeader(\"List-Unsubscribe\",'\nmailto:unsubscribe@abc.co.id?subject=Unsubscribe\n, \nhttp://abc.co.id\n');\n//$mail-\nBody = file_get_contents('file.html');\n//$mail-\nBody = file_get_contents('gmail.html');\n$mail-\nBody = \"testaja\";\n$mail-\nAddAddress(\"$imeladdress\");\n if(!$mail-\nSend())\n    {\n    echo \"Mailer Error: \" . $mail-\nErrorInfo;\n    }\n    else\n    {\n    echo \"Message has been sent\";\n    }\n?\n\n\n\n\n\nuser@it-infra ~/Downloads/PHPMailer-master $ php blsmtp.php \n2016-08-23 03:41:18 CLIENT -\n SERVER: EHLO it-infra\n2016-08-23 03:41:18 CLIENT -\n SERVER: STARTTLS\n2016-08-23 03:41:18 CLIENT -\n SERVER: EHLO it-infra\n2016-08-23 03:41:18 CLIENT -\n SERVER: AUTH LOGIN\n2016-08-23 03:41:18 CLIENT -\n SERVER: ZVd1YTVtazI0LmNvLmlk\n2016-08-23 03:41:18 CLIENT -\n SERVER: OFlzYelI=\n2016-08-23 03:41:18 CLIENT -\n SERVER: MAIL FROM:\nnewsletter@abc.co.id\n\n2016-08-23 03:41:18 CLIENT -\n SERVER: RCPT TO:\nuserp@k24.co.id\n\n2016-08-23 03:41:19 CLIENT -\n SERVER: DATA\n2016-08-23 03:41:19 CLIENT -\n SERVER: Date: Tue, 23 Aug 2016 11:41:17 +0800\n2016-08-23 03:41:19 CLIENT -\n SERVER: To: userp@k24.co.id\n2016-08-23 03:41:19 CLIENT -\n SERVER: From: noreply@abc.co.id\n2016-08-23 03:41:19 CLIENT -\n SERVER: Subject: inspirasi sehat\n2016-08-23 03:41:19 CLIENT -\n SERVER: Message-ID: \nc3bf4cf888fb9f37e7257d0fc1462bec@it-infra\n\n2016-08-23 03:41:19 CLIENT -\n SERVER: X-Mailer: PHPMailer 5.2.13 (https://github.com/PHPMailer/PHPMailer)\n2016-08-23 03:41:19 CLIENT -\n SERVER: MIME-Version: 1.0\n2016-08-23 03:41:19 CLIENT -\n SERVER: Content-Type: text/html; charset=iso-8859-1\n2016-08-23 03:41:19 CLIENT -\n SERVER: Content-Transfer-Encoding: quoted-printable\n2016-08-23 03:41:19 CLIENT -\n SERVER: 233);\"\nbr\n/span\n/div\n/div\n/body\n/html\n=0A\n2016-08-23 03:41:19 CLIENT -\n SERVER: .\n2016-08-23 03:41:19 CLIENT -\n SERVER: QUIT\n\n\n\nhasil email dengan menggunakan random ip address:\n\n\nterlihat ip menggunakan 128.x.x.180 setelah diterima dari ip internal 10.130.11.5, dimana ip internal ini adalah ip dari blsmtp.abc.co.id (mesin load balancer).\n\n\nterlihat ip address menggunakan 188.x.x.205 setelah diterima dari ip internal 10.130.11.5, dimana ip internal ini adalah ip dari blsmtp.abc.co.id (mesin load balancer)\n\n\nselesai.\n\n\nref: \n\nhttps://wiki.debian.org/PostfixAndSASL", 
            "title": "Postfix - Build load balancer native smtp server dengan postfix dan saslauth"
        }, 
        {
            "location": "/postfix-build-load-balancer-native-smtp-server-dengan-postfix-dan-saslauth/#build-load-balancer-native-smtp-server-dengan-postfix-dan-saslauth", 
            "text": "Setelah bisa build native smtp server dengan postfix, dengan autentikasi model \nsubmission port 587. selanjutnya kita akan membuat smtp tersebut mempunyai 2 ip public sebagai sendernya.  ada beberapa cara agar kita bisa sending email dengan beberapa ip public:\n1.  Assign ip public ke dalam smtp server tersebut, lalu binding ip addressnya dan gunakan ip public tersebut (  http://marinovl.blogspot.co.id/2012/09/postfix-how-to-balance-outgoing-emails.html  ). \nCara ini tidak bisa, karena digital ocean hanya menerapkan floating ip (forwarding). ip public tidak bisa diassign langsung via interface os.\n2.  Dengan cara relay ke dalam 2 ip public tersebut dari mesin yang lain. \nTentunya kita harus menyiapkan 3 buah mesin os. 2 mesin untuk sender, 1 mesin sebagai load balance. masing2 mesin os mempunyai ip public sendiri. untuk konsep load balance, cukup dengan dns round robin saja yang paling mudah.", 
            "title": "Build load balancer native smtp server dengan postfix dan saslauth"
        }, 
        {
            "location": "/postfix-build-load-balancer-native-smtp-server-dengan-postfix-dan-saslauth/#persiapan", 
            "text": "Clone droplets / mesin os yang sudah kita build dari tutorial  \"build native smtp server dengan support submission authentication\"  Enable masing2 private ip.   setting hostname mesin:   nws1.abc.co.id , dan cek semua yg berkaitan dengan hostname di postfix nya. set spf dari domain abc.co.id ke ip hostname ini.  nws2.abc.co.id , dan cek semua yg berkaitan dengan hostname di postfix nya. set spf dari domain abc.co.id ke ip hostname ini.   test 2 droplet tersebut dengan phpmailer , pastikan spf, rdns sudha diset dengan baik. \njika 2 mesin tersebut sudah ok maka bisa build untuk load balancernya.", 
            "title": "Persiapan:"
        }, 
        {
            "location": "/postfix-build-load-balancer-native-smtp-server-dengan-postfix-dan-saslauth/#setup-load-balancer", 
            "text": "Load balancer smtp dibuild dengan os ubuntu based debian, dengan enable ip private dan dengan hostname blsmtp.abc.co.id", 
            "title": "Setup Load Balancer"
        }, 
        {
            "location": "/postfix-build-load-balancer-native-smtp-server-dengan-postfix-dan-saslauth/#install-smtp-server-postfix", 
            "text": "apt-get install postfix sasl2-bin  config main.cf  relayhost = [mpl.abc.co.id]:587\nsmtp_sasl_auth_enable = yes\nsmtp_sasl_security_options = noanonymous\n\nrelay_domains =\nhome_mailbox = Maildir/\nmydomain = blsmtp.abc.co.id\nsmtpd_use_tls = yes\nsmtpd_tls_key_file = /root/abc.co.id/abc.co.id.key\nsmtpd_tls_cert_file = /root/abc.co.id/chained.crt\nsmtpd_tls_auth_only=yes\nsmtp_tls_security_level=may\n\nsmtpd_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtpd_tls_protocols = !SSLv2, !SSLv3\nsmtp_tls_mandatory_protocols = !SSLv2, !SSLv3\nsmtp_tls_protocols = !SSLv2, !SSLv3\n\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\n\n\nmailbox_size_limit = 256000000\nmyorigin = abc.co.id\nmyhostname = abc.co.id\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128 10.15.0.8 128.199.193.151\nmydestination = newsletter.abc.co.id, localhost.localdomain, localhost\nrecipient_delimiter = +\ninet_interfaces = all\nsmtp_tls_CApath = /etc/ssl/certs\nsmtpd_sasl_local_domain = $myhostname\n\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd  define sasl user password untuk relay ke 2 mesin smtp:  vim /etc/postfix/sasl_passwd\n[mpl.abc.co.id]:587 u:p\n[10.130.11.5]:587 u@blsmtp.abc.co.id:p  jangan lupa set dns untuk  mpl.abc.co.id ke ip private masing2 mesin smtp server.  set master.cf seperti berikut  smtp      inet  n       -       -       -       -       smtpd\nsubmission inet n       -       -       -       -       smtpd\n  -o smtpd_tls_security_level=encrypt\n  -o smtpd_sasl_auth_enable=yes\n  -o smtpd_reject_unlisted_sender=yes\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o broken_sasl_auth_clients=yes\n  -o smtpd_client_restrictions=permit_sasl_authenticated,reject\nsmtps     inet  n       -       -       -       -       smtpd\n  -o smtpd_tls_wrappermode=yes\n  -o smtpd_sasl_auth_enable=yes\n  -o broken_sasl_auth_clients=yes\n  -o content_filter=\n  -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject\n  -o milter_macro_daemon_name=ORIGINATING\npickup    unix  n       -       -       60      1       pickup\ncleanup   unix  n       -       -       -       0       cleanup\nqmgr      unix  n       -       n       300     1       qmgr\ntlsmgr    unix  -       -       -       1000?   1       tlsmgr\nrewrite   unix  -       -       -       -       -       trivial-rewrite\nbounce    unix  -       -       -       -       0       bounce\ndefer     unix  -       -       -       -       0       bounce\ntrace     unix  -       -       -       -       0       bounce\nverify    unix  -       -       -       -       1       verify\nflush     unix  n       -       -       1000?   0       flush\nproxymap  unix  -       -       n       -       -       proxymap\nproxywrite unix -       -       n       -       1       proxymap\nsmtp      unix  -       -       -       -       -       smtp\nrelay     unix  -       -       -       -       -       smtp\nshowq     unix  n       -       -       -       -       showq\nerror     unix  -       -       -       -       -       error\nretry     unix  -       -       -       -       -       error\ndiscard   unix  -       -       -       -       -       discard\nlocal     unix  -       n       n       -       -       local\nvirtual   unix  -       n       n       -       -       virtual\nlmtp      unix  -       -       -       -       -       lmtp\nanvil     unix  -       -       -       -       1       anvil\nscache    unix  -       -       -       -       1       scache\nmaildrop  unix  -       n       n       -       -       pipe\n  flags=DRhu user=vmail argv=/usr/bin/maildrop -d ${recipient}\nuucp      unix  -       n       n       -       -       pipe\n  flags=Fqhu user=uucp argv=uux -r -n -z -a$sender - $nexthop!rmail ($recipient)\nifmail    unix  -       n       n       -       -       pipe\n  flags=F user=ftn argv=/usr/lib/ifmail/ifmail -r $nexthop ($recipient)\nbsmtp     unix  -       n       n       -       -       pipe\n  flags=Fq. user=bsmtp argv=/usr/lib/bsmtp/bsmtp -t$nexthop -f$sender $recipient\nscalemail-backend unix  -   n   n   -   2   pipe\n  flags=R user=scalemail argv=/usr/lib/scalemail/bin/scalemail-store ${nexthop} ${user} ${extension}\nmailman   unix  -       n       n       -       -       pipe\n  flags=FR user=list argv=/usr/lib/mailman/bin/postfix-to-mailman.py\n  ${nexthop} ${user}  set /etc/postfix/sasl/smtpd.conf  pwcheck_method: auxprop\nauxprop_plugin: sasldb\nmech_list: PLAIN LOGIN  set /etc/default/saslauthd:  START=yes\nDESC=\"SASL Authentication Daemon\"\nNAME=\"saslauthd\"\nMECHANISMS=\"shadow\"\nMECH_OPTIONS=\"PLAIN LOGIN\"\nTHREADS=5\nOPTIONS=\"-c -m /var/run/saslauthd\"  create user via sasl  saslpasswd2 -c -u domain user  untuk check user:  sasldblistusers2  setelah selesai, tinggal test ke smtp load balancer dengan user dan password yg telah dibuat:  vim blsmtp.php  ?php\n//require_once('class.phpmailer.php');\nrequire 'PHPMailerAutoload.php';\n\n$imeladdress = \"userp@k24.co.id\";\n$mail = new PHPMailer(); // create a new object\n$mail- IsSMTP(); // enable SMTP\n$mail- SMTPDebug = 1; // debugging: 1 = errors and messages, 2 = messages only\n$mail- SMTPAuth = true; // authentication enabled\n//$mail- SMTPSecure = ''; // secure transfer enabled REQUIRED for GMail\n$mail- Host = \"blsmtp.abc.co.id\";\n$mail- Port = 587; // or 587\n$mail- IsHTML(true);\n$mail- XMailer = ' ';\n//$mail- Username = \"user@i.abc.co.id\";\n//$mail- Username = \"oksoft@i.abc.co.id\";\n$mail- Username = \"useren@blsmtp.abc.co.id\";\n$mail- Password = \"p%\";\n$mail- SetFrom('newsletter@abc.co.id', 'abc.co.id');\n//$mail- AddReplyTo('user@abc.co.id', 'abc.co.id');\n$mail- Sender=\"newsletter@abc.co.id\";\n$mail- Subject = \"Inspirasi sehat\";\n//$mail- addCustomHeader(\"List-Unsubscribe\",' mailto:unsubscribe@abc.co.id?subject=Unsubscribe ,  http://abc.co.id ');\n//$mail- Body = file_get_contents('file.html');\n//$mail- Body = file_get_contents('gmail.html');\n$mail- Body = \"testaja\";\n$mail- AddAddress(\"$imeladdress\");\n if(!$mail- Send())\n    {\n    echo \"Mailer Error: \" . $mail- ErrorInfo;\n    }\n    else\n    {\n    echo \"Message has been sent\";\n    }\n? \n\n\n\n\nuser@it-infra ~/Downloads/PHPMailer-master $ php blsmtp.php \n2016-08-23 03:41:18 CLIENT -  SERVER: EHLO it-infra\n2016-08-23 03:41:18 CLIENT -  SERVER: STARTTLS\n2016-08-23 03:41:18 CLIENT -  SERVER: EHLO it-infra\n2016-08-23 03:41:18 CLIENT -  SERVER: AUTH LOGIN\n2016-08-23 03:41:18 CLIENT -  SERVER: ZVd1YTVtazI0LmNvLmlk\n2016-08-23 03:41:18 CLIENT -  SERVER: OFlzYelI=\n2016-08-23 03:41:18 CLIENT -  SERVER: MAIL FROM: newsletter@abc.co.id \n2016-08-23 03:41:18 CLIENT -  SERVER: RCPT TO: userp@k24.co.id \n2016-08-23 03:41:19 CLIENT -  SERVER: DATA\n2016-08-23 03:41:19 CLIENT -  SERVER: Date: Tue, 23 Aug 2016 11:41:17 +0800\n2016-08-23 03:41:19 CLIENT -  SERVER: To: userp@k24.co.id\n2016-08-23 03:41:19 CLIENT -  SERVER: From: noreply@abc.co.id\n2016-08-23 03:41:19 CLIENT -  SERVER: Subject: inspirasi sehat\n2016-08-23 03:41:19 CLIENT -  SERVER: Message-ID:  c3bf4cf888fb9f37e7257d0fc1462bec@it-infra \n2016-08-23 03:41:19 CLIENT -  SERVER: X-Mailer: PHPMailer 5.2.13 (https://github.com/PHPMailer/PHPMailer)\n2016-08-23 03:41:19 CLIENT -  SERVER: MIME-Version: 1.0\n2016-08-23 03:41:19 CLIENT -  SERVER: Content-Type: text/html; charset=iso-8859-1\n2016-08-23 03:41:19 CLIENT -  SERVER: Content-Transfer-Encoding: quoted-printable\n2016-08-23 03:41:19 CLIENT -  SERVER: 233);\" br /span /div /div /body /html =0A\n2016-08-23 03:41:19 CLIENT -  SERVER: .\n2016-08-23 03:41:19 CLIENT -  SERVER: QUIT  hasil email dengan menggunakan random ip address:  terlihat ip menggunakan 128.x.x.180 setelah diterima dari ip internal 10.130.11.5, dimana ip internal ini adalah ip dari blsmtp.abc.co.id (mesin load balancer).  terlihat ip address menggunakan 188.x.x.205 setelah diterima dari ip internal 10.130.11.5, dimana ip internal ini adalah ip dari blsmtp.abc.co.id (mesin load balancer)  selesai.  ref:  https://wiki.debian.org/PostfixAndSASL", 
            "title": "install smtp server postfix."
        }, 
        {
            "location": "/nginx-add-intermediate-cert-untuk-trusted-android/", 
            "text": "Menambahkan Intermediate Cert agar Trusted Cert Security di Android\n\n\nKesal dikomplain terus menerus karena ssl tidak trusted ? . Ya, SSL dari RapidSSL memang banyak bermasalah tidak kompatibel di device Android. Bahkan setelah dicompare dengan \nkepunyaan sendiri\n yang selalu lancar tanpa masalah, jadi mengurungkan niat untuk renew RapidSSL .\n\n\nUntuk menambahkan Intermediate Cert dari RapidSSL, unduh bundle dari link berikut : \n\n\n\n\nbundle RapidSSL\n\n\nlalu tambahkan di existing Cert.\n\n\nreload nginx\n\n\n\n\nReferensi:\n\n\n\n\nlostechies.com\n\n\nheroku", 
            "title": "RapidSSL - Menambahkan Intermediate Cert agar Trusted Cert Security di Android"
        }, 
        {
            "location": "/nginx-add-intermediate-cert-untuk-trusted-android/#menambahkan-intermediate-cert-agar-trusted-cert-security-di-android", 
            "text": "Kesal dikomplain terus menerus karena ssl tidak trusted ? . Ya, SSL dari RapidSSL memang banyak bermasalah tidak kompatibel di device Android. Bahkan setelah dicompare dengan  kepunyaan sendiri  yang selalu lancar tanpa masalah, jadi mengurungkan niat untuk renew RapidSSL .  Untuk menambahkan Intermediate Cert dari RapidSSL, unduh bundle dari link berikut :    bundle RapidSSL  lalu tambahkan di existing Cert.  reload nginx   Referensi:   lostechies.com  heroku", 
            "title": "Menambahkan Intermediate Cert agar Trusted Cert Security di Android"
        }, 
        {
            "location": "/vestacp-exim-roundcube-manage-sieve-plugins-setting/", 
            "text": "How to enable manage sieve plugin on Roundcube VestaCP\n\n\nasumsikan kita sudah menginstall VestaCP dengan baik di Centos.\n\n\nKonfig Sieve\n\n\nInstall paket dovecot-pigeonhole:\n\n\nyum install dovecot-pigeonhole\n\n\n\ntambahkan protokol:\n\n\n# vim /etc/dovecot/dovecot.conf\nprotocols = imap pop3 lmtp sieve\nlisten = *\nbase_dir = /var/run/dovecot/\n!include conf.d/*.conf\n\n\n\ntambahkan \nauth-master\n ke dalam \nauth\n (file 10-master.conf):\n\n\nservice auth {\n  unix_listener auth-client {\n    group = mail\n    mode = 0660\n    user = dovecot\n  }\n  unix_listener auth-master {\n    group = mail\n    mode = 0660\n    user = dovecot\n  }\n  user = dovecot\n}\n\n\n\ntambahkan konfig berikut diakhir baris konfigurasi 10-master.conf:\n\n\nservice managesieve-login {\n  inet_listener sieve {\n  port = 4190\n  }\n}\nservice managesieve {\n}\nprotocol sieve {\n    managesieve_max_line_length = 65536\n    managesieve_implementation_string = dovecot\n    log_path = /var/log/dovecot-sieve-errors.log\n    info_log_path = /var/log/dovecot-sieve.log\n}\nplugin {\n    sieve = ~/.dovecot.sieve\n    sieve_global_path = /etc/dovecot/sieve/default.sieve\n    sieve_dir = ~/sieve\n    sieve_global_dir = /etc/dovecot/sieve/global/\n}\nlda_mailbox_autocreate = yes\nlda_mailbox_autosubscribe = yes\nprotocol lda {\n    mail_plugins = $mail_plugins autocreate sieve quota\n    postmaster_address = postmaster@sys.dgprasetya.com\n    hostname = sys.dgprasetya.com\n    auth_socket_path = /var/run/dovecot/auth-master\n    log_path = /var/log/dovecot-lda-errors.log\n    info_log_path = /var/log/dovecot-lda.log\n}\nprotocol lmtp {\n    mail_plugins = $mail_plugins autocreate sieve quota\n    log_path = /var/log/dovecot-lmtp-errors.log\n    info_log_path = /var/log/dovecot-lmtp.log\n}\n\n\n\nset permission dan owner:\n\n\n# touch /var/log/{dovecot-lda-errors.log,dovecot-lda.log}\n# touch /var/log/{dovecot-sieve-errors.log,dovecot-sieve.log}\n# touch /var/log/{dovecot-lmtp-errors.log,dovecot-lmtp.log}\n# mkdir -p /etc/dovecot/sieve/global\n# chown dovecot: -R /etc/dovecot/sieve\n# chown mail:mail /var/log/dovecot-*\n\n\n\nrestart exim \nservice exim restart\n lalu cek apakah sieve sudah running \nnetstat -tunlp | grep :4190\n\n\nKonfig Exim\n\n\nsetting global spam filter:\n\n\n# vim /etc/dovecot/sieve/default.sieve\nrequire [\"fileinto\"];\n# rule:[SPAM]\nif header :contains \"X-Spam-Flag\" \"YES\" {\n        fileinto \"Spam\";\n}\n# rule:[SPAM2]\nelsif header :matches \"Subject\" [\"*money*\",\"*Viagra*\",\"Cialis\"] {\n        fileinto \"Spam\";\n}\n\n\n\nenable \nmanagesieve\n plugin:\n\n\n# vim /etc/roundcubemail/main.inc.php\n$rcmail_config['plugins'] = array('password','managesieve');\n\n\n\nkonfig managesieve plugin:\n\n\nvim /usr/share/roundcubemail/plugins/managesieve/\n$config['managesieve_port'] = 4190;\n$config['managesieve_default'] = '/etc/dovecot/sieve/default.sieve';\n\n\n\nSetting Exim Delivery\n\n\nset local user delivery di bagian router config:\n\n\nlocaluser:\n    driver = accept\n    #transport = local_delivery\n    transport = dovecot\n\n    #transport = dovecot_virtual_delivery\n    condition = ${lookup{$local_part}lsearch{/etc/exim/domains/$domain/passwd}{true}{false}}\n\n\n\nset transpot dovecot di bagian Transpot:\n\n\ndovecot:\n    driver = pipe\n    command = /usr/libexec/dovecot/dovecot-lda -e -d $local_part@$domain -f $sender_address -a $original_local_part@$original_domain\n    return_path_add\n    log_output = true\n    delivery_date_add\n    envelope_to_add\n    user = ${extract{2}{:}{${lookup{$local_part}lsearch{/etc/exim/domains/$domain/passwd}}}}\n    group = mail\n    return_output\n\n\n\nrestart exim \nservice exim restart\n. create filter via roundbox webmail: \nSettings \n Filters\n\n\nlihat log exim untuk detail:\n\n\n2015-09-30 12:35:36 1ZhA3E-00058e-KT \n= root@abc.def.co.id H=abc.def.co.id [1xx.2xx.xx7.1xx] P=esmtps X=UNKNOWN:AES256-GCM-SHA384:256 S=1482 id=E1ZhA3D-003cU6-Ms@abc.def.co.id\n2015-09-30 12:35:36 1ZhA3E-00058e-KT =\n noc \nabc@def.dgprasetya.com\n R=localuser T=dovecot\n\n\n\n\n\ntested on Centos 6.7 VestaCP 0.9.8.\n\n\nRef:\n\n\n\n\nrosehosting\n\n\nforum direct admin\n\n\nforum vesta cp", 
            "title": "VestaCP - How to enable manage sieve plugin on Roundcube VestaCP Centos"
        }, 
        {
            "location": "/vestacp-exim-roundcube-manage-sieve-plugins-setting/#how-to-enable-manage-sieve-plugin-on-roundcube-vestacp", 
            "text": "asumsikan kita sudah menginstall VestaCP dengan baik di Centos.", 
            "title": "How to enable manage sieve plugin on Roundcube VestaCP"
        }, 
        {
            "location": "/vestacp-exim-roundcube-manage-sieve-plugins-setting/#konfig-sieve", 
            "text": "Install paket dovecot-pigeonhole:  yum install dovecot-pigeonhole  tambahkan protokol:  # vim /etc/dovecot/dovecot.conf\nprotocols = imap pop3 lmtp sieve\nlisten = *\nbase_dir = /var/run/dovecot/\n!include conf.d/*.conf  tambahkan  auth-master  ke dalam  auth  (file 10-master.conf):  service auth {\n  unix_listener auth-client {\n    group = mail\n    mode = 0660\n    user = dovecot\n  }\n  unix_listener auth-master {\n    group = mail\n    mode = 0660\n    user = dovecot\n  }\n  user = dovecot\n}  tambahkan konfig berikut diakhir baris konfigurasi 10-master.conf:  service managesieve-login {\n  inet_listener sieve {\n  port = 4190\n  }\n}\nservice managesieve {\n}\nprotocol sieve {\n    managesieve_max_line_length = 65536\n    managesieve_implementation_string = dovecot\n    log_path = /var/log/dovecot-sieve-errors.log\n    info_log_path = /var/log/dovecot-sieve.log\n}\nplugin {\n    sieve = ~/.dovecot.sieve\n    sieve_global_path = /etc/dovecot/sieve/default.sieve\n    sieve_dir = ~/sieve\n    sieve_global_dir = /etc/dovecot/sieve/global/\n}\nlda_mailbox_autocreate = yes\nlda_mailbox_autosubscribe = yes\nprotocol lda {\n    mail_plugins = $mail_plugins autocreate sieve quota\n    postmaster_address = postmaster@sys.dgprasetya.com\n    hostname = sys.dgprasetya.com\n    auth_socket_path = /var/run/dovecot/auth-master\n    log_path = /var/log/dovecot-lda-errors.log\n    info_log_path = /var/log/dovecot-lda.log\n}\nprotocol lmtp {\n    mail_plugins = $mail_plugins autocreate sieve quota\n    log_path = /var/log/dovecot-lmtp-errors.log\n    info_log_path = /var/log/dovecot-lmtp.log\n}  set permission dan owner:  # touch /var/log/{dovecot-lda-errors.log,dovecot-lda.log}\n# touch /var/log/{dovecot-sieve-errors.log,dovecot-sieve.log}\n# touch /var/log/{dovecot-lmtp-errors.log,dovecot-lmtp.log}\n# mkdir -p /etc/dovecot/sieve/global\n# chown dovecot: -R /etc/dovecot/sieve\n# chown mail:mail /var/log/dovecot-*  restart exim  service exim restart  lalu cek apakah sieve sudah running  netstat -tunlp | grep :4190", 
            "title": "Konfig Sieve"
        }, 
        {
            "location": "/vestacp-exim-roundcube-manage-sieve-plugins-setting/#konfig-exim", 
            "text": "setting global spam filter:  # vim /etc/dovecot/sieve/default.sieve\nrequire [\"fileinto\"];\n# rule:[SPAM]\nif header :contains \"X-Spam-Flag\" \"YES\" {\n        fileinto \"Spam\";\n}\n# rule:[SPAM2]\nelsif header :matches \"Subject\" [\"*money*\",\"*Viagra*\",\"Cialis\"] {\n        fileinto \"Spam\";\n}  enable  managesieve  plugin:  # vim /etc/roundcubemail/main.inc.php\n$rcmail_config['plugins'] = array('password','managesieve');  konfig managesieve plugin:  vim /usr/share/roundcubemail/plugins/managesieve/\n$config['managesieve_port'] = 4190;\n$config['managesieve_default'] = '/etc/dovecot/sieve/default.sieve';", 
            "title": "Konfig Exim"
        }, 
        {
            "location": "/vestacp-exim-roundcube-manage-sieve-plugins-setting/#setting-exim-delivery", 
            "text": "set local user delivery di bagian router config:  localuser:\n    driver = accept\n    #transport = local_delivery\n    transport = dovecot\n\n    #transport = dovecot_virtual_delivery\n    condition = ${lookup{$local_part}lsearch{/etc/exim/domains/$domain/passwd}{true}{false}}  set transpot dovecot di bagian Transpot:  dovecot:\n    driver = pipe\n    command = /usr/libexec/dovecot/dovecot-lda -e -d $local_part@$domain -f $sender_address -a $original_local_part@$original_domain\n    return_path_add\n    log_output = true\n    delivery_date_add\n    envelope_to_add\n    user = ${extract{2}{:}{${lookup{$local_part}lsearch{/etc/exim/domains/$domain/passwd}}}}\n    group = mail\n    return_output  restart exim  service exim restart . create filter via roundbox webmail:  Settings   Filters  lihat log exim untuk detail:  2015-09-30 12:35:36 1ZhA3E-00058e-KT  = root@abc.def.co.id H=abc.def.co.id [1xx.2xx.xx7.1xx] P=esmtps X=UNKNOWN:AES256-GCM-SHA384:256 S=1482 id=E1ZhA3D-003cU6-Ms@abc.def.co.id\n2015-09-30 12:35:36 1ZhA3E-00058e-KT =  noc  abc@def.dgprasetya.com  R=localuser T=dovecot   tested on Centos 6.7 VestaCP 0.9.8.  Ref:   rosehosting  forum direct admin  forum vesta cp", 
            "title": "Setting Exim Delivery"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/", 
            "text": "Zimbra - Clustering large deployment Mail Servers\n\n\nTopology\n\n\n\n\nsecara garis besar seperti berikut:\n\n\n\n\nzimbra ldap\n\n\nzimbra mailbox\n\n\nzimbra mta (smtp out)\n\n\nzimbra smtp in\n\n\nzimbra proxy\n\n\n\n\npastikan disable firewalld, selinux, dan port 25 yg aktif\n\n\nzimbra ldap\n\n\ninstall zimbra ldap seperti berikut:\n\n\nSelect the packages to install\nInstall zimbra-ldap [Y] Y\nInstall zimbra-logger [Y] N\nInstall zimbra-mta [Y] N\nInstall zimbra-dnscache [N] N\nInstall zimbra-snmp [Y] Y\nInstall zimbra-store [Y] N\nInstall zimbra-apache [Y] N\nInstall zimbra-spell [Y] N\nInstall zimbra-memcached [Y] N\nInstall zimbra-proxy [Y] N\nChecking required space for zimbra-core\nInstalling:\n    zimbra-core\n    zimbra-ldap\n    zimbra-snmp\nThe system will be modified.  Continue? [N] Y\nBeginning Installation - see /tmp/install.log.eDMCjVt8 for details...\n\n\n\nlangkah selanjutnya konfigurasi sesuai kebutuhan (host ldap, dll)\n\n\nlalu setup logger:\n\n\n# systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup\n\n\n\naktifkan di rsyslog.conf:\n\n\n$ModLoad imudp\n$UDPServerRun 514\n\n\n\nmasuk ke user zimbra. \nsu - zimbra\n\n\nsu - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys\n\n\n\nzimbra mailbox\n\n\nSelect the packages to install\nInstall zimbra-ldap [Y] N\nInstall zimbra-logger [Y] Y\nInstall zimbra-mta [Y] N\nInstall zimbra-dnscache [N] N\nInstall zimbra-snmp [Y] Y\nInstall zimbra-store [Y] Y\nInstall zimbra-apache [Y] Y\nInstall zimbra-spell [Y] Y\nInstall zimbra-memcached [Y] Y\nInstall zimbra-proxy [Y] N\nInstall zimbra-drive [Y] N\nInstall zimbra-imapd (BETA - for evaluation only) [N] N\nInstall zimbra-chat [Y] N\nChecking required space for zimbra-core\nChecking space for zimbra-store\nChecking required packages for zimbra-store\nzimbra-store package check complete.\nInstalling:\n    zimbra-core\n    zimbra-logger\n    zimbra-snmp\n    zimbra-store\n    zimbra-apache\n    zimbra-spell\n    zimbra-memcached\n    zimbra-patch\nThe system will be modified.  Continue? [N] Y\nBeginning Installation - see /tmp/install.log.GjIl8GY0 for details...\n\n\n\nlangkah selanjutnya konfigurasi sesuai kebutuhan (host ldap, dll). untuk mailbox2 bisa dilakukan dg cara yg sama, namun untuk create user admin ditiadakan.\n\n\nlalu setup logger:\n\n\n# systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup\n\n\n\naktifkan di rsyslog.conf:\n\n\n$ModLoad imudp\n$UDPServerRun 514\n\n\n\nmasuk ke user zimbra. \nsu - zimbra\n\n\nsu - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys\n\n\n\nzimbra mta\n\n\nSelect the packages to install\nInstall zimbra-ldap [Y] N\nInstall zimbra-logger [Y] N\nInstall zimbra-mta [Y] Y\nInstall zimbra-dnscache [Y] N\nInstall zimbra-snmp [Y] N\nInstall zimbra-store [Y] N\nInstall zimbra-apache [Y] N\nInstall zimbra-spell [Y] N\nInstall zimbra-memcached [Y] N\nInstall zimbra-proxy [Y] N\nChecking required space for zimbra-core\nInstalling:\n    zimbra-core\n    zimbra-mta\n    zimbra-mta-patch\nThe system will be modified.  Continue? [N] Y\nBeginning Installation - see /tmp/install.log.r7icFuqX for details...\n\n\n\nlangkah selanjutnya konfigurasi sesuai kebutuhan (host ldap, dll)\n\n\nlalu setup logger:\n\n\n# systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup\n\n\n\naktifkan di rsyslog.conf:\n\n\n$ModLoad imudp\n$UDPServerRun 514\n\n\n\nmasuk ke user zimbra. \nsu - zimbra\n\n\nsu - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys\n\n\n\nzimbra smtp in\n\n\nuntuk ingoing smtp, lakukan hal sama seperti installasi zimbra mta. untuk service port selain 25 bisa dinonaktifkan.\n\n\nzimbra Proxy\n\n\ninstall zimbra proxy seperti berikut:\n\n\nSelect the packages to install\nInstall zimbra-ldap [Y] N\nInstall zimbra-logger [Y] N\nInstall zimbra-mta [Y] N\nInstall zimbra-dnscache [N] N\nInstall zimbra-snmp [Y] N\nInstall zimbra-store [Y] N\nInstall zimbra-apache [Y] N\nInstall zimbra-spell [Y] N\nInstall zimbra-memcached [Y] N\nInstall zimbra-proxy [Y] Y\nChecking required space for zimbra-core\nInstalling:\n    zimbra-core\n    zimbra-proxy\n    zimbra-proxy-patch\nThe system will be modified.  Continue? [N] Y\n\n\n\nlalu setup logger:\n\n\n# systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup\n\n\n\naktifkan di rsyslog.conf:\n\n\n$ModLoad imudp\n$UDPServerRun 514\n\n\n\nmasuk ke user zimbra. \nsu - zimbra\n\n\nsu - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys\n\n\n\nsetup/enable zimbra proxy:\n\n\n[zimbra@aptikalb1 ~]$ zmcontrol stop\n[zimbra@aptikalb1 ~]$ /opt/zimbra/libexec/zmproxyconfig -e -w -C -H `zmhostname`\n[zimbra@aptikalb1 ~]$ zmcontrol start\n\n\n\nsetelah semua vm terinstall (ldap,proxy, 2 mailbox, dan 1 mta), lakukan restart logger di semua vm:\n\n\n# /opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\n# zmupdateauthkeys\n\n\n\nHaproxy\n\n\nHaproxy dalam kali ini digunakan untuk menerima dan menyeimbangkan traffic port 587 dan 465.\n\n\ninstall haproxy:\n\n\n# yum install haproxy\n\n\n\nhaproxy.cfg\n\n\nglobal\nlog         127.0.0.1 local2\nchroot      /var/lib/haproxy\npidfile     /var/run/haproxy.pid\nmaxconn     4000\nuser        haproxy\ngroup       haproxy\ndaemon\n\ndefaults\n        timeout client 1m\n        log global\n        mode tcp\n        timeout server 1m\n        timeout connect 5s\n\n## port 25\nfrontend smtp-25\n        bind *:25\n        default_backend backend-smtp-25\n\nbackend backend-smtp-25\n        server mail1 10.10.22.53:26 send-proxy\n        server mail2 10.10.22.55:26 send-proxy\n\n## port 465\nfrontend smtp-465\n        bind *:467\n        default_backend backend-smtp-465\n\nbackend backend-smtp-465\n        server mail1 10.10.22.53:466 send-proxy\n        server mail2 10.10.22.55:466 send-proxy\n\n## port 587\nfrontend smtp-587\n        bind *:589\n        default_backend backend-smtp-587\n\nbackend backend-smtp-587\n        server mail1 10.10.22.53:588 send-proxy\n        server mail2 10.10.22.54:588 send-proxy\n\n\n\nrestart haproxy:\n\n\nservice haproxy restart\n\n\n\nedit zimbra conf postfix:\n\n\nvi /opt/zimbra/common/conf/master.cf.in\n\n\n26      inet  n       -       n       -       1       postscreen\n        -o postscreen_upstream_proxy_protocol=haproxy\n\n466    inet  n       -       n       -       -       smtpd\n%%uncomment SERVICE:opendkim%%  -o content_filter=scan:[%%zimbraLocalBindAddress%%]:10030\n        -o smtpd_tls_wrappermode=yes\n        -o smtpd_sasl_auth_enable=yes\n        -o smtpd_client_restrictions=\n        -o smtpd_data_restrictions=\n        -o smtpd_helo_restrictions=\n        -o smtpd_recipient_restrictions=\n        -o smtpd_relay_restrictions=permit_sasl_authenticated,reject\n        -o syslog_name=postfix/smtps\n        -o milter_macro_daemon_name=ORIGINATING\n        -o smtpd_upstream_proxy_protocol=haproxy\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_filter=[%%zimbraLocalBindAddress%%]:10027\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_options=speed_adjust\n\n588 inet n      -       n       -       -       smtpd\n%%uncomment SERVICE:opendkim%%  -o content_filter=scan:[%%zimbraLocalBindAddress%%]:10030\n        -o smtpd_etrn_restrictions=reject\n        -o smtpd_sasl_auth_enable=%%zimbraMtaSaslAuthEnable%%\n        -o smtpd_tls_security_level=%%zimbraMtaTlsSecurityLevel%%\n        -o smtpd_client_restrictions=permit_sasl_authenticated,reject\n        -o smtpd_data_restrictions=\n        -o smtpd_helo_restrictions=\n        -o smtpd_recipient_restrictions=\n        -o smtpd_relay_restrictions=permit_sasl_authenticated,reject\n        -o syslog_name=postfix/submission\n        -o milter_macro_daemon_name=ORIGINATING\n        -o smtpd_upstream_proxy_protocol=haproxy\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_filter=[%%zimbraLocalBindAddress%%]:10027\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_options=speed_adjust\n\n\n\nrestart zmmta:\n\n\nzmmtactl restart\n\n\n\ncontoh konfigurasi hasil cluster/multi server zimbra:\n\n\n\n\n\n\n10.10.22.51     zmproxy.local zmproxy\n10.10.22.52     zmldap.local zmldap\n10.10.22.53     zmmta.local zmmta smtp.out\n10.10.22.54     lb.local (mta)\n10.10.22.55     zmmta4.local zmmta4 smtp.out\n10.10.22.56     zmmailbox2.local zmmailbox2\n10.10.22.57     zmmailbox1.local zmmailbox1\n10.10.22.62     zmmtain1.local zmmtain1\n10.10.22.63     zmmtain2.local zmmtain2\n\n\n\nuntuk keperluan dns spoofing via \n/etc/nameservers\n, bisa menggunakan \ndnsmasq\n.\n\n\nreferensi:\n\n\nhttp://linoxide.com/linux-how-to/howto-install-configure-zimbra-8-6-multi-server-centos-7/\n\n\nhttps://computingforgeeks.com/zimbra-multi-server-installation-on-centos-7/", 
            "title": "Zimbra - Clustering large deployment Mail Servers"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/#topology", 
            "text": "secara garis besar seperti berikut:   zimbra ldap  zimbra mailbox  zimbra mta (smtp out)  zimbra smtp in  zimbra proxy   pastikan disable firewalld, selinux, dan port 25 yg aktif", 
            "title": "Topology"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/#zimbra-ldap", 
            "text": "install zimbra ldap seperti berikut:  Select the packages to install\nInstall zimbra-ldap [Y] Y\nInstall zimbra-logger [Y] N\nInstall zimbra-mta [Y] N\nInstall zimbra-dnscache [N] N\nInstall zimbra-snmp [Y] Y\nInstall zimbra-store [Y] N\nInstall zimbra-apache [Y] N\nInstall zimbra-spell [Y] N\nInstall zimbra-memcached [Y] N\nInstall zimbra-proxy [Y] N\nChecking required space for zimbra-core\nInstalling:\n    zimbra-core\n    zimbra-ldap\n    zimbra-snmp\nThe system will be modified.  Continue? [N] Y\nBeginning Installation - see /tmp/install.log.eDMCjVt8 for details...  langkah selanjutnya konfigurasi sesuai kebutuhan (host ldap, dll)  lalu setup logger:  # systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup  aktifkan di rsyslog.conf:  $ModLoad imudp\n$UDPServerRun 514  masuk ke user zimbra.  su - zimbra  su - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys", 
            "title": "zimbra ldap"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/#zimbra-mailbox", 
            "text": "Select the packages to install\nInstall zimbra-ldap [Y] N\nInstall zimbra-logger [Y] Y\nInstall zimbra-mta [Y] N\nInstall zimbra-dnscache [N] N\nInstall zimbra-snmp [Y] Y\nInstall zimbra-store [Y] Y\nInstall zimbra-apache [Y] Y\nInstall zimbra-spell [Y] Y\nInstall zimbra-memcached [Y] Y\nInstall zimbra-proxy [Y] N\nInstall zimbra-drive [Y] N\nInstall zimbra-imapd (BETA - for evaluation only) [N] N\nInstall zimbra-chat [Y] N\nChecking required space for zimbra-core\nChecking space for zimbra-store\nChecking required packages for zimbra-store\nzimbra-store package check complete.\nInstalling:\n    zimbra-core\n    zimbra-logger\n    zimbra-snmp\n    zimbra-store\n    zimbra-apache\n    zimbra-spell\n    zimbra-memcached\n    zimbra-patch\nThe system will be modified.  Continue? [N] Y\nBeginning Installation - see /tmp/install.log.GjIl8GY0 for details...  langkah selanjutnya konfigurasi sesuai kebutuhan (host ldap, dll). untuk mailbox2 bisa dilakukan dg cara yg sama, namun untuk create user admin ditiadakan.  lalu setup logger:  # systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup  aktifkan di rsyslog.conf:  $ModLoad imudp\n$UDPServerRun 514  masuk ke user zimbra.  su - zimbra  su - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys", 
            "title": "zimbra mailbox"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/#zimbra-mta", 
            "text": "Select the packages to install\nInstall zimbra-ldap [Y] N\nInstall zimbra-logger [Y] N\nInstall zimbra-mta [Y] Y\nInstall zimbra-dnscache [Y] N\nInstall zimbra-snmp [Y] N\nInstall zimbra-store [Y] N\nInstall zimbra-apache [Y] N\nInstall zimbra-spell [Y] N\nInstall zimbra-memcached [Y] N\nInstall zimbra-proxy [Y] N\nChecking required space for zimbra-core\nInstalling:\n    zimbra-core\n    zimbra-mta\n    zimbra-mta-patch\nThe system will be modified.  Continue? [N] Y\nBeginning Installation - see /tmp/install.log.r7icFuqX for details...  langkah selanjutnya konfigurasi sesuai kebutuhan (host ldap, dll)  lalu setup logger:  # systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup  aktifkan di rsyslog.conf:  $ModLoad imudp\n$UDPServerRun 514  masuk ke user zimbra.  su - zimbra  su - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys", 
            "title": "zimbra mta"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/#zimbra-smtp-in", 
            "text": "untuk ingoing smtp, lakukan hal sama seperti installasi zimbra mta. untuk service port selain 25 bisa dinonaktifkan.", 
            "title": "zimbra smtp in"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/#zimbra-proxy", 
            "text": "install zimbra proxy seperti berikut:  Select the packages to install\nInstall zimbra-ldap [Y] N\nInstall zimbra-logger [Y] N\nInstall zimbra-mta [Y] N\nInstall zimbra-dnscache [N] N\nInstall zimbra-snmp [Y] N\nInstall zimbra-store [Y] N\nInstall zimbra-apache [Y] N\nInstall zimbra-spell [Y] N\nInstall zimbra-memcached [Y] N\nInstall zimbra-proxy [Y] Y\nChecking required space for zimbra-core\nInstalling:\n    zimbra-core\n    zimbra-proxy\n    zimbra-proxy-patch\nThe system will be modified.  Continue? [N] Y  lalu setup logger:  # systemctl restart crond;systemctl enable crond;vim /etc/rsyslog.conf;systemctl restart rsyslog;systemctl enable rsyslog;/opt/zimbra/libexec/zmsyslogsetup  aktifkan di rsyslog.conf:  $ModLoad imudp\n$UDPServerRun 514  masuk ke user zimbra.  su - zimbra  su - zimbra\n/opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\nzmupdateauthkeys  setup/enable zimbra proxy:  [zimbra@aptikalb1 ~]$ zmcontrol stop\n[zimbra@aptikalb1 ~]$ /opt/zimbra/libexec/zmproxyconfig -e -w -C -H `zmhostname`\n[zimbra@aptikalb1 ~]$ zmcontrol start  setelah semua vm terinstall (ldap,proxy, 2 mailbox, dan 1 mta), lakukan restart logger di semua vm:  # /opt/zimbra/libexec/zmsyslogsetup;systemctl restart rsyslog\n# zmupdateauthkeys", 
            "title": "zimbra Proxy"
        }, 
        {
            "location": "/zimbra-clustering-large-deployment-mail-servers/#haproxy", 
            "text": "Haproxy dalam kali ini digunakan untuk menerima dan menyeimbangkan traffic port 587 dan 465.  install haproxy:  # yum install haproxy  haproxy.cfg  global\nlog         127.0.0.1 local2\nchroot      /var/lib/haproxy\npidfile     /var/run/haproxy.pid\nmaxconn     4000\nuser        haproxy\ngroup       haproxy\ndaemon\n\ndefaults\n        timeout client 1m\n        log global\n        mode tcp\n        timeout server 1m\n        timeout connect 5s\n\n## port 25\nfrontend smtp-25\n        bind *:25\n        default_backend backend-smtp-25\n\nbackend backend-smtp-25\n        server mail1 10.10.22.53:26 send-proxy\n        server mail2 10.10.22.55:26 send-proxy\n\n## port 465\nfrontend smtp-465\n        bind *:467\n        default_backend backend-smtp-465\n\nbackend backend-smtp-465\n        server mail1 10.10.22.53:466 send-proxy\n        server mail2 10.10.22.55:466 send-proxy\n\n## port 587\nfrontend smtp-587\n        bind *:589\n        default_backend backend-smtp-587\n\nbackend backend-smtp-587\n        server mail1 10.10.22.53:588 send-proxy\n        server mail2 10.10.22.54:588 send-proxy  restart haproxy:  service haproxy restart  edit zimbra conf postfix:  vi /opt/zimbra/common/conf/master.cf.in\n\n\n26      inet  n       -       n       -       1       postscreen\n        -o postscreen_upstream_proxy_protocol=haproxy\n\n466    inet  n       -       n       -       -       smtpd\n%%uncomment SERVICE:opendkim%%  -o content_filter=scan:[%%zimbraLocalBindAddress%%]:10030\n        -o smtpd_tls_wrappermode=yes\n        -o smtpd_sasl_auth_enable=yes\n        -o smtpd_client_restrictions=\n        -o smtpd_data_restrictions=\n        -o smtpd_helo_restrictions=\n        -o smtpd_recipient_restrictions=\n        -o smtpd_relay_restrictions=permit_sasl_authenticated,reject\n        -o syslog_name=postfix/smtps\n        -o milter_macro_daemon_name=ORIGINATING\n        -o smtpd_upstream_proxy_protocol=haproxy\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_filter=[%%zimbraLocalBindAddress%%]:10027\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_options=speed_adjust\n\n588 inet n      -       n       -       -       smtpd\n%%uncomment SERVICE:opendkim%%  -o content_filter=scan:[%%zimbraLocalBindAddress%%]:10030\n        -o smtpd_etrn_restrictions=reject\n        -o smtpd_sasl_auth_enable=%%zimbraMtaSaslAuthEnable%%\n        -o smtpd_tls_security_level=%%zimbraMtaTlsSecurityLevel%%\n        -o smtpd_client_restrictions=permit_sasl_authenticated,reject\n        -o smtpd_data_restrictions=\n        -o smtpd_helo_restrictions=\n        -o smtpd_recipient_restrictions=\n        -o smtpd_relay_restrictions=permit_sasl_authenticated,reject\n        -o syslog_name=postfix/submission\n        -o milter_macro_daemon_name=ORIGINATING\n        -o smtpd_upstream_proxy_protocol=haproxy\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_filter=[%%zimbraLocalBindAddress%%]:10027\n%%uncomment LOCAL:postjournal_enabled%% -o smtpd_proxy_options=speed_adjust  restart zmmta:  zmmtactl restart  contoh konfigurasi hasil cluster/multi server zimbra:    10.10.22.51     zmproxy.local zmproxy\n10.10.22.52     zmldap.local zmldap\n10.10.22.53     zmmta.local zmmta smtp.out\n10.10.22.54     lb.local (mta)\n10.10.22.55     zmmta4.local zmmta4 smtp.out\n10.10.22.56     zmmailbox2.local zmmailbox2\n10.10.22.57     zmmailbox1.local zmmailbox1\n10.10.22.62     zmmtain1.local zmmtain1\n10.10.22.63     zmmtain2.local zmmtain2  untuk keperluan dns spoofing via  /etc/nameservers , bisa menggunakan  dnsmasq .  referensi:  http://linoxide.com/linux-how-to/howto-install-configure-zimbra-8-6-multi-server-centos-7/  https://computingforgeeks.com/zimbra-multi-server-installation-on-centos-7/", 
            "title": "Haproxy"
        }, 
        {
            "location": "/zabbix-install-4.4-version/", 
            "text": "Install zabbix latest version with Telegram Notifications\n\n\nInstall Zabbix Server \n FrontEnd Zabbix\n\n\nInstall repo:\n\n\n# rpm -Uvh https://repo.zabbix.com/zabbix/4.4/rhel/7/x86_64/zabbix-release-4.4-1.el7.noarch.rpm\n\n\n\nInstall package untuk zabbix server dan zabbix frontend based on PostgreSQL database:\n\n\n# yum install postgresql-server zabbix-server-pgsql zabbix-agent epel-release zabbix-web-pgsql zabbix-nginx-conf\n\n\n\nSetup DB PostgreSQL:\n\n\n# postgresql-setup initdb\n\n\n\nStart postgresql service:\n\n\n# systemctl start postgresql \n systemctl enable postgresql\n\n\n\nsetting trust user:\n\n\n# vi /var/lib/pgsql/data/pg_hba.conf\nhost all all 127.0.0.1/32 md5\nhost all all ::1/128 md5\n\n\n\ncreate user postgresql untuk zabbix:\n\n\n$ sudo -u postgres createuser --pwprompt zabbix\n$ sudo -u postgres createdb -O zabbix zabbix\n\n\n\nImport data zabbix:\n\n\n$ zcat /usr/share/doc/zabbix-server-pgsql*/create.sql.gz | sudo -u zabbix psql zabbix\n\n\n\nsetting database:\n\n\n# vi /etc/zabbix/zabbix_server.conf\nDBHost=localhost\nDBName=zabbix\nDBUser=zabbix\nDBPassword=\npassword\n\n\n\n\nrestart services\n\n\n# systemctl restart zabbix-server zabbix-agent nginx php-fpm postgresql\n\n\n\nenable startup services:\n\n\n# systemctl enable zabbix-server zabbix-agent nginx php-fpm\n\n\n\nakses frontend zabbix ke localhost/zabbix atau url yg relevan disesuaikan dg kondisi jaringan\n.\n\n\nMenambahkan Host Monitoring\n\n\nInstall zabbix agent di server yg akan dimonitor.\n\n\nInstall repo dan agent:\n\n\n# rpm -Uvh https://repo.zabbix.com/zabbix/4.4/rhel/7/x86_64/zabbix-release-4.4-1.el7.noarch.rpm\n# yum install zabbix zabbix-agent\n\n\n\nsetting zabbix_agentd.conf\n\n\n#Server=[zabbix server ip]\n#Hostname=[ Hostname of client system ]\n\nServer=192.168.1.100\nHostname=Server1\n\n\n\nstart services:\n\n\nservice zabbix-agent restart\n\n\n\nlalu bisa menambahkan host, template, trigger, item, dll:\n\n\n\n\nbeberapa template yang bisa dipakai untuk monitoring:\n\n\n\n\nInstall Telegram Notifications:\n\n\nUnduh file \n\n\n# wget -c \"https://git.cdp.li/polcape/zabbix/-/raw/master/telegram-notify/zabbix-telegram.sh\"\n\n\n\nedit file \nzabbix-telegram.sh\n\n\nsesuaikan variable dibawah ini:\n\n\nZBX_URL with the Zabbix address or URL\nUSERNAME and PASSWORD for access to Zabbix GUI (this user must have the permission to see the graph)\nBOT_TOKEN with the TokenID obtained from BotFather\nSEND_GRAPH and SEND_MESSAGE flag to enable the two features\nZABBIXVERSION34 if the version of Zabbix is \n= 3.4.1\nWIDTH to increase the width of graph image\nPERIOD to set the seconds to see in the graph\n\n\n\nsimple test via cli:\n\n\n./zabbix-telegram.sh id_user_telegram \"OK Disaster Subject\" \"Message Item Graphic: [10490]\"\n\n\n\nTambahkan Media Types:\n\n\n\n\nsave dan test untuk memastikan script bisa jalan.\n\n\nTambahkan akses ke user yg dipakai di variable \nzabbix-telegram.sh\n diatas:\n\n\n\n\nCreate Action untuk mengirimkan alert:\n\n\n\n\njangan lupa save dan test terlebih dahulu:\n\n\nAlert di zabbix:\n\n\n\n\nAlert di Telegram:\n\n\n\n\nPros:\n\n\n\n\nKonfigurasi lebih mudah melalui web frontend.\n\n\nDokumentasi lengkap\n\n\nBisa Active check, Passive check baik lewat agent atau snmpd.\n\n\nIntegrasi banyak yg disupport\n\n\n\n\nCons:\n- beberapa template, rule alert, atau trigger agak rumit. perlu ketelitian.\n- tidak bisa one setup langsung selesai bisa dimonitoring, tetapi mesti disetting satu persatu untuk services, dll.\n\n\nRef:\n\n\n\n\nzabbix front end\n\n\n\n\nzabbix server\n\n\n\n\n\n\nzabbix agent", 
            "title": "Zabbix - Install zabbix latest version with Telegram Notifications"
        }, 
        {
            "location": "/zabbix-install-4.4-version/#install-zabbix-latest-version-with-telegram-notifications", 
            "text": "", 
            "title": "Install zabbix latest version with Telegram Notifications"
        }, 
        {
            "location": "/zabbix-install-4.4-version/#install-zabbix-server-frontend-zabbix", 
            "text": "Install repo:  # rpm -Uvh https://repo.zabbix.com/zabbix/4.4/rhel/7/x86_64/zabbix-release-4.4-1.el7.noarch.rpm  Install package untuk zabbix server dan zabbix frontend based on PostgreSQL database:  # yum install postgresql-server zabbix-server-pgsql zabbix-agent epel-release zabbix-web-pgsql zabbix-nginx-conf  Setup DB PostgreSQL:  # postgresql-setup initdb  Start postgresql service:  # systemctl start postgresql   systemctl enable postgresql  setting trust user:  # vi /var/lib/pgsql/data/pg_hba.conf\nhost all all 127.0.0.1/32 md5\nhost all all ::1/128 md5  create user postgresql untuk zabbix:  $ sudo -u postgres createuser --pwprompt zabbix\n$ sudo -u postgres createdb -O zabbix zabbix  Import data zabbix:  $ zcat /usr/share/doc/zabbix-server-pgsql*/create.sql.gz | sudo -u zabbix psql zabbix  setting database:  # vi /etc/zabbix/zabbix_server.conf\nDBHost=localhost\nDBName=zabbix\nDBUser=zabbix\nDBPassword= password   restart services  # systemctl restart zabbix-server zabbix-agent nginx php-fpm postgresql  enable startup services:  # systemctl enable zabbix-server zabbix-agent nginx php-fpm  akses frontend zabbix ke localhost/zabbix atau url yg relevan disesuaikan dg kondisi jaringan .", 
            "title": "Install Zabbix Server &amp; FrontEnd Zabbix"
        }, 
        {
            "location": "/zabbix-install-4.4-version/#menambahkan-host-monitoring", 
            "text": "Install zabbix agent di server yg akan dimonitor.  Install repo dan agent:  # rpm -Uvh https://repo.zabbix.com/zabbix/4.4/rhel/7/x86_64/zabbix-release-4.4-1.el7.noarch.rpm\n# yum install zabbix zabbix-agent  setting zabbix_agentd.conf  #Server=[zabbix server ip]\n#Hostname=[ Hostname of client system ]\n\nServer=192.168.1.100\nHostname=Server1  start services:  service zabbix-agent restart  lalu bisa menambahkan host, template, trigger, item, dll:   beberapa template yang bisa dipakai untuk monitoring:", 
            "title": "Menambahkan Host Monitoring"
        }, 
        {
            "location": "/zabbix-install-4.4-version/#install-telegram-notifications", 
            "text": "Unduh file   # wget -c \"https://git.cdp.li/polcape/zabbix/-/raw/master/telegram-notify/zabbix-telegram.sh\"  edit file  zabbix-telegram.sh  sesuaikan variable dibawah ini:  ZBX_URL with the Zabbix address or URL\nUSERNAME and PASSWORD for access to Zabbix GUI (this user must have the permission to see the graph)\nBOT_TOKEN with the TokenID obtained from BotFather\nSEND_GRAPH and SEND_MESSAGE flag to enable the two features\nZABBIXVERSION34 if the version of Zabbix is  = 3.4.1\nWIDTH to increase the width of graph image\nPERIOD to set the seconds to see in the graph  simple test via cli:  ./zabbix-telegram.sh id_user_telegram \"OK Disaster Subject\" \"Message Item Graphic: [10490]\"  Tambahkan Media Types:   save dan test untuk memastikan script bisa jalan.  Tambahkan akses ke user yg dipakai di variable  zabbix-telegram.sh  diatas:   Create Action untuk mengirimkan alert:   jangan lupa save dan test terlebih dahulu:  Alert di zabbix:   Alert di Telegram:   Pros:   Konfigurasi lebih mudah melalui web frontend.  Dokumentasi lengkap  Bisa Active check, Passive check baik lewat agent atau snmpd.  Integrasi banyak yg disupport   Cons:\n- beberapa template, rule alert, atau trigger agak rumit. perlu ketelitian.\n- tidak bisa one setup langsung selesai bisa dimonitoring, tetapi mesti disetting satu persatu untuk services, dll.  Ref:   zabbix front end   zabbix server    zabbix agent", 
            "title": "Install Telegram Notifications:"
        }, 
        {
            "location": "/zimbra-mail-server-performance-dan-Tuning/", 
            "text": "set Performance dan Tuning Zimbra Mail Server\n\n\nissues:\n\n\nCPU High load\n\n\n\n\nHTTP ERROR\n\n\n\n\n\n\n\n\nZimbra web mail akan terasa lambat jika diakses dan kadang memunculkan http error baik 502 atau 500, dan jika dilihat dari prosesnya maka cpu akan nampak terlihat HIGH.\n\n\nSolusi:\n\n\nTweak konfigurasi zimbra baik set performance \n tunning.\nset value::\n\n\nzimbraImapNumThreads: 400\nzimbraImapMaxConnections: 400\nmailboxd_java_heap_memory_percent = 28\nmailboxd_java_heap_new_size_percent = 25\nmailboxd_java_heap_size = 4096\n\n\n\njalankan:\n\n\nzmprov ms `zmhostname` zimbraImapNumThreads 400\nzmprov ms `zmhostname` zimbraImapMaxConnections 400\nzmlocalconfig -e mailboxd_java_heap_memory_percent=28\nzmlocalconfig -e mailboxd_java_heap_new_size_percent=25\nzmlocalconfig -e mailboxd_java_heap_size=4096\n\n\n\npada \nmailboxd_java_options\n ditambahkan \n-XX:NewRatio=2\n -dan \nXX:PermSize\n dinaikkan dari \n128m\n ke \n196m\n ::\n\n\nmailboxd_java_options = -server -Djava.awt.headless=true -Dsun.net.inetaddr.ttl=${networkaddress_cache_ttl} -Dorg.apache.jasper.compiler.disablejsr199=true -XX:+UseConcMarkSweepGC -XX:NewRatio=2 -XX:PermSize=196m -XX:MaxPermSize=350m -XX:SoftRefLRUPolicyMSPerMB=1 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -XX:-OmitStackTraceInFastThrow -Djava.net.preferIPv4Stack=true\n\n\n\njalankan:\n\n\nzmlocalconfig -e mailboxd_java_options =\"-server -Djava.awt.headless=true -Dsun.net.inetaddr.ttl=${networkaddress_cache_ttl} -Dorg.apache.jasper.compiler.disablejsr199=true -XX:+UseConcMarkSweepGC -XX:NewRatio=2 -XX:PermSize=196m -XX:MaxPermSize=350m -XX:SoftRefLRUPolicyMSPerMB=1 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -XX:-OmitStackTraceInFastThrow -Djava.net.preferIPv4Stack=true\"\n\n\n\n\n\nLalu restart zimbra dengan \nzmcontrol restart\n \n monitoring:\n\n\n\n\nJika sudah stabil maka proses CPU akan nampak sedang, tidak pernah \nHIGH\n secara terus menerus. \n\n\nBesarnya value yang diset menyesuaikan environment kondisi hardware baik CPU maupun RAM. Manual tweak zimbra dari tunning \n set performance ini bisa dibaca di link: \nhttps://wiki.zimbra.com/wiki/Performance_Tuning_Guidelines_for_Large_Deployments\n atau via file terlampir \nPerformance Tuning Guidelines for Large Deployments ZIMBRA\n\n\nKondisi Hardware:\n\n\n1 CPU \"Intel(R) Core(TM) i3-3220T CPU @ 2.80GHz\", RAM 16GB .\n\n\n\nreferensi:\n\n\nhttps://bugzilla.zimbra.com/show_bug.cgi?id=78661\n\n\nhttps://wiki.zimbra.com/wiki/Performance_Tuning_Guidelines_for_Large_Deployments#RAM_and_CPU\n\n\nhttp://community.zimbra.com/collaboration/f/1886/t/1140230", 
            "title": "Zimbra - Set Performance dan Tuning"
        }, 
        {
            "location": "/zimbra-mail-server-performance-dan-Tuning/#set-performance-dan-tuning-zimbra-mail-server", 
            "text": "issues:  CPU High load   HTTP ERROR     Zimbra web mail akan terasa lambat jika diakses dan kadang memunculkan http error baik 502 atau 500, dan jika dilihat dari prosesnya maka cpu akan nampak terlihat HIGH.  Solusi:  Tweak konfigurasi zimbra baik set performance   tunning.\nset value::  zimbraImapNumThreads: 400\nzimbraImapMaxConnections: 400\nmailboxd_java_heap_memory_percent = 28\nmailboxd_java_heap_new_size_percent = 25\nmailboxd_java_heap_size = 4096  jalankan:  zmprov ms `zmhostname` zimbraImapNumThreads 400\nzmprov ms `zmhostname` zimbraImapMaxConnections 400\nzmlocalconfig -e mailboxd_java_heap_memory_percent=28\nzmlocalconfig -e mailboxd_java_heap_new_size_percent=25\nzmlocalconfig -e mailboxd_java_heap_size=4096  pada  mailboxd_java_options  ditambahkan  -XX:NewRatio=2  -dan  XX:PermSize  dinaikkan dari  128m  ke  196m  ::  mailboxd_java_options = -server -Djava.awt.headless=true -Dsun.net.inetaddr.ttl=${networkaddress_cache_ttl} -Dorg.apache.jasper.compiler.disablejsr199=true -XX:+UseConcMarkSweepGC -XX:NewRatio=2 -XX:PermSize=196m -XX:MaxPermSize=350m -XX:SoftRefLRUPolicyMSPerMB=1 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -XX:-OmitStackTraceInFastThrow -Djava.net.preferIPv4Stack=true  jalankan:  zmlocalconfig -e mailboxd_java_options =\"-server -Djava.awt.headless=true -Dsun.net.inetaddr.ttl=${networkaddress_cache_ttl} -Dorg.apache.jasper.compiler.disablejsr199=true -XX:+UseConcMarkSweepGC -XX:NewRatio=2 -XX:PermSize=196m -XX:MaxPermSize=350m -XX:SoftRefLRUPolicyMSPerMB=1 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -XX:-OmitStackTraceInFastThrow -Djava.net.preferIPv4Stack=true\"   Lalu restart zimbra dengan  zmcontrol restart    monitoring:   Jika sudah stabil maka proses CPU akan nampak sedang, tidak pernah  HIGH  secara terus menerus.   Besarnya value yang diset menyesuaikan environment kondisi hardware baik CPU maupun RAM. Manual tweak zimbra dari tunning   set performance ini bisa dibaca di link:  https://wiki.zimbra.com/wiki/Performance_Tuning_Guidelines_for_Large_Deployments  atau via file terlampir  Performance Tuning Guidelines for Large Deployments ZIMBRA  Kondisi Hardware:  1 CPU \"Intel(R) Core(TM) i3-3220T CPU @ 2.80GHz\", RAM 16GB .  referensi:  https://bugzilla.zimbra.com/show_bug.cgi?id=78661  https://wiki.zimbra.com/wiki/Performance_Tuning_Guidelines_for_Large_Deployments#RAM_and_CPU  http://community.zimbra.com/collaboration/f/1886/t/1140230", 
            "title": "set Performance dan Tuning Zimbra Mail Server"
        }, 
        {
            "location": "/reject-fake-email-dari-certain-domain/", 
            "text": "Reject fake email dari certain domain\n\n\nreject email spoofing dari @abc.co.id atau pun domain yg terdaftar di mail server zimbra. caranya:\ntambahkan :\n\n\ncheck_sender_access hash:/opt/zimbra/conf/domainrestrict\n\n\n\nke dalam file  \"opt/zimbra/conf/zmconfigd/smtpd_sender_restrictions.cf\" .\n\n\nhasil akhir file \"/opt/zimbra/conf/zmconfigd/smtpd_sender_restrictions.cf\":\n\n\nzimbra@mail:~$ cat /opt/zimbra/conf/zmconfigd/smtpd_sender_restrictions.cf\n%%contains VAR:zimbraServiceEnabled antivirus^ check_sender_access regexp:/opt/zimbra/postfix/conf/tag_as_originating.re%%\n%%contains VAR:zimbraServiceEnabled antivirus^ permit_mynetworks%%\n%%contains VAR:zimbraServiceEnabled antivirus^ permit_sasl_authenticated%%\n%%contains VAR:zimbraServiceEnabled antivirus^ permit_tls_clientcerts%%\ncheck_sender_access hash:/opt/zimbra/conf/domainrestrict\n%%contains VAR:zimbraServiceEnabled antivirus^ check_sender_access regexp:/opt/zimbra/postfix/conf/tag_as_foreign.re%%\nzimbra@mail:~$\n\n\n\ncreate file \"/opt/zimbra/conf/domainrestrict\"\n\n\nabc.co.id       REJECT\nabc.com             REJECT\n\n\n\nlalu generate hash:\n\n\npostmap  /opt/zimbra/conf/domainrestrict\n\n\n\nrestart mta:\n\n\nzmmtactl restart\n\n\n\ntesting:", 
            "title": "Zimbra - Reject Fake Email Certain Domain"
        }, 
        {
            "location": "/reject-fake-email-dari-certain-domain/#reject-fake-email-dari-certain-domain", 
            "text": "reject email spoofing dari @abc.co.id atau pun domain yg terdaftar di mail server zimbra. caranya:\ntambahkan :  check_sender_access hash:/opt/zimbra/conf/domainrestrict  ke dalam file  \"opt/zimbra/conf/zmconfigd/smtpd_sender_restrictions.cf\" .  hasil akhir file \"/opt/zimbra/conf/zmconfigd/smtpd_sender_restrictions.cf\":  zimbra@mail:~$ cat /opt/zimbra/conf/zmconfigd/smtpd_sender_restrictions.cf\n%%contains VAR:zimbraServiceEnabled antivirus^ check_sender_access regexp:/opt/zimbra/postfix/conf/tag_as_originating.re%%\n%%contains VAR:zimbraServiceEnabled antivirus^ permit_mynetworks%%\n%%contains VAR:zimbraServiceEnabled antivirus^ permit_sasl_authenticated%%\n%%contains VAR:zimbraServiceEnabled antivirus^ permit_tls_clientcerts%%\ncheck_sender_access hash:/opt/zimbra/conf/domainrestrict\n%%contains VAR:zimbraServiceEnabled antivirus^ check_sender_access regexp:/opt/zimbra/postfix/conf/tag_as_foreign.re%%\nzimbra@mail:~$  create file \"/opt/zimbra/conf/domainrestrict\"  abc.co.id       REJECT\nabc.com             REJECT  lalu generate hash:  postmap  /opt/zimbra/conf/domainrestrict  restart mta:  zmmtactl restart  testing:", 
            "title": "Reject fake email dari certain domain"
        }, 
        {
            "location": "/rate-limit-user-mail-server-zimbra/", 
            "text": "Rate Limit user di Mail server Zimbra\n\n\nmail server production menggunakan zimbra dengan versi 8.0.4\n\n\nIssue:\n\n\nmembatasi user agar tidak menggunakan email yang berlebihan/spamming ketika mengirim email. dalam issue ini akan diset menjadi 300 email per jam.\n\n\nlangkah-langkah dibawah harus sudah ditest di dummy server terlebih dahulu agar tidak terjadi hal-hal yang tidak diinginkan dikarenakan ini adalah server production. backup jika diperlukan.\n\n\nInstall dan Enable service cbpolicyd:\nzmprov ms `zmhostname` +zimbraServiceInstalled cbpolicyd +zimbraServiceEnabled cbpolicyd\n\n\n\nenable policyd di postfix config:\n\n\nzmlocalconfig -e postfix_enable_smtpd_policyd=yes\nset Mta service untuk cbpolicyd:\nzmprov mcf +zimbraMtaRestriction \"check_policy_service inet:127.0.0.1:10031\"\nzmlocalconfig -e cbpolicyd_log_level=4; zmlocalconfig -e cbpolicyd_log_detail=modules,tracking,policies; zmlocalconfig -e cbpolicyd_module_accesscontrol=1 cbpolicyd_module_checkhelo=1 cbpolicyd_module_checkspf=1 cbpolicyd_module_greylisting=1 cbpolicyd_module_quotas=1\n\n\n\npindah direktory ke srv\n\n\ncd /srv/\n\n\n\ndownload paket dan ekstrak\n\n\nwget -c \"http://download.policyd.org/v2.0.14/cluebringer-v2.0.14.tar.bz2\ntar -xvf cluebringer-v2.0.14.tar.bz2\n\n\n\npindah ke directory htdocs apache dari zimbra lalu create symlink\n\n\ncd /opt/zimbra/httpd/htdocs/\nln -s /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui/ .\n\n\n\nbackup original webui bawaan zimbra:\n\n\ncp -a /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui/ /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui-backup-`date +%F_%H%M`\n\n\n\npindah ke directory /srv/cluebringer-v2.0.14\n\n\ncd /srv/cluebringer-v2.0.14/\n\n\n\nkopi file php dan css:\n\n\ncp -a *.php *.css /opt/zimbra/cbpolicyd/share/webui/\n\n\n\npindah directory lalu create .htaccess dan .htpasswd\n\n\ncd /opt/zimbra/cbpolicyd/share/webui\n\n\n\nvim .htaccess\n\n\nAuthUserFile /opt/zimbra/cbpolicyd/share/webui/.htpasswd\nAuthName \"User and Passwordasdad\"\nAuthType Basic\nRequire valid-user\n\n\n\ncreate user password menggunakan htpasswd.\n\n\nvim /opt/zimbra/cbpolicyd/share/webui/.htpasswd\n\n\n\nedit database config:\n\n\ncd /opt/zimbra/cbpolicyd/share/webui/includes/\nvim config.php\nubah type database:\n$DB_DSN=\"sqlite:/opt/zimbra/data/cbpolicyd/db/cbpolicyd.sqlitedb\";\n\n\n\ntambahkan diakhir baris /opt/zimbra/conf/httpd.conf :\n\n\nvim /opt/zimbra/conf/httpd.conf\nAlias /webui /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui/\n# Comment out the following 3 lines to make web ui accessible from anywhere\n\nDirectory \"/opt/zimbra/cbpolicyd-2.1.0-beta/share/webui\"\n\nOptions FollowSymLinks MultiViews\nAllowOverride All\nOrder allow,deny\nallow from all\n\n/Directory\n\n\n\n\nRestart zimbra apache, mta, dan cbpolicyd:\n\n\nzmapachectl restart\nzmmtactl restart\nzmcbpolicydctl restart\n\n\n\nlalu akses ke url mailserver.domain:7780/webui/index.php (http://117.102.64.35:7780/webui/index.php). dan ketika mengakses url ini seharusnya meminta password. check kembali konfigurasi dari zimbra apache jika tidak meminta password.\npastikan rule htaccess berjalan, karena ini security utama untuk interface cbpolicyd daemon.\n\n\nJika service sudah terinstall dan konfigurasi service sudah ok. kini tinggal mengkonfigurasi untuk rule dari cbpolicyd .\n\n\n\n\n\n\nPilih Menu Quotas configure. Lalu klik no 1 dengan Test Policy, pilih select Action Change:\n    a. Ubah Link to Policy menjadi Default.\n    b. Track menjadi Sender:user@domain\n    c.  Data diisi: Maksimal 300 email per jam\n    d. lalu klik submit\n\n\n\n\n\n\nKlik back to Quotas, lalu klik no 1 dengan Default Policy, pilih select Action Limit:\n    a. klik Type Messages Count, lalu select Action Change\n    b. Ubah Counter Limit menjadi 300.\n    c. selesai\n\n\n\n\n\n\nUntuk testing bisa dengan nilai limit yang kecil, misal 2 email.\n\n\nHasil:\n\n\nIT-Infra \n Rate Limit user zimbra di Mail server production \n maksimal.png\n\n\nIT-Infra \n Rate Limit user zimbra di Mail server production \n logmaksimal.png\n\n\nRef:\n\n\nhttps://wiki.zimbra.com/wiki/How-to_for_cbpolicyd\nhttp://www.excellent.co.id/product-services/zimbra/tips-zimbra-instalasi-policyd-rate-limit-sending-message-pada-zimbra-versi-8/\nhttps://www.excellent.co.id/product-services/zimbra/tips-zimbra-membatasi-pengiriman-emailrate-limit-sending-message-dengan-policyd/comment-page-1/#comment-93128\nhttps://www.vavai.net/2014/02/zimbra-tips-policyd-rate-limit-sending-message-implementation-on-zimbra-8/\nhttps://www.vavai.net/2014/02/zimbra-tips-rate-limit-sending-message-with-policyd/\nhttps://www.vavai.net/2014/02/zimbra-tips-how-to-secure-policyd-web-admin/", 
            "title": "Zimbra - Rate Limit user di Mail server Zimbra"
        }, 
        {
            "location": "/rate-limit-user-mail-server-zimbra/#rate-limit-user-di-mail-server-zimbra", 
            "text": "mail server production menggunakan zimbra dengan versi 8.0.4  Issue:  membatasi user agar tidak menggunakan email yang berlebihan/spamming ketika mengirim email. dalam issue ini akan diset menjadi 300 email per jam.  langkah-langkah dibawah harus sudah ditest di dummy server terlebih dahulu agar tidak terjadi hal-hal yang tidak diinginkan dikarenakan ini adalah server production. backup jika diperlukan.  Install dan Enable service cbpolicyd:\nzmprov ms `zmhostname` +zimbraServiceInstalled cbpolicyd +zimbraServiceEnabled cbpolicyd  enable policyd di postfix config:  zmlocalconfig -e postfix_enable_smtpd_policyd=yes\nset Mta service untuk cbpolicyd:\nzmprov mcf +zimbraMtaRestriction \"check_policy_service inet:127.0.0.1:10031\"\nzmlocalconfig -e cbpolicyd_log_level=4; zmlocalconfig -e cbpolicyd_log_detail=modules,tracking,policies; zmlocalconfig -e cbpolicyd_module_accesscontrol=1 cbpolicyd_module_checkhelo=1 cbpolicyd_module_checkspf=1 cbpolicyd_module_greylisting=1 cbpolicyd_module_quotas=1  pindah direktory ke srv  cd /srv/  download paket dan ekstrak  wget -c \"http://download.policyd.org/v2.0.14/cluebringer-v2.0.14.tar.bz2\ntar -xvf cluebringer-v2.0.14.tar.bz2  pindah ke directory htdocs apache dari zimbra lalu create symlink  cd /opt/zimbra/httpd/htdocs/\nln -s /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui/ .  backup original webui bawaan zimbra:  cp -a /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui/ /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui-backup-`date +%F_%H%M`  pindah ke directory /srv/cluebringer-v2.0.14  cd /srv/cluebringer-v2.0.14/  kopi file php dan css:  cp -a *.php *.css /opt/zimbra/cbpolicyd/share/webui/  pindah directory lalu create .htaccess dan .htpasswd  cd /opt/zimbra/cbpolicyd/share/webui  vim .htaccess  AuthUserFile /opt/zimbra/cbpolicyd/share/webui/.htpasswd\nAuthName \"User and Passwordasdad\"\nAuthType Basic\nRequire valid-user  create user password menggunakan htpasswd.  vim /opt/zimbra/cbpolicyd/share/webui/.htpasswd  edit database config:  cd /opt/zimbra/cbpolicyd/share/webui/includes/\nvim config.php\nubah type database:\n$DB_DSN=\"sqlite:/opt/zimbra/data/cbpolicyd/db/cbpolicyd.sqlitedb\";  tambahkan diakhir baris /opt/zimbra/conf/httpd.conf :  vim /opt/zimbra/conf/httpd.conf\nAlias /webui /opt/zimbra/cbpolicyd-2.1.0-beta/share/webui/\n# Comment out the following 3 lines to make web ui accessible from anywhere Directory \"/opt/zimbra/cbpolicyd-2.1.0-beta/share/webui\" \nOptions FollowSymLinks MultiViews\nAllowOverride All\nOrder allow,deny\nallow from all /Directory   Restart zimbra apache, mta, dan cbpolicyd:  zmapachectl restart\nzmmtactl restart\nzmcbpolicydctl restart  lalu akses ke url mailserver.domain:7780/webui/index.php (http://117.102.64.35:7780/webui/index.php). dan ketika mengakses url ini seharusnya meminta password. check kembali konfigurasi dari zimbra apache jika tidak meminta password.\npastikan rule htaccess berjalan, karena ini security utama untuk interface cbpolicyd daemon.  Jika service sudah terinstall dan konfigurasi service sudah ok. kini tinggal mengkonfigurasi untuk rule dari cbpolicyd .    Pilih Menu Quotas configure. Lalu klik no 1 dengan Test Policy, pilih select Action Change:\n    a. Ubah Link to Policy menjadi Default.\n    b. Track menjadi Sender:user@domain\n    c.  Data diisi: Maksimal 300 email per jam\n    d. lalu klik submit    Klik back to Quotas, lalu klik no 1 dengan Default Policy, pilih select Action Limit:\n    a. klik Type Messages Count, lalu select Action Change\n    b. Ubah Counter Limit menjadi 300.\n    c. selesai    Untuk testing bisa dengan nilai limit yang kecil, misal 2 email.  Hasil:  IT-Infra   Rate Limit user zimbra di Mail server production   maksimal.png  IT-Infra   Rate Limit user zimbra di Mail server production   logmaksimal.png  Ref:  https://wiki.zimbra.com/wiki/How-to_for_cbpolicyd\nhttp://www.excellent.co.id/product-services/zimbra/tips-zimbra-instalasi-policyd-rate-limit-sending-message-pada-zimbra-versi-8/\nhttps://www.excellent.co.id/product-services/zimbra/tips-zimbra-membatasi-pengiriman-emailrate-limit-sending-message-dengan-policyd/comment-page-1/#comment-93128\nhttps://www.vavai.net/2014/02/zimbra-tips-policyd-rate-limit-sending-message-implementation-on-zimbra-8/\nhttps://www.vavai.net/2014/02/zimbra-tips-rate-limit-sending-message-with-policyd/\nhttps://www.vavai.net/2014/02/zimbra-tips-how-to-secure-policyd-web-admin/", 
            "title": "Rate Limit user di Mail server Zimbra"
        }, 
        {
            "location": "/zimbra-mail-queue/", 
            "text": "Zimbra - Monitoring Queue Mail\n\n\nMonitoring Queue Mail Zimbra dengan menggunakan postqueue di bash script. auto monitor queue mail zimbra. ketika queue (antrian email melebihi 75 email) maka otomatis akan memberitahukan ke user@email . Jika sudah turun dibawah 75 akan diberikan status OK.\n\n\n#!/bin/bash\n#count=76\ncount=$(/opt/zimbra/postfix/sbin/postqueue -p | awk '{ print $1 }' | grep \"@\" | wc -l)\nif [ \"$count\" -ge \"75\" ];then\n    #true\n        grep \"lock\" /tmp/queue.lock\n        #if false\n        if [ \"$?\" -eq \"1\" ];then\n        #send notice here down\n        # echo \"gt 10\"   \n                until [ \"$count\" -lt \"75\" ]; \n                    do \n                #sleep 60\n                        count=$(/opt/zimbra/postfix/sbin/postqueue -p | awk '{ print $1 }' | grep \"@\" | wc -l)\n                            if [ \"$count\" -ge \"75\" ];then\n                            echo \"send notice here down\"\n                            #       echo \"gt 10\"\n                            fi\n                        echo \"lock\" \n /tmp/queue.lock\n                        sleep 60\n                done\n            echo \"send notice here up\"\n            ##      echo \"lt 10\"\n        echo \"\" \n /tmp/queue.lock\n        fi\nfi\n\n\n\nlalu simpan di dalam crontab:\n\n\n#monitor mail queue\n*/10 * * * * /bin/bash /opt/zimbra/backup/scripts/monitorqueue/run.sh", 
            "title": "Zimbra - Monitoring Queue Mail"
        }, 
        {
            "location": "/zimbra-mail-queue/#zimbra-monitoring-queue-mail", 
            "text": "Monitoring Queue Mail Zimbra dengan menggunakan postqueue di bash script. auto monitor queue mail zimbra. ketika queue (antrian email melebihi 75 email) maka otomatis akan memberitahukan ke user@email . Jika sudah turun dibawah 75 akan diberikan status OK.  #!/bin/bash\n#count=76\ncount=$(/opt/zimbra/postfix/sbin/postqueue -p | awk '{ print $1 }' | grep \"@\" | wc -l)\nif [ \"$count\" -ge \"75\" ];then\n    #true\n        grep \"lock\" /tmp/queue.lock\n        #if false\n        if [ \"$?\" -eq \"1\" ];then\n        #send notice here down\n        # echo \"gt 10\"   \n                until [ \"$count\" -lt \"75\" ]; \n                    do \n                #sleep 60\n                        count=$(/opt/zimbra/postfix/sbin/postqueue -p | awk '{ print $1 }' | grep \"@\" | wc -l)\n                            if [ \"$count\" -ge \"75\" ];then\n                            echo \"send notice here down\"\n                            #       echo \"gt 10\"\n                            fi\n                        echo \"lock\"   /tmp/queue.lock\n                        sleep 60\n                done\n            echo \"send notice here up\"\n            ##      echo \"lt 10\"\n        echo \"\"   /tmp/queue.lock\n        fi\nfi  lalu simpan di dalam crontab:  #monitor mail queue\n*/10 * * * * /bin/bash /opt/zimbra/backup/scripts/monitorqueue/run.sh", 
            "title": "Zimbra - Monitoring Queue Mail"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/", 
            "text": "build RBL DNS untuk anti spam based ip address\n\n\nRequirements:\n\n\nMySQL server. Menggunakan mysql server. pastikan telah terinstall dengan baik. pada percobaan kali ini dengan Os CentOs 6.5\n\n\npersiapkan database, username dan password untuk akses mysql. create database misal: rbldns\n\n\nmysql\n create database rbldns;\nmysql\n grant all privileges on rbldns.* to 'rbldns'@'localhost' identified by 'rbl1231';\nlalu create table ips di database rbldns;\nCREATE TABLE `ips` (\n  `id` int(16) NOT NULL AUTO_INCREMENT,\n  `ipaddress` varchar(40) NOT NULL DEFAULT '',\n  `dateadded` datetime NOT NULL DEFAULT '0000-00-00 00:00:00',\n  `reportedby` varchar(40) DEFAULT NULL,\n  `updated` datetime DEFAULT NULL,\n  `attacknotes` text,\n  `b_or_w` char(1) NOT NULL DEFAULT 'b',\n  PRIMARY KEY (`id`),\n  KEY `dateadded` (`dateadded`),\n  KEY `b_or_w` (`b_or_w`)\n) ENGINE=MyISAM AUTO_INCREMENT=189220 DEFAULT CHARSET=latin1 COMMENT='spammer list';\n\n\n\nsampai di sini database untuk rbl dns sudah siap.\nRBL DNS daemon. menggunakan rbldnsd (http://www.corpit.ru/mjt/rbldnsd.html).\n\n\ninstallasi\n\n\n# wget -c \"http://www.corpit.ru/mjt/rbldnsd/rbldnsd-0.997a.tar.gz\"\n# tar -xvf rbldnsd-0.997a.tar.gz \n# cd rbldnsd-0.997a\n# ./configure \n# make\n# cp -a rbldnsd /usr/local/sbin/rbldnsd\n\n\n\nKonfigurasi\n\n\ntambahkan user rbldns yang akan digunakan sebagai daemon user:\n\n\nuseradd rbldns\n\n\n\ncreate directory\n\n\n# mkdir -p /var/lib/rbldns/{dsbl,log}\n\n\n\ncreate file konfig\n\n\n# touch /var/lib/rbldns/dsbl/{dsbl,rbl,forward,spammerlist,whitelist,rbl.log}\n# touch /var/lib/rbldns/log/rbl.log\n\n\n\nunduh file rebuild rbldns yang akan digunakan untuk export dari mysql ke dalam bentuk file txt (spammerlist).\n\n\n# wget -O /usr/local/bin/rebuild_rbldns.pl http://www.blue-quartz.com/rbl/rebuild_rbldns.txt\n\n\n\nchmod 750 lalu edit\n\n\n# chmod 750 /usr/local/bin/rebuild_rbldns.pl\n# vim /usr/local/bin/rebuild_rbldns.pl\n\n\n\nedit user, pass, nama database yang sesuai.\n\n\n#!/usr/bin/perl\n# rebuild_rbldns.pl\n# Copyright (c) 2006 by Herb Rubin herbr@pfinders.com covered under GPL license\n$version = \"1.01\"; # Mar 20, 2009\n#\n# Purpose: rebuild a flatfile of IP addresses from mysql ips table for RBL blacklist server\n# Expects: database table named ips\n#\n# CREATE TABLE `ips` (\n#  `ipaddress` varchar(15) NOT NULL default '',\n#  `dateadded` datetime NOT NULL default '0000-00-00 00:00:00',\n#  `reportedby` varchar(40) default NULL,\n#  `updated` datetime default NULL,\n#  `attacknotes` text,\n#  `b_or_w` char(1) NOT NULL default 'b',\n#  PRIMARY KEY  (`ipaddress`),\n#  KEY `dateadded` (`dateadded`),\n#  KEY `b_or_w` (`b_or_w`)\n#) ENGINE=MyISAM DEFAULT CHARSET=latin1 COMMENT='spammer list';\n#\n# Begin User Defined Section\n#----------------------------\nmy $blacklist_file = \"/var/lib/rbldns/dsbl/spammerlist\";\nmy $whitelist_file = \"/var/lib/rbldns/dsbl/whitelist\";\nmy $rbl_domain     = \"rbldns.abc.co.id\";\nmy $mysql_user     = \"rbldns\";\nmy $mysql_pass     = \"pass\";\nmy $mysql_database = \"rbldns\";\nmy $mysql_host     = \"localhost\";\nmy $datasource     = \"dbi:mysql:database=$mysql_database;host=$mysql_host\";\nmy $temp_file      = \"/var/lib/rbldns/dsbl/templist\";\n#----------------------------\n# End User Defined Section\n$progname = $0;\n$progname = $1 if ($progname =~ /([\\w\\._]+)$/); # trim off path\nuse Getopt::Std;\nuse DBI;\n\n$pid = $$;\n\ngetopts(\"fhvV\",\\%Options);\n\nusage if ($Options{'h'}); # then exit\nmy $dbh;\n\nif ($Options{\"V\"}) {\n    print \"$progname version $version\\n\";\n    exit 0; # good exit\n}\nif ($dbh = DBI-\nconnect($datasource, $mysql_user, $mysql_pass, { PrintError =\n 0, RaiseError =\n 0 }) ) {\n    #########################\n    # Logged in to database #\n    #########################\n    \nbuild_file($blacklist_file, \"b\"); \n    \nbuild_file($whitelist_file, \"w\");\n    $dbh-\ndisconnect;\n} else {\n    #################################\n    # failed to connect to database #\n    #################################\n    print DBI-\nerrstr . \"\\n\" if ($Options{'v'});\n    print \"Error: Could not connect to local MySQL database. (did password change?)\\n\";\n    exit 1; # bad exit\n}\nexit;\n##########################\n# subroutines start here #\n##########################\nsub usage {\n    print \nEOF;\n$progname usage:\n\n   $progname [-hmtvV]\n   Rebuild the rbl dns flat file from a mysql database.\n   rbl means relay blacklist.\n\n   Recommendation: Run this as a cronjob on a regular basis.\n where:\n    -h         Display this help\n    -v         Verbose mode\n    -V         Show $progname version.\nEOF\n}\nsub build_file {\n###########################################################\n# create a file from mysql, either blacklist or whitelist #\n###########################################################\n  my ($file, $type) = @_;\n  if (open RBL, \"\n$temp_file\") {\n      #########################################\n      # first line of file is always the same #\n      #########################################\n      print RBL \":127.0.0.2:spammer must die -netsysadmin k24-\\n\";\n      my $sql = \"SELECT ipaddress FROM ips WHERE b_or_w='$type' ORDER BY dateadded, ipaddress\";\n      my $sth = $dbh-\nprepare($sql);\n      $sth-\nexecute;\n      my $count = 0;\n      while ($hash_ref   = $sth-\nfetchrow_hashref) {\n         my $ipaddress   = $$hash_ref{'ipaddress'};\n         #my $dateadded   = $$hash_ref{'dateadded'};\n         #my $reportedby  = $$hash_ref{'reportedby'};\n         #my $updated     = $$hash_ref{'updated'};\n         #my $attacknotes = $$hash_ref{'attacknotes'};\n         #my $borw        = $$hash_ref{'borw'};\n         $count ++;\n         if ($type eq \"w\") {\n             print RBL \"!$ipaddress\\n\";\n         } else {\n             print RBL \"$ipaddress\\n\";\n         }\n      }\n      close RBL;\n      `mv $temp_file $file`;\n      print \"$count ips of type $type\\n\" if ($Options{'v'});\n  } else {\n      print \"Failed to open $file for writing\\n\";\n  }\n}\n\n\n\ncreate file script daemon untuk rbl dns seperti dibawah ini:\nsimpan dengan nama /etc/sysconfig/rbldnsd:\n\n\n# My boot rbldnsd options\n# -----------------------------------------\n# TTL 35m, check files every 60s for changes, -f = smooth reloads\n# -l logfilepath\n# Please change 101.102.103.104 to your real public IP that you want the dns daemon to listen on\n# Please change mydomain.com to your real domain name.\n#\n#RBLDNSD=\"-u rbldnsd -l /var/lib/rbldns/log/rbl.log -f -r/var/lib/rbldns/dsbl -b 192.168.1.50 rbldns.abc.co.id:ip4set:spammerlist,whitelist rbldns.abc.co.id:generic:forward\"\nOPTIONS=\"-u rbldns -p /var/run/rbldnsd.pid -l /var/lib/rbldns/log/rbl.log -f -r/var/lib/rbldns/dsbl -b 0.0.0.0 rbldns.abc.co.id:ip4set:spammerlist,whitelist rbldns.abc.co.id:generic:forward\"\n\n\n\nsimpan dengan nama /etc/init.d/rbldnsd:\n\n\n#!/bin/bash\n#\n# chkconfig: 2345 85 15\n# description: rbldnsd is a DNS server designed for dnsbls.  \n# processname: rbldnsd\n# pidfile: /var/run/rbldnsd.pid\n# source function library\n. /etc/init.d/functions\n\nprog=\"rbldnsd\"\nlockfile=/var/lock/subsys/$prog\nPID_FILE=/var/run/rbldnsd.pid\n[ -e /etc/sysconfig/rbldnsd ] \n . /etc/sysconfig/rbldnsd \nRETVAL=0\nstart() {\n        echo -n $\"Starting rbldnsd service: \"\n        daemon /usr/local/sbin/rbldnsd $OPTIONS\n        RETVAL=$?\n        echo\n        [ $RETVAL -eq 0 ] \n touch /var/lock/subsys/rbldnsd\n}\nstop() {\n        echo -n $\"Shutting down rbldnsd service: \"\n        killproc rbldnsd\n        RETVAL=$?\n        echo\n        [ $RETVAL -eq 0 ] \n rm -f /var/lock/subsys/rbldnsd\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart|reload)\n        stop\n        start\n        RETVAL=$?\n        ;;\n  condrestart)\n        if [ -f /var/lock/subsys/rbldnsd ]; then\n            stop\n            start\n            RETVAL=$?\n        fi\n        ;;\n  status)\n        status -p $PID_FILE rbldnsd\n        RETVAL=$?\n                if [ $RETVAL -eq 3 -a -f $lockfile ] ; then\n                        RETVAL=2\n                fi\n        ;;\n  *)\n        echo $\"Usage: $0 {start|stop|restart|condrestart|status}\"\n        exit 1\nesac\nexit $RETVAL\n\n\n\nstart daemon rbldns\n\n\n# chmod a+x /etc/init.d/rbldnsd\n# /etc/init.d/rbldnsd start\n\n\n\nlalu cek service apakah sudah listen atau belum:\n\n\n[root@rbldns ~]# netstat -ntlpu | grep rbldns\nudp        0      0 0.0.0.0:53                  0.0.0.0:*                               7237/rbldnsd        \n[root@rbldns ~]#\n\n\n\nJika sudah listen smpai dengan langkah ini sudah ready untuk digunakan.\n\n\nSetting DNS untuk rbldns.abc.co.id\n\n\nAgar RBL DNS dapat digunakan di mail server, khususnya zimbra maka kita perlu menambahkan dns ns record rbldns.abc.co.id (misalnya) ke dns manager dari abc.co.id\n\n\nsetting NS record\n\n\n\n\nlalu setting a records daripada a.rbldns.abc.co.id\n\n\n\n\nPastikan Firewall Mikrotik sudah disetup port forwarding 53 udp dari ip  202.169.239.180 ke ip internal 192.168.1.50\n\n\nTesting:\n\n\nUntuk menguji apakah RBL DNS sudah berjalan sebelum diterapkan di mail server bisa dengan cara berikut:\ninsert ip dengan perintah:\n\n\nmysql\n INSERT INTO ips SET  ipaddress='207.126.164.135',  reportedby='manual',  attacknotes='spammers',  b_or_w='b',  dateadded=now(),  updated=now();\"\nJika sudah, lalu build dan restart services rbldnsd:\n[root@rbldns tmp]# /usr/local/bin/rebuild_rbldns.pl;/etc/init.d/rbldnsd restart\nShutting down rbldnsd service:                             [  OK  ]\nStarting rbldnsd service: rbldnsd: listening on 0.0.0.0/53\nrbldnsd: ip4set:spammerlist,whitelist: 20150518 022140: e32/24/16/8=189204/0/0/0\nrbldnsd: generic:forward: 20140617 122159: e=0\nrbldnsd: zones reloaded, time 0.2e/0.2u sec, mem arena=280 free=129 mmap=2960 Kb\nrbldnsd: rbldnsd version 0.997a (23 Jul 2013) started (1 socket(s), 1 zone(s))\n                                                           [  OK  ]\n[root@rbldns tmp]#\n\n\n\ncek file spammerlist\n\n\n[root@rbldns ~]# cat /var/lib/rbldns/dsbl/spammerlist | grep 207.126.164.135\n207.126.164.135\n[root@rbldns ~]#\n\n\n\nip yang diblok sudah masuk kedalam list,.\n\n\ncek terakhir via lookup dig dns.\n\n\ndian@it-infra ~ $ dig 135.164.126.207.rbldns.abc.co.id @202.169.239.180\n; \n DiG 9.9.5-3-Ubuntu \n 135.164.126.207.rbldns.abc.co.id @202.169.239.180\n;; global options: +cmd\n;; Got answer:\n;; -\nHEADER\n- opcode: QUERY, status: NOERROR, id: 64533\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 2\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;135.164.126.207.rbldns.abc.co.id. IN   A\n;; ANSWER SECTION:\n135.164.126.207.rbldns.abc.co.id. 2100 IN A 127.0.0.2\n;; AUTHORITY SECTION:\nrbldns.abc.co.id.   1800    IN  NS  a.rbldns.abc.co.id.\n;; ADDITIONAL SECTION:\na.rbldns.abc.co.id. 1800    IN  A   202.169.239.180\n;; Query time: 302 msec\n;; SERVER: 202.169.239.180#53(202.169.239.180)\n;; WHEN: Mon May 18 10:21:36 WIB 2015\n;; MSG SIZE  rcvd: 109\n\n\n\nJika ada answer, dengan results 127.0.0.2 , maka ip sudah masuk ke RBL DNS. dan sudah bekerja dengan baik. Jika tidak ada results, maka ip tidak diblok.\n\n\ndian@it-infra ~ $ dig 35.64.102.117.rbldns.abc.co.id @202.169.239.180\n; \n DiG 9.9.5-3-Ubuntu \n 35.64.102.117.rbldns.abc.co.id @202.169.239.180\n;; global options: +cmd\n;; Got answer:\n;; -\nHEADER\n- opcode: QUERY, status: NXDOMAIN, id: 50561\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;35.64.102.117.rbldns.abc.co.id.    IN  A\n;; Query time: 134 msec\n;; SERVER: 202.169.239.180#53(202.169.239.180)\n;; WHEN: Mon May 18 10:23:38 WIB 2015\n;; MSG SIZE  rcvd: 59\ndian@it-infra ~ $\n\n\n\nLangkah terakhir memasang RBL DNS di zimbra mudah sekali, cukup seperti digambar bawah ini lalu save dan restart services \n\n\n\n\nrestart services amavis dan milter\n\n\nzmamavisdctl reload\nzmmtactl reload\n\n\n\nResults:\n\n\n\n\nref: \n\nhttp://www.blue-quartz.com/rbl/", 
            "title": "Zimbra - build RBL DNS untuk anti spam based ip address"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#build-rbl-dns-untuk-anti-spam-based-ip-address", 
            "text": "", 
            "title": "build RBL DNS untuk anti spam based ip address"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#requirements", 
            "text": "", 
            "title": "Requirements:"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#mysql-server-menggunakan-mysql-server-pastikan-telah-terinstall-dengan-baik-pada-percobaan-kali-ini-dengan-os-centos-65", 
            "text": "persiapkan database, username dan password untuk akses mysql. create database misal: rbldns  mysql  create database rbldns;\nmysql  grant all privileges on rbldns.* to 'rbldns'@'localhost' identified by 'rbl1231';\nlalu create table ips di database rbldns;\nCREATE TABLE `ips` (\n  `id` int(16) NOT NULL AUTO_INCREMENT,\n  `ipaddress` varchar(40) NOT NULL DEFAULT '',\n  `dateadded` datetime NOT NULL DEFAULT '0000-00-00 00:00:00',\n  `reportedby` varchar(40) DEFAULT NULL,\n  `updated` datetime DEFAULT NULL,\n  `attacknotes` text,\n  `b_or_w` char(1) NOT NULL DEFAULT 'b',\n  PRIMARY KEY (`id`),\n  KEY `dateadded` (`dateadded`),\n  KEY `b_or_w` (`b_or_w`)\n) ENGINE=MyISAM AUTO_INCREMENT=189220 DEFAULT CHARSET=latin1 COMMENT='spammer list';  sampai di sini database untuk rbl dns sudah siap.\nRBL DNS daemon. menggunakan rbldnsd (http://www.corpit.ru/mjt/rbldnsd.html).", 
            "title": "MySQL server. Menggunakan mysql server. pastikan telah terinstall dengan baik. pada percobaan kali ini dengan Os CentOs 6.5"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#installasi", 
            "text": "# wget -c \"http://www.corpit.ru/mjt/rbldnsd/rbldnsd-0.997a.tar.gz\"\n# tar -xvf rbldnsd-0.997a.tar.gz \n# cd rbldnsd-0.997a\n# ./configure \n# make\n# cp -a rbldnsd /usr/local/sbin/rbldnsd", 
            "title": "installasi"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#konfigurasi", 
            "text": "tambahkan user rbldns yang akan digunakan sebagai daemon user:  useradd rbldns  create directory  # mkdir -p /var/lib/rbldns/{dsbl,log}", 
            "title": "Konfigurasi"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#create-file-konfig", 
            "text": "# touch /var/lib/rbldns/dsbl/{dsbl,rbl,forward,spammerlist,whitelist,rbl.log}\n# touch /var/lib/rbldns/log/rbl.log  unduh file rebuild rbldns yang akan digunakan untuk export dari mysql ke dalam bentuk file txt (spammerlist).  # wget -O /usr/local/bin/rebuild_rbldns.pl http://www.blue-quartz.com/rbl/rebuild_rbldns.txt  chmod 750 lalu edit  # chmod 750 /usr/local/bin/rebuild_rbldns.pl\n# vim /usr/local/bin/rebuild_rbldns.pl  edit user, pass, nama database yang sesuai.  #!/usr/bin/perl\n# rebuild_rbldns.pl\n# Copyright (c) 2006 by Herb Rubin herbr@pfinders.com covered under GPL license\n$version = \"1.01\"; # Mar 20, 2009\n#\n# Purpose: rebuild a flatfile of IP addresses from mysql ips table for RBL blacklist server\n# Expects: database table named ips\n#\n# CREATE TABLE `ips` (\n#  `ipaddress` varchar(15) NOT NULL default '',\n#  `dateadded` datetime NOT NULL default '0000-00-00 00:00:00',\n#  `reportedby` varchar(40) default NULL,\n#  `updated` datetime default NULL,\n#  `attacknotes` text,\n#  `b_or_w` char(1) NOT NULL default 'b',\n#  PRIMARY KEY  (`ipaddress`),\n#  KEY `dateadded` (`dateadded`),\n#  KEY `b_or_w` (`b_or_w`)\n#) ENGINE=MyISAM DEFAULT CHARSET=latin1 COMMENT='spammer list';\n#\n# Begin User Defined Section\n#----------------------------\nmy $blacklist_file = \"/var/lib/rbldns/dsbl/spammerlist\";\nmy $whitelist_file = \"/var/lib/rbldns/dsbl/whitelist\";\nmy $rbl_domain     = \"rbldns.abc.co.id\";\nmy $mysql_user     = \"rbldns\";\nmy $mysql_pass     = \"pass\";\nmy $mysql_database = \"rbldns\";\nmy $mysql_host     = \"localhost\";\nmy $datasource     = \"dbi:mysql:database=$mysql_database;host=$mysql_host\";\nmy $temp_file      = \"/var/lib/rbldns/dsbl/templist\";\n#----------------------------\n# End User Defined Section\n$progname = $0;\n$progname = $1 if ($progname =~ /([\\w\\._]+)$/); # trim off path\nuse Getopt::Std;\nuse DBI;\n\n$pid = $$; getopts(\"fhvV\",\\%Options); usage if ($Options{'h'}); # then exit\nmy $dbh;\n\nif ($Options{\"V\"}) {\n    print \"$progname version $version\\n\";\n    exit 0; # good exit\n}\nif ($dbh = DBI- connect($datasource, $mysql_user, $mysql_pass, { PrintError =  0, RaiseError =  0 }) ) {\n    #########################\n    # Logged in to database #\n    #########################\n     build_file($blacklist_file, \"b\"); \n     build_file($whitelist_file, \"w\");\n    $dbh- disconnect;\n} else {\n    #################################\n    # failed to connect to database #\n    #################################\n    print DBI- errstr . \"\\n\" if ($Options{'v'});\n    print \"Error: Could not connect to local MySQL database. (did password change?)\\n\";\n    exit 1; # bad exit\n}\nexit;\n##########################\n# subroutines start here #\n##########################\nsub usage {\n    print  EOF;\n$progname usage:\n\n   $progname [-hmtvV]\n   Rebuild the rbl dns flat file from a mysql database.\n   rbl means relay blacklist.\n\n   Recommendation: Run this as a cronjob on a regular basis.\n where:\n    -h         Display this help\n    -v         Verbose mode\n    -V         Show $progname version.\nEOF\n}\nsub build_file {\n###########################################################\n# create a file from mysql, either blacklist or whitelist #\n###########################################################\n  my ($file, $type) = @_;\n  if (open RBL, \" $temp_file\") {\n      #########################################\n      # first line of file is always the same #\n      #########################################\n      print RBL \":127.0.0.2:spammer must die -netsysadmin k24-\\n\";\n      my $sql = \"SELECT ipaddress FROM ips WHERE b_or_w='$type' ORDER BY dateadded, ipaddress\";\n      my $sth = $dbh- prepare($sql);\n      $sth- execute;\n      my $count = 0;\n      while ($hash_ref   = $sth- fetchrow_hashref) {\n         my $ipaddress   = $$hash_ref{'ipaddress'};\n         #my $dateadded   = $$hash_ref{'dateadded'};\n         #my $reportedby  = $$hash_ref{'reportedby'};\n         #my $updated     = $$hash_ref{'updated'};\n         #my $attacknotes = $$hash_ref{'attacknotes'};\n         #my $borw        = $$hash_ref{'borw'};\n         $count ++;\n         if ($type eq \"w\") {\n             print RBL \"!$ipaddress\\n\";\n         } else {\n             print RBL \"$ipaddress\\n\";\n         }\n      }\n      close RBL;\n      `mv $temp_file $file`;\n      print \"$count ips of type $type\\n\" if ($Options{'v'});\n  } else {\n      print \"Failed to open $file for writing\\n\";\n  }\n}  create file script daemon untuk rbl dns seperti dibawah ini:\nsimpan dengan nama /etc/sysconfig/rbldnsd:  # My boot rbldnsd options\n# -----------------------------------------\n# TTL 35m, check files every 60s for changes, -f = smooth reloads\n# -l logfilepath\n# Please change 101.102.103.104 to your real public IP that you want the dns daemon to listen on\n# Please change mydomain.com to your real domain name.\n#\n#RBLDNSD=\"-u rbldnsd -l /var/lib/rbldns/log/rbl.log -f -r/var/lib/rbldns/dsbl -b 192.168.1.50 rbldns.abc.co.id:ip4set:spammerlist,whitelist rbldns.abc.co.id:generic:forward\"\nOPTIONS=\"-u rbldns -p /var/run/rbldnsd.pid -l /var/lib/rbldns/log/rbl.log -f -r/var/lib/rbldns/dsbl -b 0.0.0.0 rbldns.abc.co.id:ip4set:spammerlist,whitelist rbldns.abc.co.id:generic:forward\"  simpan dengan nama /etc/init.d/rbldnsd:  #!/bin/bash\n#\n# chkconfig: 2345 85 15\n# description: rbldnsd is a DNS server designed for dnsbls.  \n# processname: rbldnsd\n# pidfile: /var/run/rbldnsd.pid\n# source function library\n. /etc/init.d/functions\n\nprog=\"rbldnsd\"\nlockfile=/var/lock/subsys/$prog\nPID_FILE=/var/run/rbldnsd.pid\n[ -e /etc/sysconfig/rbldnsd ]   . /etc/sysconfig/rbldnsd \nRETVAL=0\nstart() {\n        echo -n $\"Starting rbldnsd service: \"\n        daemon /usr/local/sbin/rbldnsd $OPTIONS\n        RETVAL=$?\n        echo\n        [ $RETVAL -eq 0 ]   touch /var/lock/subsys/rbldnsd\n}\nstop() {\n        echo -n $\"Shutting down rbldnsd service: \"\n        killproc rbldnsd\n        RETVAL=$?\n        echo\n        [ $RETVAL -eq 0 ]   rm -f /var/lock/subsys/rbldnsd\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart|reload)\n        stop\n        start\n        RETVAL=$?\n        ;;\n  condrestart)\n        if [ -f /var/lock/subsys/rbldnsd ]; then\n            stop\n            start\n            RETVAL=$?\n        fi\n        ;;\n  status)\n        status -p $PID_FILE rbldnsd\n        RETVAL=$?\n                if [ $RETVAL -eq 3 -a -f $lockfile ] ; then\n                        RETVAL=2\n                fi\n        ;;\n  *)\n        echo $\"Usage: $0 {start|stop|restart|condrestart|status}\"\n        exit 1\nesac\nexit $RETVAL  start daemon rbldns  # chmod a+x /etc/init.d/rbldnsd\n# /etc/init.d/rbldnsd start  lalu cek service apakah sudah listen atau belum:  [root@rbldns ~]# netstat -ntlpu | grep rbldns\nudp        0      0 0.0.0.0:53                  0.0.0.0:*                               7237/rbldnsd        \n[root@rbldns ~]#  Jika sudah listen smpai dengan langkah ini sudah ready untuk digunakan.  Setting DNS untuk rbldns.abc.co.id  Agar RBL DNS dapat digunakan di mail server, khususnya zimbra maka kita perlu menambahkan dns ns record rbldns.abc.co.id (misalnya) ke dns manager dari abc.co.id", 
            "title": "create file konfig"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#setting-ns-record", 
            "text": "lalu setting a records daripada a.rbldns.abc.co.id   Pastikan Firewall Mikrotik sudah disetup port forwarding 53 udp dari ip  202.169.239.180 ke ip internal 192.168.1.50", 
            "title": "setting NS record"
        }, 
        {
            "location": "/dns-build-RBL-DNS-untuk-anti-spam-based-ip-address/#testing", 
            "text": "Untuk menguji apakah RBL DNS sudah berjalan sebelum diterapkan di mail server bisa dengan cara berikut:\ninsert ip dengan perintah:  mysql  INSERT INTO ips SET  ipaddress='207.126.164.135',  reportedby='manual',  attacknotes='spammers',  b_or_w='b',  dateadded=now(),  updated=now();\"\nJika sudah, lalu build dan restart services rbldnsd:\n[root@rbldns tmp]# /usr/local/bin/rebuild_rbldns.pl;/etc/init.d/rbldnsd restart\nShutting down rbldnsd service:                             [  OK  ]\nStarting rbldnsd service: rbldnsd: listening on 0.0.0.0/53\nrbldnsd: ip4set:spammerlist,whitelist: 20150518 022140: e32/24/16/8=189204/0/0/0\nrbldnsd: generic:forward: 20140617 122159: e=0\nrbldnsd: zones reloaded, time 0.2e/0.2u sec, mem arena=280 free=129 mmap=2960 Kb\nrbldnsd: rbldnsd version 0.997a (23 Jul 2013) started (1 socket(s), 1 zone(s))\n                                                           [  OK  ]\n[root@rbldns tmp]#  cek file spammerlist  [root@rbldns ~]# cat /var/lib/rbldns/dsbl/spammerlist | grep 207.126.164.135\n207.126.164.135\n[root@rbldns ~]#  ip yang diblok sudah masuk kedalam list,.  cek terakhir via lookup dig dns.  dian@it-infra ~ $ dig 135.164.126.207.rbldns.abc.co.id @202.169.239.180\n;   DiG 9.9.5-3-Ubuntu   135.164.126.207.rbldns.abc.co.id @202.169.239.180\n;; global options: +cmd\n;; Got answer:\n;; - HEADER - opcode: QUERY, status: NOERROR, id: 64533\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 2\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;135.164.126.207.rbldns.abc.co.id. IN   A\n;; ANSWER SECTION:\n135.164.126.207.rbldns.abc.co.id. 2100 IN A 127.0.0.2\n;; AUTHORITY SECTION:\nrbldns.abc.co.id.   1800    IN  NS  a.rbldns.abc.co.id.\n;; ADDITIONAL SECTION:\na.rbldns.abc.co.id. 1800    IN  A   202.169.239.180\n;; Query time: 302 msec\n;; SERVER: 202.169.239.180#53(202.169.239.180)\n;; WHEN: Mon May 18 10:21:36 WIB 2015\n;; MSG SIZE  rcvd: 109  Jika ada answer, dengan results 127.0.0.2 , maka ip sudah masuk ke RBL DNS. dan sudah bekerja dengan baik. Jika tidak ada results, maka ip tidak diblok.  dian@it-infra ~ $ dig 35.64.102.117.rbldns.abc.co.id @202.169.239.180\n;   DiG 9.9.5-3-Ubuntu   35.64.102.117.rbldns.abc.co.id @202.169.239.180\n;; global options: +cmd\n;; Got answer:\n;; - HEADER - opcode: QUERY, status: NXDOMAIN, id: 50561\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;35.64.102.117.rbldns.abc.co.id.    IN  A\n;; Query time: 134 msec\n;; SERVER: 202.169.239.180#53(202.169.239.180)\n;; WHEN: Mon May 18 10:23:38 WIB 2015\n;; MSG SIZE  rcvd: 59\ndian@it-infra ~ $  Langkah terakhir memasang RBL DNS di zimbra mudah sekali, cukup seperti digambar bawah ini lalu save dan restart services    restart services amavis dan milter  zmamavisdctl reload\nzmmtactl reload  Results:   ref:  http://www.blue-quartz.com/rbl/", 
            "title": "Testing:"
        }, 
        {
            "location": "/zimbra-enable-original-ip-nginx-proxy/", 
            "text": "Zimbra - Enable Original IP Nginx Proxy\n\n\noriginal ip public zimbra tidak terlihat di log ketika login menggunakan web browser. \n\n\ncontoh log: \n\n\n2015-10-22 08:52:08,525 INFO [qtp719953478-1071339:http://127.0.0.1:8080/service/soap/AuthRequest] [name=user@abc.co.id;oip=192.168.2.2;ua=zclient/8.0.4_GA_5737;] security - cmd=Auth; account=user@abc.co.id; protocol=soap;\n\n\n\nterlihat ip private yang tersimpan di log. Untuk mencatat log ip public maka berikut langkah yang dijalankan:\n\n\ncheck nginx X-Originating-IP support\n\n\nzimbra@mail2:~$ zmlocalconfig zimbra_http_originating_ip_header\nzimbra_http_originating_ip_header = X-Forwarded-For\nzimbra@mail2:~$\n\n\n\njika sudah ada opsi \nX-Forwarded-For\n, berarti zimbra sudah disupport.\n\n\ncheck Trusted IP\n\n\ncheck trusted IP address yang ada di internal nginx proxy. secara default nilainya kosong.\n\n\nzmprov gcf zimbraMailTrustedIP\n\n\n\ntambahkan Trusted IP\n\n\nuntuk menambahkan trusted ip, bisa dengan cara berikut:\n\n\nzmprov mcf +zimbraMailTrustedIP 127.0.0.1 +zimbraMailTrustedIP 192.168.4.2\n\n\n\nip 192.168.4.2 adalah ip local server zimbra.\n\n\nrestart zmmailbox daemon\n\n\nzmmailboxdctl restart\n\n\n\nlog akhir:\n\n\n2015-10-23 06:45:43,080 INFO  [qtp719953478-17242:http://127.0.0.1:8080/service/soap/AuthRequest] [name=user@abc.co.id;oip=36.73.58.164;ua=zclient/8.0.4_GA_5737;] security - cmd=Auth; account=user@abc.co.id; protocol=soap;\n\n\n\nTerlihat original ip public: 36.73.58.164\n\n\nReferensi:\n  1. \nhttps://wiki.zimbra.com/wiki/Log_Files", 
            "title": "Zimbra - Enable Original IP Public Nginx Proxy"
        }, 
        {
            "location": "/zimbra-enable-original-ip-nginx-proxy/#zimbra-enable-original-ip-nginx-proxy", 
            "text": "original ip public zimbra tidak terlihat di log ketika login menggunakan web browser.   contoh log:   2015-10-22 08:52:08,525 INFO [qtp719953478-1071339:http://127.0.0.1:8080/service/soap/AuthRequest] [name=user@abc.co.id;oip=192.168.2.2;ua=zclient/8.0.4_GA_5737;] security - cmd=Auth; account=user@abc.co.id; protocol=soap;  terlihat ip private yang tersimpan di log. Untuk mencatat log ip public maka berikut langkah yang dijalankan:", 
            "title": "Zimbra - Enable Original IP Nginx Proxy"
        }, 
        {
            "location": "/zimbra-enable-original-ip-nginx-proxy/#check-nginx-x-originating-ip-support", 
            "text": "zimbra@mail2:~$ zmlocalconfig zimbra_http_originating_ip_header\nzimbra_http_originating_ip_header = X-Forwarded-For\nzimbra@mail2:~$  jika sudah ada opsi  X-Forwarded-For , berarti zimbra sudah disupport.", 
            "title": "check nginx X-Originating-IP support"
        }, 
        {
            "location": "/zimbra-enable-original-ip-nginx-proxy/#check-trusted-ip", 
            "text": "check trusted IP address yang ada di internal nginx proxy. secara default nilainya kosong.  zmprov gcf zimbraMailTrustedIP", 
            "title": "check Trusted IP"
        }, 
        {
            "location": "/zimbra-enable-original-ip-nginx-proxy/#tambahkan-trusted-ip", 
            "text": "untuk menambahkan trusted ip, bisa dengan cara berikut:  zmprov mcf +zimbraMailTrustedIP 127.0.0.1 +zimbraMailTrustedIP 192.168.4.2  ip 192.168.4.2 adalah ip local server zimbra.", 
            "title": "tambahkan Trusted IP"
        }, 
        {
            "location": "/zimbra-enable-original-ip-nginx-proxy/#restart-zmmailbox-daemon", 
            "text": "zmmailboxdctl restart  log akhir:  2015-10-23 06:45:43,080 INFO  [qtp719953478-17242:http://127.0.0.1:8080/service/soap/AuthRequest] [name=user@abc.co.id;oip=36.73.58.164;ua=zclient/8.0.4_GA_5737;] security - cmd=Auth; account=user@abc.co.id; protocol=soap;  Terlihat original ip public: 36.73.58.164  Referensi:\n  1.  https://wiki.zimbra.com/wiki/Log_Files", 
            "title": "restart zmmailbox daemon"
        }, 
        {
            "location": "/zimbra-setting-glusterfs-untuk-backup-mail-account/", 
            "text": "setup GlusterFS untuk NFS sharing backup email account zimbra di Ubuntu 12.04\n\n\nMail server Zimbra (mail.abc.co.id) telah menggunakan RAID 1+0 . lihat hasil config status dibawah\n\n\n/opt/hp/hpssacli/bin # /opt/hp/hpssacli/bin/hpssacli ctrl all show config\nDynamic Smart Array B120i RAID in Slot 0 (Embedded)\nSmart Array P222 in Slot 1                (sn: PDSXH0BRH5P0P4)\n   array A (SATA, Unused Space: 0  MB)\n      logicaldrive 1 (5.5 TB, RAID 1+0, OK)\n      physicaldrive 2I:1:1 (port 2I:box 1:bay 1, SATA, 3 TB, OK)\n      physicaldrive 2I:1:2 (port 2I:box 1:bay 2, SATA, 3 TB, OK)\n      physicaldrive 2I:1:3 (port 2I:box 1:bay 3, SATA, 3 TB, OK)\n      physicaldrive 2I:1:4 (port 2I:box 1:bay 4, SATA, 3 TB, OK)\n   SEP (Vendor ID PMCSIERA, Model SRCv8x6G) 380 (WWID: 500143802894C36F)\n/opt/hp/hpssacli/bin #\n\n\n\nRAID is not a backup solution. It is used to improve disk I/O (performance) and reliability of your server or workstation.  Can RAID Array Fail ? Yes. The entire RAID array can fail taking down all your data (yes hardware RAID card do dies) \nlink\n\n\nGlusterFS is used in environments where high performance, redundancy and reliability are of a premium.\nGlusterFS is a file system that is designed to provide network storage that can be made redundant, fault-tolerant and scalable. It\u2019s particularly well suited to applications that require high-performance access to large files. With GlusterFS, you can have enterprise- or scientific-research-grade storage up and running in minutes. \nlink\n\n\nSetup GlusterFS ini sebagai langkah akhir atau solusi terakhir (backup), jika raid disk sudah tidak bisa diselamatkan. Dengan menggunakan space ~400 GB, backup harian dari email zimbra yang kurang lebih 1GB/hari, diharapkan dapat menampung selama 365 hari atau satu tahun. setelah satu tahun akan dirotate.\n\n\nPrepare:\n\n\n\n\nLinux server (menggunakan ubuntu server 12.04).\nKarena mail server zimbra telah menggunakan ubuntu server 12.04, maka untuk compability glusterfs, lebih baik menggunakan Os yang sama. Pastikan telah terinstall dengan baik.\n\n\n\n\nInstall GlusterFS\nUntuk menginstall glusterfs ketik perintah:\n\n\napt-get install glusterfs-server \n\n\n\n\n\n\nSetting brick:\n\n\nbrick adalah  storage pool yang akan digunakan oleh gluster fs untuk menampung datanya. berikut disk space free dari ubuntu server yang telah kita install:\n\n\nroot@glusterfs:/data1# df -h\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda1       2.9G  1.1G  1.8G  38% /\nudev            2.0G  4.0K  2.0G   1% /dev\ntmpfs           406M  240K  405M   1% /run\nnone            5.0M     0  5.0M   0% /run/lock\nnone            2.0G     0  2.0G   0% /run/shm\n/dev/sdb1       148G  592M  140G   1% /data1\n/dev/sdc1       252G  592M  239G   1% /data2\n\n\n\ndirectory \n/data1\n dan directory \n/data2\n memiliki free space yang dapat kita gunakan, jika ditotal maka kurang lebih menjadi 400GB . kita buat directory \nzimbrabackup\n misalnya di setiap directory tersebut.\n\n\nroot@glusterfs:~# mkdir /data1/zimbrabackup\nroot@glusterfs:~# mkdir /data2/zimbrabackup\n\n\n\ndari 2 buah directory partisi disk tersebut akan kita gabung menjadi satu dengan perintah:\n \npastikan glusterfs (hostname) sudah didefine di /etc/hosts\n\n\nroot@glusterfs:~# gluster volume create ZimbraBackup transport tcp glusterfs:/data1/zimbrabackup glusterfs:/data2/zimbrabackup\nCreation of volume ZimbraBackup has been successful. Please start the volume to access data.\nroot@glusterfs:~# gluster volume info\nVolume Name: ZimbraBackup\nType: Distribute\nStatus: Created\nNumber of Bricks: 2\nTransport-type: tcp\nBricks:\nBrick1: glusterfs:/data1/zimbrabackup\nBrick2: glusterfs:/data2/zimbrabackup\nroot@glusterfs:~#\n\n\n\nlalu kita allow host yang dapat mengakses distributed volume tersebut:\n\n\nroot@glusterfs:~# gluster volume set ZimbraBackup auth.allow 192.168.2.2\nSet volume successful\n\n\n\nlalu cek dengan perintah:\n\n\nroot@glusterfs:~# gluster volume info\nVolume Name: ZimbraBackup\nType: Distribute\nStatus: Created\nNumber of Bricks: 2\nTransport-type: tcp\nBricks:\nBrick1: glusterfs:/data1/zimbrabackup\nBrick2: glusterfs:/data2/zimbrabackup\nOptions Reconfigured:\nauth.allow: 192.168.2.2\nroot@glusterfs:~#\n\n\n\nJika sudah lalu start volume dengan perintah\n\n\nroot@glusterfs:~# gluster volume start ZimbraBackup\nStarting volume ZimbraBackup has been successful\nroot@glusterfs:~#\n\n\n\ncek status volume\n\n\nroot@glusterfs:~# gluster volume info\nVolume Name: ZimbraBackup\nType: Distribute\nStatus: Started\nNumber of Bricks: 2\nTransport-type: tcp\nBricks:\nBrick1: glusterfs:/data1/zimbrabackup\nBrick2: glusterfs:/data2/zimbrabackup\nOptions Reconfigured:\nauth.allow: 192.168.2.2\nroot@glusterfs:~#\n\n\n\nok. storage pool sudah ready.\n\n\nMount dari client\n\n\nMount gluster volume dari mail server zimbra\nuntuk mounting NFS dari GlusterFS ketik:\n\n\nroot@mail:~# mount.glusterfs 192.168.1.51:/ZimbraBackup /ZimbraBackup/\n\n\n\nlalu cek:\n\n\nroot@mail:~# df -h\nFilesystem                   Size  Used Avail Use% Mounted on\n/dev/mapper/zimbra--vg-root  5.4T  816G  4.4T  16% /\nudev                         3.9G  4.0K  3.9G   1% /dev\ntmpfs                        783M  248K  782M   1% /run\nnone                         5.0M     0  5.0M   0% /run/lock\nnone                         3.9G     0  3.9G   0% /run/shm\n/dev/sda2                    237M   32M  193M  14% /boot\n192.168.1.51:/ZimbraBackup   400G  119M  379G   1% /ZimbraBackup\n\n\n\nterlihat size directory \n/ZimbraBackup\n sebesar 400GB . \nlalu coba transfer file ke host \nglusterFS\n:\n\n\nroot@mail:/ZimbraBackup# rsync -avh --progress /backup/zimbra-backup/20150512.tar.bz2 /ZimbraBackup/20150512.tar.bz2\nsending incremental file list\n20150512.tar.bz2\n       1.12G 100%   60.27MB/s    0:00:17 (xfer#1, to-check=0/1)\nsent 1.12G bytes  received 31 bytes  60.34M bytes/sec\ntotal size is 1.12G  speedup is 1.00\nroot@mail:/ZimbraBackup#\n\n\n\ncek di host glusterfs:\n\n\nroot@glusterfs:~# ls /data*/zimbrabackup/\n/data1/zimbrabackup/:\n20150512.tar.bz2\n/data2/zimbrabackup/:\nroot@glusterfs:~#\n\n\n\nfile \n20150512.tar.bz2\n sudah tersimpan di /data1/zimbrabackup/\n\n\nref:\n\n\n\n\nhttp://glusterhacker.blogspot.com\n\n\nwww.gluster.org Configuring_Distributed_Striped_Volumes\n\n\nhttp://how-to.linuxcareer.com/\n\n\nhttp://edoceo.com/\n\n\n\n\nFinal shell script untuk backup:\n\n\n#!/bin/bash\n### START CONFIGURATION ###\nDIR=\"/backup/zimbra-backup\";\n#BASEDIR=\"/home/user/backup\";\n### END OF CONFIGURATION ###\n\nmount | grep Zimbra\n\nif [ \"$?\" == \"0\" ];then\n    USERS=`su - zimbra -c 'zmprov -l gaa'`;\n    ### The above command work on Zimbra 5.x. If you use Zimbra 6.x, use\n    ### USERS=`su - zimbra -c 'zmprov -l gaa'`; instead\n    DATE=`date +%Y%m%d`;\n\n    ### backup list account\n    echo \"Processing list account backup...\"\n    touch $DIR/listaccount-\"$DATE\".csv\n    su - zimbra -c \"zmprov -l gaa\" \n $DIR/listaccount-\"$DATE\".csv\n    echo \"backup list account done...\"\n    HARI=`date --date='1 days ago' +\"%m/%d/%Y\"`\n\n    #HARI=`date +%m/%d/%Y`\n    #query=\"\nquery=after:$HARI\"\n    query=\"\nquery=date:$HARI\"\n\n    if [ ! -d $DIR ]; then mkdir $DIR; chown zimbra:zimbra $DIR; fi\n\n    ### backup mailbox\n    for ACCOUNT in $USERS; do\n            NAME=`echo $ACCOUNT`;\n            echo \"Processing mailbox $NAME backup...\"\n            #su - zimbra -c \"zmmailbox -z -m $ACCOUNT getRestURL '//?fmt=zip$query' \n $DIR/$NAME.zip\";\n            su - zimbra -c \"zmmailbox -z -m $ACCOUNT getRestURL '//?fmt=tgz$query' \n $DIR/$NAME.tgz\";\n    done\n\n    echo \"Compressing mailbox backup, please wait...\"\n    #cd $DIR; mkdir $DATE; mv *.zip $DATE\n    cd $DIR; mkdir $DATE; mv *.tgz $DATE\n\n    tar cjvf $DIR/$DATE.tar.bz2 $DATE;\n    rsync -avh --progress $DIR/$DATE.tar.bz2 /ZimbraBackup/$DATE.tar.bz2\n    rsync -avh --progress $DIR/listaccount-\"$DATE\".csv /ZimbraBackup/listaccount-\"$DATE\".csv\n\n    logfile=\"/tmp/zbackup-`date +%F`.log\"\n    echo \"Zimbra mailbox backup has been completed successfully...\" \n $logfile\n    echo \"\" \n $logfile\n\n    sizeremote=`du -sh /ZimbraBackup/$DATE.tar.bz2`\n    sizelocal=`du -sh $DIR/$DATE.tar.bz2`\n    checksumlocal=`/usr/bin/md5sum $DIR/$DATE.tar.bz2`\n    checksumremote=`/usr/bin/md5sum /ZimbraBackup/$DATE.tar.bz2`\n\n    echo \"Size File di NFS: $sizeremote\" \n $logfile\n    echo \"Size File di local: $sizelocal\" \n $logfile\n    echo \"Checksum File di NFS: $checksumremote\" \n $logfile\n    echo \"Checksum File di local: $checksumlocal\" \n $logfile\n\n    cd $DIR;rm -rf $DATE;rm -rf $DATE.tar.bz2;\n    if [ -f \"$DIR/$DATE.tar.bz2\" ];then\n        echo \"WARNING!: File $DIR/$DATE.tar.bz2 still exist\" \n $logfile\n    else\n        echo \"File $DIR/$DATE.tar.bz2 was deleted...\" \n $logfile\n    fi\n\n    echo \"\" \n $logfile\n    echo \"GlusterFS Space:\" \n $logfile\n    /bin/df /ZimbraBackup \n $logfile\n\n    /usr/bin/sendemail -f ngadimin@abc.co.id -u \"Zimbra daily account Backup (OK)\" -t ngadimin@abc.co.id -o message-content-type=text -o message-file=$logfile -xu user -xp pass -s 192.168.2.2:587 -o tls=no\n\nelse\n    /usr/bin/sendemail -f ngadimin@abc.co.id -u \"Zimbra daily account Backup (Warning)\" -t ngadimin@abc.co.id -o message-content-type=text -o -m \"Zimbra mailbox backup failed. /ZimbraBackup mount not found\" -xu user -xp pass -s 192.168.2.2:587 -o tls=no\n\nfi", 
            "title": "Zimbra - setup GlusterFS untuk NFS sharing backup email account zimbra di Ubuntu 12.04"
        }, 
        {
            "location": "/zimbra-setting-glusterfs-untuk-backup-mail-account/#setup-glusterfs-untuk-nfs-sharing-backup-email-account-zimbra-di-ubuntu-1204", 
            "text": "Mail server Zimbra (mail.abc.co.id) telah menggunakan RAID 1+0 . lihat hasil config status dibawah  /opt/hp/hpssacli/bin # /opt/hp/hpssacli/bin/hpssacli ctrl all show config\nDynamic Smart Array B120i RAID in Slot 0 (Embedded)\nSmart Array P222 in Slot 1                (sn: PDSXH0BRH5P0P4)\n   array A (SATA, Unused Space: 0  MB)\n      logicaldrive 1 (5.5 TB, RAID 1+0, OK)\n      physicaldrive 2I:1:1 (port 2I:box 1:bay 1, SATA, 3 TB, OK)\n      physicaldrive 2I:1:2 (port 2I:box 1:bay 2, SATA, 3 TB, OK)\n      physicaldrive 2I:1:3 (port 2I:box 1:bay 3, SATA, 3 TB, OK)\n      physicaldrive 2I:1:4 (port 2I:box 1:bay 4, SATA, 3 TB, OK)\n   SEP (Vendor ID PMCSIERA, Model SRCv8x6G) 380 (WWID: 500143802894C36F)\n/opt/hp/hpssacli/bin #  RAID is not a backup solution. It is used to improve disk I/O (performance) and reliability of your server or workstation.  Can RAID Array Fail ? Yes. The entire RAID array can fail taking down all your data (yes hardware RAID card do dies)  link  GlusterFS is used in environments where high performance, redundancy and reliability are of a premium.\nGlusterFS is a file system that is designed to provide network storage that can be made redundant, fault-tolerant and scalable. It\u2019s particularly well suited to applications that require high-performance access to large files. With GlusterFS, you can have enterprise- or scientific-research-grade storage up and running in minutes.  link  Setup GlusterFS ini sebagai langkah akhir atau solusi terakhir (backup), jika raid disk sudah tidak bisa diselamatkan. Dengan menggunakan space ~400 GB, backup harian dari email zimbra yang kurang lebih 1GB/hari, diharapkan dapat menampung selama 365 hari atau satu tahun. setelah satu tahun akan dirotate.", 
            "title": "setup GlusterFS untuk NFS sharing backup email account zimbra di Ubuntu 12.04"
        }, 
        {
            "location": "/zimbra-setting-glusterfs-untuk-backup-mail-account/#prepare", 
            "text": "Linux server (menggunakan ubuntu server 12.04).\nKarena mail server zimbra telah menggunakan ubuntu server 12.04, maka untuk compability glusterfs, lebih baik menggunakan Os yang sama. Pastikan telah terinstall dengan baik.   Install GlusterFS\nUntuk menginstall glusterfs ketik perintah:  apt-get install glusterfs-server", 
            "title": "Prepare:"
        }, 
        {
            "location": "/zimbra-setting-glusterfs-untuk-backup-mail-account/#setting-brick", 
            "text": "brick adalah  storage pool yang akan digunakan oleh gluster fs untuk menampung datanya. berikut disk space free dari ubuntu server yang telah kita install:  root@glusterfs:/data1# df -h\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda1       2.9G  1.1G  1.8G  38% /\nudev            2.0G  4.0K  2.0G   1% /dev\ntmpfs           406M  240K  405M   1% /run\nnone            5.0M     0  5.0M   0% /run/lock\nnone            2.0G     0  2.0G   0% /run/shm\n/dev/sdb1       148G  592M  140G   1% /data1\n/dev/sdc1       252G  592M  239G   1% /data2  directory  /data1  dan directory  /data2  memiliki free space yang dapat kita gunakan, jika ditotal maka kurang lebih menjadi 400GB . kita buat directory  zimbrabackup  misalnya di setiap directory tersebut.  root@glusterfs:~# mkdir /data1/zimbrabackup\nroot@glusterfs:~# mkdir /data2/zimbrabackup  dari 2 buah directory partisi disk tersebut akan kita gabung menjadi satu dengan perintah:\n  pastikan glusterfs (hostname) sudah didefine di /etc/hosts  root@glusterfs:~# gluster volume create ZimbraBackup transport tcp glusterfs:/data1/zimbrabackup glusterfs:/data2/zimbrabackup\nCreation of volume ZimbraBackup has been successful. Please start the volume to access data.\nroot@glusterfs:~# gluster volume info\nVolume Name: ZimbraBackup\nType: Distribute\nStatus: Created\nNumber of Bricks: 2\nTransport-type: tcp\nBricks:\nBrick1: glusterfs:/data1/zimbrabackup\nBrick2: glusterfs:/data2/zimbrabackup\nroot@glusterfs:~#  lalu kita allow host yang dapat mengakses distributed volume tersebut:  root@glusterfs:~# gluster volume set ZimbraBackup auth.allow 192.168.2.2\nSet volume successful  lalu cek dengan perintah:  root@glusterfs:~# gluster volume info\nVolume Name: ZimbraBackup\nType: Distribute\nStatus: Created\nNumber of Bricks: 2\nTransport-type: tcp\nBricks:\nBrick1: glusterfs:/data1/zimbrabackup\nBrick2: glusterfs:/data2/zimbrabackup\nOptions Reconfigured:\nauth.allow: 192.168.2.2\nroot@glusterfs:~#  Jika sudah lalu start volume dengan perintah  root@glusterfs:~# gluster volume start ZimbraBackup\nStarting volume ZimbraBackup has been successful\nroot@glusterfs:~#  cek status volume  root@glusterfs:~# gluster volume info\nVolume Name: ZimbraBackup\nType: Distribute\nStatus: Started\nNumber of Bricks: 2\nTransport-type: tcp\nBricks:\nBrick1: glusterfs:/data1/zimbrabackup\nBrick2: glusterfs:/data2/zimbrabackup\nOptions Reconfigured:\nauth.allow: 192.168.2.2\nroot@glusterfs:~#  ok. storage pool sudah ready.", 
            "title": "Setting brick:"
        }, 
        {
            "location": "/zimbra-setting-glusterfs-untuk-backup-mail-account/#mount-dari-client", 
            "text": "Mount gluster volume dari mail server zimbra\nuntuk mounting NFS dari GlusterFS ketik:  root@mail:~# mount.glusterfs 192.168.1.51:/ZimbraBackup /ZimbraBackup/  lalu cek:  root@mail:~# df -h\nFilesystem                   Size  Used Avail Use% Mounted on\n/dev/mapper/zimbra--vg-root  5.4T  816G  4.4T  16% /\nudev                         3.9G  4.0K  3.9G   1% /dev\ntmpfs                        783M  248K  782M   1% /run\nnone                         5.0M     0  5.0M   0% /run/lock\nnone                         3.9G     0  3.9G   0% /run/shm\n/dev/sda2                    237M   32M  193M  14% /boot\n192.168.1.51:/ZimbraBackup   400G  119M  379G   1% /ZimbraBackup  terlihat size directory  /ZimbraBackup  sebesar 400GB . \nlalu coba transfer file ke host  glusterFS :  root@mail:/ZimbraBackup# rsync -avh --progress /backup/zimbra-backup/20150512.tar.bz2 /ZimbraBackup/20150512.tar.bz2\nsending incremental file list\n20150512.tar.bz2\n       1.12G 100%   60.27MB/s    0:00:17 (xfer#1, to-check=0/1)\nsent 1.12G bytes  received 31 bytes  60.34M bytes/sec\ntotal size is 1.12G  speedup is 1.00\nroot@mail:/ZimbraBackup#  cek di host glusterfs:  root@glusterfs:~# ls /data*/zimbrabackup/\n/data1/zimbrabackup/:\n20150512.tar.bz2\n/data2/zimbrabackup/:\nroot@glusterfs:~#  file  20150512.tar.bz2  sudah tersimpan di /data1/zimbrabackup/  ref:   http://glusterhacker.blogspot.com  www.gluster.org Configuring_Distributed_Striped_Volumes  http://how-to.linuxcareer.com/  http://edoceo.com/   Final shell script untuk backup:  #!/bin/bash\n### START CONFIGURATION ###\nDIR=\"/backup/zimbra-backup\";\n#BASEDIR=\"/home/user/backup\";\n### END OF CONFIGURATION ###\n\nmount | grep Zimbra\n\nif [ \"$?\" == \"0\" ];then\n    USERS=`su - zimbra -c 'zmprov -l gaa'`;\n    ### The above command work on Zimbra 5.x. If you use Zimbra 6.x, use\n    ### USERS=`su - zimbra -c 'zmprov -l gaa'`; instead\n    DATE=`date +%Y%m%d`;\n\n    ### backup list account\n    echo \"Processing list account backup...\"\n    touch $DIR/listaccount-\"$DATE\".csv\n    su - zimbra -c \"zmprov -l gaa\"   $DIR/listaccount-\"$DATE\".csv\n    echo \"backup list account done...\"\n    HARI=`date --date='1 days ago' +\"%m/%d/%Y\"`\n\n    #HARI=`date +%m/%d/%Y`\n    #query=\" query=after:$HARI\"\n    query=\" query=date:$HARI\"\n\n    if [ ! -d $DIR ]; then mkdir $DIR; chown zimbra:zimbra $DIR; fi\n\n    ### backup mailbox\n    for ACCOUNT in $USERS; do\n            NAME=`echo $ACCOUNT`;\n            echo \"Processing mailbox $NAME backup...\"\n            #su - zimbra -c \"zmmailbox -z -m $ACCOUNT getRestURL '//?fmt=zip$query'   $DIR/$NAME.zip\";\n            su - zimbra -c \"zmmailbox -z -m $ACCOUNT getRestURL '//?fmt=tgz$query'   $DIR/$NAME.tgz\";\n    done\n\n    echo \"Compressing mailbox backup, please wait...\"\n    #cd $DIR; mkdir $DATE; mv *.zip $DATE\n    cd $DIR; mkdir $DATE; mv *.tgz $DATE\n\n    tar cjvf $DIR/$DATE.tar.bz2 $DATE;\n    rsync -avh --progress $DIR/$DATE.tar.bz2 /ZimbraBackup/$DATE.tar.bz2\n    rsync -avh --progress $DIR/listaccount-\"$DATE\".csv /ZimbraBackup/listaccount-\"$DATE\".csv\n\n    logfile=\"/tmp/zbackup-`date +%F`.log\"\n    echo \"Zimbra mailbox backup has been completed successfully...\"   $logfile\n    echo \"\"   $logfile\n\n    sizeremote=`du -sh /ZimbraBackup/$DATE.tar.bz2`\n    sizelocal=`du -sh $DIR/$DATE.tar.bz2`\n    checksumlocal=`/usr/bin/md5sum $DIR/$DATE.tar.bz2`\n    checksumremote=`/usr/bin/md5sum /ZimbraBackup/$DATE.tar.bz2`\n\n    echo \"Size File di NFS: $sizeremote\"   $logfile\n    echo \"Size File di local: $sizelocal\"   $logfile\n    echo \"Checksum File di NFS: $checksumremote\"   $logfile\n    echo \"Checksum File di local: $checksumlocal\"   $logfile\n\n    cd $DIR;rm -rf $DATE;rm -rf $DATE.tar.bz2;\n    if [ -f \"$DIR/$DATE.tar.bz2\" ];then\n        echo \"WARNING!: File $DIR/$DATE.tar.bz2 still exist\"   $logfile\n    else\n        echo \"File $DIR/$DATE.tar.bz2 was deleted...\"   $logfile\n    fi\n\n    echo \"\"   $logfile\n    echo \"GlusterFS Space:\"   $logfile\n    /bin/df /ZimbraBackup   $logfile\n\n    /usr/bin/sendemail -f ngadimin@abc.co.id -u \"Zimbra daily account Backup (OK)\" -t ngadimin@abc.co.id -o message-content-type=text -o message-file=$logfile -xu user -xp pass -s 192.168.2.2:587 -o tls=no\n\nelse\n    /usr/bin/sendemail -f ngadimin@abc.co.id -u \"Zimbra daily account Backup (Warning)\" -t ngadimin@abc.co.id -o message-content-type=text -o -m \"Zimbra mailbox backup failed. /ZimbraBackup mount not found\" -xu user -xp pass -s 192.168.2.2:587 -o tls=no\n\nfi", 
            "title": "Mount dari client"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/", 
            "text": "Diagnosa kernel Panic PSOD VMware 5.5 HP StoreEasy 1430 Storage\n\n\nA kernel panic is an action taken by an operating system upon detecting an internal fatal error from which it cannot safely recover. The term is largely specific to Unix and Unix-like systems; for Microsoft Windows operating systems the equivalent term is \"stop error\" (or, colloquially, \"Blue Screen of Death\"). http://en.wikipedia.org/wiki/Kernel_panic\n\n\nPada kasus ini di server mail.abc.co.id yang menggunakan \nVMWare 5.5\n terjadi Kernel Panic dengan message error \nPurple screen\n:\n\n\n\n\nPertama kali untuk mendiagnosa kernel panic tersebut adalah mencari log dari kernel dump. biasanya akan disimpan di \n/var/core/\n atau directory \n/root/\n di vmware . \n\n\n/vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # pwd\n/var/core\n/vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # ls\nvmkernel-zdump.1\n/vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # vmkdump_extract -l vmkernel-zdump.1\n/vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # ls\nvmkernel-log.1    vmkernel-zdump.1\n\n\n\nuntuk mengekstak kernel dump ( vmkernel-zdump.1 ) cukup dengan perintah \nvmkdump_extract -l vmkernel-zdump.1\n seperti contoh diatas. setelah dilakukan diagnosa pada kernel file dump didapatkan log:\n\n\n2015-04-09T11:43:56.858Z cpu0:18576095)@BlueScreen: #PF Exception 14 in world 18576095:vmklinux_9:h IP 0x418005ca0594 addr 0x0\nPTEs:0x10d31c027;0x10d31d027;0x0;\n2015-04-09T11:43:56.858Z cpu0:18576095)Code start: 0x418005000000 VMK uptime: 78:11:36:27.131\n2015-04-09T11:43:56.859Z cpu0:18576095)0x41254b7ddda0:[0x418005ca0594]hpsa_update_scsi_devices@\nNone\n#\nNone\n+0x39c stack: 0x4109cea15060\n2015-04-09T11:43:56.859Z cpu0:18576095)0x41254b7dde20:[0x418005ca128f]hpsa_scan_start@\nNone\n#\nNone\n+0x187 stack: 0x41254b7dde60\n2015-04-09T11:43:56.859Z cpu0:18576095)0x41254b7dde90:[0x418005ca27af]hpsa_kickoff_rescan@\nNone\n#\nNone\n+0x20f stack: 0x0\n2015-04-09T11:43:56.860Z cpu0:18576095)0x41254b7ddf30:[0x4180056e675d]kthread@com.vmware.driverAPI#9.2+0x185 stack: 0x0\n2015-04-09T11:43:56.860Z cpu0:18576095)0x41254b7ddf80:[0x4180056e3e5b]LinuxStartFunc@com.vmware.driverAPI#9.2+0x97 stack: 0x100d\n2015-04-09T11:43:56.860Z cpu0:18576095)0x41254b7ddfd0:[0x4180050bb14f]vmkWorldFunc@vmkernel#nover+0x83 stack: 0x0\n2015-04-09T11:43:56.861Z cpu0:18576095)0x41254b7ddff0:[0x418005253532]CpuSched_StartWorld@vmkernel#nover+0xfa stack: 0x0\n\n\n\nsetelah itu kita bisa teliti dan analisa dengan research di search engine mengenai tersebut, jika tidak ditemukan mengenai informasi log tersebut maka bisa submit report ke VMware dengan menyertakan log dari hasil perintah vm-support .\nJika ditemukan maka kita bisa mendapatkan hasil analisa tersebut di:\n\n\n\n\nhttp://kb.vmware.com/selfservice/microsites/search.do?language=en_US\ncmd=displayKC\nexternalId=2073753\n\n\nhttps://communities.vmware.com/thread/472795\n\n\nhttp://h20564.www2.hp.com/hpsc/doc/public/display?docId=c04302261\n\n\n\n\ndari referensi diatas bisa kita simpulkan sementara bahwa ditemukan BUG driver scsi storage raid controller pada tipe P222 HP Smart Array Controller di vmware 5.5 (lihat referensi no 3). \n Untuk keperluan investigasi lebih lanjut kita periksa versi vmware, kernel, tipe server, tipe RAID Card, Product server, dll\n\n\nversi vmware:\n\n\n~ # uname -a\nVMkernel zimbra 5.5.0 #1 SMP Release build-1623387 Feb 21 2014 17:19:17 x86_64 GNU/Linux\n~ # vmware -v\nVMware ESXi 5.5.0 build-1623387\n~ #\n\n\n\nTipe Server:\n\n\n~ # smbiosDump | less\nSystem Info: #256\nManufacturer: \"HP\"\nProduct: \"StoreEasy 1430 Storage\"\nSerial: \"SGH352ACMJ\"\nUUID: 4a4d4341323533484753413039443742\nWake-up: 0x06 (Power Switch)\n\n\n\nversi driver/firmware RAID Card yang digunakan di server sekarang:\n\n\n~ # esxcli software vib get -n scsi-hpsa\nHewlett-Packard_bootbank_scsi-hpsa_5.5.0.58-1OEM.550.0.0.1331820\nName: scsi-hpsa\nVersion: 5.5.0.58-1OEM.550.0.0.1331820\n\n\n\natau bisa dengan perintah:\n\n\n~ # esxcli software vib list | grep -i scsi-hpsa\nscsi-hpsa 5.5.0.58-1OEM.550.0.0.1331820 Hewlett-Packard VMwareCertified 2014-04-10\n~ #\n\n\n\ntipe/model RAID Card:\n\n\n~ # lspci -vvv | grep \"Smart Array\"\n0000:08:00.0 RAID bus controller Mass storage controller: Hewlett-Packard Company Smart Array P222 [vmhba2]\n\n\n\nuntuk mencari RAID Card bisa dengan mencari product ID lalu mencarinya dalam katalog melalui search engine (google)\n\n\nProduct ID:\n\n\n~ # smbiosDump | egrep '(Product ID)'\nProduct ID: B7D90A\n~ #\n\n\n\nSolusi atau kesimpulan atau Action:\n\n\nupdate driver RAID Controller, Go to\n\n\n\n\nhttp://www8.hp.com/us/en/drivers.html\n\n\nEnter the HP Smart Array Controller model (for example, \"Smart Array P222\" and click Search )\n\n\nclick HP Smart Array P222 Controller\n\n\nSelect the appropriate operating system. (vmware 5.5)\n\n\nSelect Driver - Storage Controller .\n\n\nklik \"* RECOMMENDED * HP ProLiant Smart Array Controller Driver for VMware vSphere 5.5 (VIB file) (American, International)\" atau link \nhttp://h20564.www2.hp.com/hpsc/swd/public/detail?sp4ts.oid=5194889\nswItemId=MTX_cc957c5c29c84bdb840d5ee52b\nswEnvOid=4166#tab1\n.\n\n\nklik download\n\n\n\n\ninfo file yang diunduh:\n\n\nType: Driver - Storage Controller\nVersion: 5.5.0.84-1(30 Mar 2015)\nOperating System(s):\nVMware vSphere 5.5\nFile name: scsi-hpsa-5.5.0.84-1OEM.550.0.0.1331820.x86_64.vib (64 KB)\nchecksum: d55390a95fa83e5f0ab16eb817df8e07 scsi-hpsa-5.5.0.84-1OEM.550.0.0.1331820.x86_64.vib\n\n\n\nCara Update:\n\n\n esxcli software vib install -v file:\nvib\u2019s location in /tmp\n --force --no-sig-check --maintenance-mode\n\n\n\nBefore:\n\n\n\n\nAfter:\n\n\n\n\nRef:\n\n\n\n\nhttp://www.vmwarearena.com/2014/07/troubleshoot-psod-on-esxi-5-5-due-to-hpsa-driver-5-5-0-58-1.html\n\n\nhttp://h20564.www2.hp.com/hpsc/swd/public/detail?sp4ts.oid=5194889\nswItemId=MTX_cc957c5c29c84bdb840d5ee52b\nswEnvOid=4166#tab3", 
            "title": "Zimbra - Diagnosa kernel Panic PSOD VMware 5.5 HP StoreEasy 1430 Storage"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#diagnosa-kernel-panic-psod-vmware-55-hp-storeeasy-1430-storage", 
            "text": "A kernel panic is an action taken by an operating system upon detecting an internal fatal error from which it cannot safely recover. The term is largely specific to Unix and Unix-like systems; for Microsoft Windows operating systems the equivalent term is \"stop error\" (or, colloquially, \"Blue Screen of Death\"). http://en.wikipedia.org/wiki/Kernel_panic  Pada kasus ini di server mail.abc.co.id yang menggunakan  VMWare 5.5  terjadi Kernel Panic dengan message error  Purple screen :   Pertama kali untuk mendiagnosa kernel panic tersebut adalah mencari log dari kernel dump. biasanya akan disimpan di  /var/core/  atau directory  /root/  di vmware .   /vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # pwd\n/var/core\n/vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # ls\nvmkernel-zdump.1\n/vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # vmkdump_extract -l vmkernel-zdump.1\n/vmfs/volumes/534668d4-ae54823c-e0c1-a45d36c590b8/core # ls\nvmkernel-log.1    vmkernel-zdump.1  untuk mengekstak kernel dump ( vmkernel-zdump.1 ) cukup dengan perintah  vmkdump_extract -l vmkernel-zdump.1  seperti contoh diatas. setelah dilakukan diagnosa pada kernel file dump didapatkan log:  2015-04-09T11:43:56.858Z cpu0:18576095)@BlueScreen: #PF Exception 14 in world 18576095:vmklinux_9:h IP 0x418005ca0594 addr 0x0\nPTEs:0x10d31c027;0x10d31d027;0x0;\n2015-04-09T11:43:56.858Z cpu0:18576095)Code start: 0x418005000000 VMK uptime: 78:11:36:27.131\n2015-04-09T11:43:56.859Z cpu0:18576095)0x41254b7ddda0:[0x418005ca0594]hpsa_update_scsi_devices@ None # None +0x39c stack: 0x4109cea15060\n2015-04-09T11:43:56.859Z cpu0:18576095)0x41254b7dde20:[0x418005ca128f]hpsa_scan_start@ None # None +0x187 stack: 0x41254b7dde60\n2015-04-09T11:43:56.859Z cpu0:18576095)0x41254b7dde90:[0x418005ca27af]hpsa_kickoff_rescan@ None # None +0x20f stack: 0x0\n2015-04-09T11:43:56.860Z cpu0:18576095)0x41254b7ddf30:[0x4180056e675d]kthread@com.vmware.driverAPI#9.2+0x185 stack: 0x0\n2015-04-09T11:43:56.860Z cpu0:18576095)0x41254b7ddf80:[0x4180056e3e5b]LinuxStartFunc@com.vmware.driverAPI#9.2+0x97 stack: 0x100d\n2015-04-09T11:43:56.860Z cpu0:18576095)0x41254b7ddfd0:[0x4180050bb14f]vmkWorldFunc@vmkernel#nover+0x83 stack: 0x0\n2015-04-09T11:43:56.861Z cpu0:18576095)0x41254b7ddff0:[0x418005253532]CpuSched_StartWorld@vmkernel#nover+0xfa stack: 0x0  setelah itu kita bisa teliti dan analisa dengan research di search engine mengenai tersebut, jika tidak ditemukan mengenai informasi log tersebut maka bisa submit report ke VMware dengan menyertakan log dari hasil perintah vm-support .\nJika ditemukan maka kita bisa mendapatkan hasil analisa tersebut di:   http://kb.vmware.com/selfservice/microsites/search.do?language=en_US cmd=displayKC externalId=2073753  https://communities.vmware.com/thread/472795  http://h20564.www2.hp.com/hpsc/doc/public/display?docId=c04302261   dari referensi diatas bisa kita simpulkan sementara bahwa ditemukan BUG driver scsi storage raid controller pada tipe P222 HP Smart Array Controller di vmware 5.5 (lihat referensi no 3). \n Untuk keperluan investigasi lebih lanjut kita periksa versi vmware, kernel, tipe server, tipe RAID Card, Product server, dll", 
            "title": "Diagnosa kernel Panic PSOD VMware 5.5 HP StoreEasy 1430 Storage"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#versi-vmware", 
            "text": "~ # uname -a\nVMkernel zimbra 5.5.0 #1 SMP Release build-1623387 Feb 21 2014 17:19:17 x86_64 GNU/Linux\n~ # vmware -v\nVMware ESXi 5.5.0 build-1623387\n~ #", 
            "title": "versi vmware:"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#tipe-server", 
            "text": "~ # smbiosDump | less\nSystem Info: #256\nManufacturer: \"HP\"\nProduct: \"StoreEasy 1430 Storage\"\nSerial: \"SGH352ACMJ\"\nUUID: 4a4d4341323533484753413039443742\nWake-up: 0x06 (Power Switch)", 
            "title": "Tipe Server:"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#versi-driverfirmware-raid-card-yang-digunakan-di-server-sekarang", 
            "text": "~ # esxcli software vib get -n scsi-hpsa\nHewlett-Packard_bootbank_scsi-hpsa_5.5.0.58-1OEM.550.0.0.1331820\nName: scsi-hpsa\nVersion: 5.5.0.58-1OEM.550.0.0.1331820", 
            "title": "versi driver/firmware RAID Card yang digunakan di server sekarang:"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#atau-bisa-dengan-perintah", 
            "text": "~ # esxcli software vib list | grep -i scsi-hpsa\nscsi-hpsa 5.5.0.58-1OEM.550.0.0.1331820 Hewlett-Packard VMwareCertified 2014-04-10\n~ #", 
            "title": "atau bisa dengan perintah:"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#tipemodel-raid-card", 
            "text": "~ # lspci -vvv | grep \"Smart Array\"\n0000:08:00.0 RAID bus controller Mass storage controller: Hewlett-Packard Company Smart Array P222 [vmhba2]  untuk mencari RAID Card bisa dengan mencari product ID lalu mencarinya dalam katalog melalui search engine (google)", 
            "title": "tipe/model RAID Card:"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#product-id", 
            "text": "~ # smbiosDump | egrep '(Product ID)'\nProduct ID: B7D90A\n~ #", 
            "title": "Product ID:"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#solusi-atau-kesimpulan-atau-action", 
            "text": "update driver RAID Controller, Go to   http://www8.hp.com/us/en/drivers.html  Enter the HP Smart Array Controller model (for example, \"Smart Array P222\" and click Search )  click HP Smart Array P222 Controller  Select the appropriate operating system. (vmware 5.5)  Select Driver - Storage Controller .  klik \"* RECOMMENDED * HP ProLiant Smart Array Controller Driver for VMware vSphere 5.5 (VIB file) (American, International)\" atau link  http://h20564.www2.hp.com/hpsc/swd/public/detail?sp4ts.oid=5194889 swItemId=MTX_cc957c5c29c84bdb840d5ee52b swEnvOid=4166#tab1 .  klik download", 
            "title": "Solusi atau kesimpulan atau Action:"
        }, 
        {
            "location": "/zimbra-diagnosa-vmware-55-psod-kernel-panic/#info-file-yang-diunduh", 
            "text": "Type: Driver - Storage Controller\nVersion: 5.5.0.84-1(30 Mar 2015)\nOperating System(s):\nVMware vSphere 5.5\nFile name: scsi-hpsa-5.5.0.84-1OEM.550.0.0.1331820.x86_64.vib (64 KB)\nchecksum: d55390a95fa83e5f0ab16eb817df8e07 scsi-hpsa-5.5.0.84-1OEM.550.0.0.1331820.x86_64.vib  Cara Update:   esxcli software vib install -v file: vib\u2019s location in /tmp  --force --no-sig-check --maintenance-mode  Before:   After:   Ref:   http://www.vmwarearena.com/2014/07/troubleshoot-psod-on-esxi-5-5-due-to-hpsa-driver-5-5-0-58-1.html  http://h20564.www2.hp.com/hpsc/swd/public/detail?sp4ts.oid=5194889 swItemId=MTX_cc957c5c29c84bdb840d5ee52b swEnvOid=4166#tab3", 
            "title": "info file yang diunduh:"
        }, 
        {
            "location": "/zimbra-black-list-domain/", 
            "text": "Zimbra - black list domain\n\n\nJika ada email yang di anggap spam, maka domain email tersebut bisa dimasukan ke dalam soft-blacklisting (positive score) di zimbra.\n\n\nMasuk sebagai root dan masuk ke user zimbra.\n\n\n    zimbra@mail:~$ \n    zimbra@mail:~$ vim /opt/zimbra/conf/amavisd.conf.in\n\n\n\nEdit di bagian #soft-blacklisting (positive score) dengan menambahkan domain yang akan di block dan beri nilai (plus).\n\n\n    'sender@example.net'                     =\n  3.0,\n    '.example.net'                           =\n  1.0,\n    'yahoo.com.tw'                           =\n  20.0,\n    'yahoo.com.hk'               =\n  20.0,\n    'kimo.com'                   =\n  20.0,\n    'info@infoaxe.net'                   =\n  20.0,\n    'info@flipmailer.com'                    =\n  20.0,\n    'info@fliporamailer.com'             =\n  20.0,\n    'info@fliporamail.com'               =\n  20.0,\n    'info@info-emailer.com'            =\n 20.0,\n    'facebookmail.com'         =\n 20.0,\n    'info@discovercoolwebsites.com'    =\n 20.0,\n    'amudler4231@suomi24.fi'    =\n 20.0,\n    'gf1107@outlook.it'         =\n 20.0,\n    'damamadi@gmx.fr'           =\n 20.0,\n\n\n\nsimpan dan keluar dan restart amavisd.\n\n\n    zmamavisdctl restart", 
            "title": "Zimbra - black list domain"
        }, 
        {
            "location": "/zimbra-black-list-domain/#zimbra-black-list-domain", 
            "text": "Jika ada email yang di anggap spam, maka domain email tersebut bisa dimasukan ke dalam soft-blacklisting (positive score) di zimbra.  Masuk sebagai root dan masuk ke user zimbra.      zimbra@mail:~$ \n    zimbra@mail:~$ vim /opt/zimbra/conf/amavisd.conf.in  Edit di bagian #soft-blacklisting (positive score) dengan menambahkan domain yang akan di block dan beri nilai (plus).      'sender@example.net'                     =   3.0,\n    '.example.net'                           =   1.0,\n    'yahoo.com.tw'                           =   20.0,\n    'yahoo.com.hk'               =   20.0,\n    'kimo.com'                   =   20.0,\n    'info@infoaxe.net'                   =   20.0,\n    'info@flipmailer.com'                    =   20.0,\n    'info@fliporamailer.com'             =   20.0,\n    'info@fliporamail.com'               =   20.0,\n    'info@info-emailer.com'            =  20.0,\n    'facebookmail.com'         =  20.0,\n    'info@discovercoolwebsites.com'    =  20.0,\n    'amudler4231@suomi24.fi'    =  20.0,\n    'gf1107@outlook.it'         =  20.0,\n    'damamadi@gmx.fr'           =  20.0,  simpan dan keluar dan restart amavisd.      zmamavisdctl restart", 
            "title": "Zimbra - black list domain"
        }, 
        {
            "location": "/zimbra-disclaimer/", 
            "text": "Zimbra - Setting Disclaimer\n\n\nSetting Disclaimer Footer di Zimbra\n\n\ncd /opt/zimbra/postfix/conf\nzmprov mcf zimbraDomainMandatoryMailSignatureEnabled TRUE\nzmprov mcf zimbraDomainMandatoryMailSignatureText \"`cat disclaimer.txt`\"\nzmprov mcf zimbraDomainMandatoryMailSignatureHTML \"`cat disclaimer.html`\"\nzmamavisdctl restart\n\n\n\nUntuk skip disclaimer ke dalam local domain, tambahkan di \n/opt/zimbra/amavisd/sbin/amavisd\n setelah baris no \n13443\n\n\n else {\n      $to_be_mangled = 0  if $r-\nrecip_is_local;\n                }\n\n\n\nref: \nhttp://www.zimbra.com/forums/administrators/49996-solved-domain-disclaimer-zimbra-7-1-0-a-2.html\n\n\nupdated\n\n\nUntuk multiple domain footer zimbra 8.5 NE bisa dicoba langkah berikut (untesting di server production)\nVerified that domain level disclaimer support has been added.\n\n\nBuild:\n\nRelease 8.5.0.BETA3.2883.UBUNTU12.64 UBUNTU12_64 NETWORK edition.\n\n\nSteps\n\n\n\n\nCreate a new domain(e.g. qatest.com), and account(e.g. qa_test2@qatest.com)\n\n\nEnable the use of disclaimers\n\n\nAdd disclaimers to the new domain\n\n\nSend email from the account (e.g. qa_test2@qatest.com) in html and plain text format, check emails received with correct HTML disclaimer and plain text disclaimer.\n\n\n\n\ncli:\n\n\nzimbra@zqa-064:~$ zmprov cd qatest.com\ncb9a4846-6df1-4c18-8044-4c1d4c21ccc5\nzimbra@zqa-064:~$ zmprov ca qa_test2@qatest.com test123\n95d4caf4-c474-4397-83da-aa21de792b6a\n\nzimbra@zqa-064:~$ zmprov -l gaa\nqa_test1@zqa-064.eng.vmware.com\nqa_test2@qatest.com\n    ...\n\nzimbra@zqa-064:~$ zmprov mcf zimbraDomainMandatoryMailSignatureEnabled TRUE\nzimbra@zqa-064:~$ zmprov gcf zimbraDomainMandatoryMailSignatureEnabled\nzimbraDomainMandatoryMailSignatureEnabled: TRUE\nzimbra@zqa-064:~$ zmprov md qatest.com zimbraAmavisDomainDisclaimerText \"text disclamer\" zimbraAmavisDomainDisclaimerHTML \"HTML disclaimer\"\nzimbra@zqa-064:~$ zmprov gd qatest.com zimbraAmavisDomainDisclaimerText \"text disclamer\" zimbraAmavisDomainDisclaimerHTML \"HTML disclaimer\"\n# name qatest.com\nzimbraAmavisDomainDisclaimerHTML: HTML disclaimer\nzimbraAmavisDomainDisclaimerText: text disclamer\nzimbra@zqa-064:~$ zmprov gd zqa-064.eng.vmware.com zimbraAmavisDomainDisclaimerText \"text disclamer\" zimbraAmavisDomainDisclaimerHTML \"HTML disclaimer\"\n# name zqa-064.eng.vmware.com\n\n\nzimbra@zqa-064:~$ ./libexec/zmaltermimeconfig -e qatest.com\nEnabled disclaimers for domain: qatest.com\nGenerating disclaimers for domain qatest.com.\n\n\n\nref: \nhttps://bugzilla.zimbra.com/show_bug.cgi?id=41872", 
            "title": "Zimbra - Setting Disclaimer"
        }, 
        {
            "location": "/zimbra-disclaimer/#zimbra-setting-disclaimer", 
            "text": "Setting Disclaimer Footer di Zimbra  cd /opt/zimbra/postfix/conf\nzmprov mcf zimbraDomainMandatoryMailSignatureEnabled TRUE\nzmprov mcf zimbraDomainMandatoryMailSignatureText \"`cat disclaimer.txt`\"\nzmprov mcf zimbraDomainMandatoryMailSignatureHTML \"`cat disclaimer.html`\"\nzmamavisdctl restart  Untuk skip disclaimer ke dalam local domain, tambahkan di  /opt/zimbra/amavisd/sbin/amavisd  setelah baris no  13443   else {\n      $to_be_mangled = 0  if $r- recip_is_local;\n                }  ref:  http://www.zimbra.com/forums/administrators/49996-solved-domain-disclaimer-zimbra-7-1-0-a-2.html  updated  Untuk multiple domain footer zimbra 8.5 NE bisa dicoba langkah berikut (untesting di server production)\nVerified that domain level disclaimer support has been added.  Build: \nRelease 8.5.0.BETA3.2883.UBUNTU12.64 UBUNTU12_64 NETWORK edition.  Steps   Create a new domain(e.g. qatest.com), and account(e.g. qa_test2@qatest.com)  Enable the use of disclaimers  Add disclaimers to the new domain  Send email from the account (e.g. qa_test2@qatest.com) in html and plain text format, check emails received with correct HTML disclaimer and plain text disclaimer.   cli:  zimbra@zqa-064:~$ zmprov cd qatest.com\ncb9a4846-6df1-4c18-8044-4c1d4c21ccc5\nzimbra@zqa-064:~$ zmprov ca qa_test2@qatest.com test123\n95d4caf4-c474-4397-83da-aa21de792b6a\n\nzimbra@zqa-064:~$ zmprov -l gaa\nqa_test1@zqa-064.eng.vmware.com\nqa_test2@qatest.com\n    ...\n\nzimbra@zqa-064:~$ zmprov mcf zimbraDomainMandatoryMailSignatureEnabled TRUE\nzimbra@zqa-064:~$ zmprov gcf zimbraDomainMandatoryMailSignatureEnabled\nzimbraDomainMandatoryMailSignatureEnabled: TRUE\nzimbra@zqa-064:~$ zmprov md qatest.com zimbraAmavisDomainDisclaimerText \"text disclamer\" zimbraAmavisDomainDisclaimerHTML \"HTML disclaimer\"\nzimbra@zqa-064:~$ zmprov gd qatest.com zimbraAmavisDomainDisclaimerText \"text disclamer\" zimbraAmavisDomainDisclaimerHTML \"HTML disclaimer\"\n# name qatest.com\nzimbraAmavisDomainDisclaimerHTML: HTML disclaimer\nzimbraAmavisDomainDisclaimerText: text disclamer\nzimbra@zqa-064:~$ zmprov gd zqa-064.eng.vmware.com zimbraAmavisDomainDisclaimerText \"text disclamer\" zimbraAmavisDomainDisclaimerHTML \"HTML disclaimer\"\n# name zqa-064.eng.vmware.com\n\n\nzimbra@zqa-064:~$ ./libexec/zmaltermimeconfig -e qatest.com\nEnabled disclaimers for domain: qatest.com\nGenerating disclaimers for domain qatest.com.  ref:  https://bugzilla.zimbra.com/show_bug.cgi?id=41872", 
            "title": "Zimbra - Setting Disclaimer"
        }, 
        {
            "location": "/zimbra-backup-restore/", 
            "text": "Zimbra - Backup dan Restore mail account zimbra\n\n\nBackup\n\n\nUntuk menggunakan fitur bawaan backup zimbra cukup dengan perintah:\n\n\n# /opt/zimbra/bin/zmmailbox -z -m user@domain getRestURL '//?fmt=tgz' \n nama-file.tgz\n\n\n\nperintah diatas akan membackup seluruh isi email dari user@domain ke dalam file nama-file.tgz dengan kompressi.\n\n\nUntuk membackup pada hari atau tanggal tertentu:\n\n\n/opt/zimbra/bin/zmmailbox -z -m dian@tech.co.id getRestURL '//?fmt=tgz\nquery=date:3/20/15' \n ./testaja.tgz\n\n\n\nartinya kita membackup file email account  \ndian@tech.co.id\n dalam format tgz ke dalam file testaja.tgz. email yang dibackup hanya pada tanggal 20 maret 2015 saja.\n\n\nuntuk query, opsi query lain bisa dengan after, before dll. \n\n\nmore: \nhttp://wiki.zimbra.com/wiki/Ajcody-Migration-Notes#Rest_And_The_FMT.3D_Option\n\n\nRestore:\n\n\nuntuk me-restore gunakan perintah dibawah ini (contoh)\n\n\n/opt/zimbra/bin/zmmailbox -z -m dian@tech.co.id postRestURL '//?fmt=tgz\nresolve=skip' ./testaja.tgz\n\n\n\nuntuk parameter resolve dll, bisa dibaca di: \nhttp://wiki.zimbra.com/wiki/Ajcody-Migration-Notes#Rest_And_The_FMT.3D_Option\n\n\nref: http://stdout.no/zimbra-open-source-backup-strategy-and-scripts/\n\n\ncontoh PoC:\n\n\nroot@mail:/tmp# date\nWed Apr  1 09:20:49 WIB 2015\nroot@mail:/tmp# tar -xvf /backup/zimbra-backup/20150401.tar.bz2 20150401/dian@abc.co.id.tgz\n20150401/dian@abc.co.id.tgz\nroot@mail:/tmp# tar -tvf 20150401/dian@abc.co.id.tgz | tail -n 5\n-rw-r--r-- 0/message 57441 2015-03-31 22:07 Inbox/0000054672-Are all key interactions on your website functioning_.eml\n-r--r--r-- 0/message 685 2015-03-31 23:46 Inbox/0000054674-Subject_ www.infosehat24.com RapidSSL Order_ 12350054 Complete.eml.meta\n-rw-r--r-- 0/message 7438 2015-03-31 23:46 Inbox/0000054674-Subject_ www.infosehat24.com RapidSSL Order_ 12350054 Complete.eml\n-r--r--r-- 0/message 706 2015-03-31 23:58 Log Member/0000054675-Log Serve Member Log_server_member - Build # 2342 - Successful!.eml.meta\n-rw-r--r-- 0/message 12591 2015-03-31 23:58 Log Member/0000054675-Log Serve Member Log_server_member - Build # 2342 - Successful!.eml", 
            "title": "Zimbra - Cara Backup dan Restore Mail Account"
        }, 
        {
            "location": "/zimbra-backup-restore/#zimbra-backup-dan-restore-mail-account-zimbra", 
            "text": "", 
            "title": "Zimbra - Backup dan Restore mail account zimbra"
        }, 
        {
            "location": "/zimbra-backup-restore/#backup", 
            "text": "Untuk menggunakan fitur bawaan backup zimbra cukup dengan perintah:  # /opt/zimbra/bin/zmmailbox -z -m user@domain getRestURL '//?fmt=tgz'   nama-file.tgz  perintah diatas akan membackup seluruh isi email dari user@domain ke dalam file nama-file.tgz dengan kompressi.  Untuk membackup pada hari atau tanggal tertentu:  /opt/zimbra/bin/zmmailbox -z -m dian@tech.co.id getRestURL '//?fmt=tgz query=date:3/20/15'   ./testaja.tgz  artinya kita membackup file email account   dian@tech.co.id  dalam format tgz ke dalam file testaja.tgz. email yang dibackup hanya pada tanggal 20 maret 2015 saja.  untuk query, opsi query lain bisa dengan after, before dll.   more:  http://wiki.zimbra.com/wiki/Ajcody-Migration-Notes#Rest_And_The_FMT.3D_Option", 
            "title": "Backup"
        }, 
        {
            "location": "/zimbra-backup-restore/#restore", 
            "text": "untuk me-restore gunakan perintah dibawah ini (contoh)  /opt/zimbra/bin/zmmailbox -z -m dian@tech.co.id postRestURL '//?fmt=tgz resolve=skip' ./testaja.tgz  untuk parameter resolve dll, bisa dibaca di:  http://wiki.zimbra.com/wiki/Ajcody-Migration-Notes#Rest_And_The_FMT.3D_Option  ref: http://stdout.no/zimbra-open-source-backup-strategy-and-scripts/", 
            "title": "Restore:"
        }, 
        {
            "location": "/zimbra-backup-restore/#contoh-poc", 
            "text": "root@mail:/tmp# date\nWed Apr  1 09:20:49 WIB 2015\nroot@mail:/tmp# tar -xvf /backup/zimbra-backup/20150401.tar.bz2 20150401/dian@abc.co.id.tgz\n20150401/dian@abc.co.id.tgz\nroot@mail:/tmp# tar -tvf 20150401/dian@abc.co.id.tgz | tail -n 5\n-rw-r--r-- 0/message 57441 2015-03-31 22:07 Inbox/0000054672-Are all key interactions on your website functioning_.eml\n-r--r--r-- 0/message 685 2015-03-31 23:46 Inbox/0000054674-Subject_ www.infosehat24.com RapidSSL Order_ 12350054 Complete.eml.meta\n-rw-r--r-- 0/message 7438 2015-03-31 23:46 Inbox/0000054674-Subject_ www.infosehat24.com RapidSSL Order_ 12350054 Complete.eml\n-r--r--r-- 0/message 706 2015-03-31 23:58 Log Member/0000054675-Log Serve Member Log_server_member - Build # 2342 - Successful!.eml.meta\n-rw-r--r-- 0/message 12591 2015-03-31 23:58 Log Member/0000054675-Log Serve Member Log_server_member - Build # 2342 - Successful!.eml", 
            "title": "contoh PoC:"
        }, 
        {
            "location": "/zimbra-build-saml-server-untuk-google-apps/", 
            "text": "Build SAML Server Untuk SSO Google Apps\n\n\nSecurity Assertion Markup Language (SAML, pronounced sam-el[1]) is an XML-based, open-standard data format for exchanging authentication and authorization data between parties, in particular, between an identity provider and a service provider. SAML is a product of the OASIS Security Services Technical Committee. SAML dates from 2001; the most recent major update of SAML was published in 2005, but protocol enhancements have steadily been added through additional, optional standards. https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language\n\n\nrequierements:\n\n\n\n\nSystem Operasi dengan Webserver yang bisa menghandle php scripts\n\n\nPHP versi \n= 5.2 , dengan support PHP Extension:\n\n\ndate, dom, hash, libxml, openssl, pcre, SPL, zlib\n\n\nphp mcrypt untuk enkripsi assertion.\n\n\nphp ldap untuk authentikasi ldap\n\n\n\n\nPada percobaan kali ini menggunakan OS  Ubuntu 12.04.5 LTS dengan webserver nginx, php-fpm dan dengan menggunakan Simple SAML PHP https://simplesamlphp.org . Pastikan semuanya terinstall dengan baik.\nclone source code simple saml php:\n\n\ngit clone https://github.com/simplesamlphp/simplesamlphp\n\n\n\nkopi config-templates dan metadata-templates\n\n\n# cp -a config-templates config\n# cp -a metadata-templates metadata\n\n\n\nedit file config/config.php, config/ldap.php dan config/authsources.php lalu simpan.\nedit file metadata/saml20-idp-hosted.php dan saml20-sp-remote.php lalu simpan.\n\n\nmasuk ke admin google apps lalu edit konfig seperti ini:\n\n\n\n\nlalu simpan dan testing:\n\n\nbuka url accounts.google.com/ServiceLoginAuth . \nmasukan username: misal user@abc.co.id dan klik login\nakan terbuka url seperti gambar berikut:\n\n\n\n\nisi username dan password seperti dalam contoh gambar diatas, lalu klik login.\nJika berhasil akan terbuka halaman seperti berikut:\n\n\n\n\nselesai", 
            "title": "Zimbra - Build SAML server untuk google apps"
        }, 
        {
            "location": "/zimbra-build-saml-server-untuk-google-apps/#build-saml-server-untuk-sso-google-apps", 
            "text": "Security Assertion Markup Language (SAML, pronounced sam-el[1]) is an XML-based, open-standard data format for exchanging authentication and authorization data between parties, in particular, between an identity provider and a service provider. SAML is a product of the OASIS Security Services Technical Committee. SAML dates from 2001; the most recent major update of SAML was published in 2005, but protocol enhancements have steadily been added through additional, optional standards. https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language  requierements:   System Operasi dengan Webserver yang bisa menghandle php scripts  PHP versi  = 5.2 , dengan support PHP Extension:  date, dom, hash, libxml, openssl, pcre, SPL, zlib  php mcrypt untuk enkripsi assertion.  php ldap untuk authentikasi ldap   Pada percobaan kali ini menggunakan OS  Ubuntu 12.04.5 LTS dengan webserver nginx, php-fpm dan dengan menggunakan Simple SAML PHP https://simplesamlphp.org . Pastikan semuanya terinstall dengan baik.\nclone source code simple saml php:  git clone https://github.com/simplesamlphp/simplesamlphp  kopi config-templates dan metadata-templates  # cp -a config-templates config\n# cp -a metadata-templates metadata  edit file config/config.php, config/ldap.php dan config/authsources.php lalu simpan.\nedit file metadata/saml20-idp-hosted.php dan saml20-sp-remote.php lalu simpan.  masuk ke admin google apps lalu edit konfig seperti ini:   lalu simpan dan testing:  buka url accounts.google.com/ServiceLoginAuth . \nmasukan username: misal user@abc.co.id dan klik login\nakan terbuka url seperti gambar berikut:   isi username dan password seperti dalam contoh gambar diatas, lalu klik login.\nJika berhasil akan terbuka halaman seperti berikut:   selesai", 
            "title": "Build SAML Server Untuk SSO Google Apps"
        }, 
        {
            "location": "/zimbra-AHBL-scoring-issue/", 
            "text": "Troubleshoot DNS AHBL scoring issue di zimbra\n\n\nsample email yang masuk ke Junk folder:\n\n\nReturn-Path: edy@jmn.net.id\nReceived: from 192.168.2.1 (LHLO mail.abc.co.id) (192.168.2.1) by\n mail.abc.co.id with LMTP; Thu, 26 Mar 2015 10:57:53 +0700 (WIT)\nReceived: from localhost (localhost [127.0.0.1])\n    by mail.abc.co.id (Postfix) with ESMTP id 337894480511;\n    Thu, 26 Mar 2015 10:57:53 +0700 (WIB)\nX-Virus-Scanned: amavisd-new at mail.abc.co.id\nX-Spam-Flag: YES\nX-Spam-Score: 9.31\nX-Spam-Level: *********\nX-Spam-Status: Yes, score=9.31 tagged_above=-10 required=6.6\n    tests=[BAYES_50=0.8, DNS_FROM_AHBL_RHSBL=2.699,\n    FSL_HELO_BARE_IP_2=1.738, HTML_MESSAGE=0.001,\n    RCVD_IN_BRBL_LASTEXT=1.449, RCVD_NUMERIC_HELO=1.164, RDNS_NONE=0.793,\n    SPF_SOFTFAIL=0.665, URIBL_BLOCKED=0.001] autolearn=no\nReceived: from mail.abc.co.id ([127.0.0.1])\n    by localhost (mail.abc.co.id [127.0.0.1]) (amavisd-new, port 10024)\n    with ESMTP id lyn-kN0HDD6W; Thu, 26 Mar 2015 10:57:52 +0700 (WIB)\nReceived: from bakpia.jmn.net.id (unknown [192.168.2.1])\n    by mail.abc.co.id (Postfix) with ESMTPS id 8BAF5448050F\n    for \nit@abc.co.id\n; Thu, 26 Mar 2015 10:57:52 +0700 (WIB)\nReceived: (qmail 23578 invoked by uid 210); 26 Mar 2015 03:51:58 -0000\nReceived: from 202.169.224.61 (edy@jmn.net.id@202.169.224.61) by bakpia.jmn.net.id (envelope-from \nedy@jmn.net.id\n, uid 201) with qmail-scanner-2.05-dn \n (clamdscan: 0.97.7/20240. spamassassin: 3.3.1. perlscan: 2.05-dn.  \n Clear:RC:1(202.169.224.61):. \n Processed in 0.035362 secs); 26 Mar 2015 03:51:58 -0000\nReceived: from unknown (HELO ?192.168.1.133?) (edy@jmn.net.id@202.169.224.61)\n  by 0 with ESMTPA; 26 Mar 2015 03:51:58 -0000\nMessage-ID: \n5513825C.9000004@jmn.net.id\n\nDate: Thu, 26 Mar 2015 10:51:56 +0700\nFrom: Edy Mulyono \nedy@jmn.net.id\n\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20100101 Thunderbird/31.5.0\nMIME-Version: 1.0\nTo: \"Dian\" \ndgprasetya@abc.co.id\n\nCC: it@abc.co.id, noc@jmn.net.id, c-care@jmn.net.id\nSubject: Re: Link Kotabaru Down\nReferences: \n1762256003.2360852.1427335970075.JavaMail.zimbra@abc.co.id\n \n55137815.5020306@jmn.net.id\n \n2089728974.2367864.1427339420605.JavaMail.zimbra@abc.co.id\n \n489143161.2370429.1427340898658.JavaMail.zimbra@abc.co.id\n\nIn-Reply-To: \n489143161.2370429.1427340898658.JavaMail.zimbra@abc.co.id\n\nContent-Type: multipart/alternative;\n boundary=\"------------090408000400010701000809\"\nX-Zimbra-DL: it@abc.co.id\n\n\n\nterlihat score: \n\n\nX-Spam-Score: 9.31\n\n\n\ndan yang paling tinggi adalah \nDNS AHBL: 2.699\n . padahal sejak 1st, Jan 2015 DNS AHBL sudah tidak dimaintain lagi. http://www.ahbl.org/content/changes-ahbl . oleh karena itu kita bisa menetralkan scoring dari DNS AHBL dengan score: 0 atau dengan nilai yang sangat rendah mendekati netral.\n\n\ntambahkan di \nlocal.cf\n\n\n# vim /opt/zimbra/conf/spamassassin/local.cf\nscore DNS_FROM_AHBL_RHSBL 0\n\n\n\ntambahkan/rubah seperlunya di \n50_scores.cf\n\n\n# vim /opt/zimbra/conf/spamassassin/50_scores.cf\nscore ALL_TRUSTED -3.000\nscore DNS_FROM_AHBL_RHSBL 0 0.001 0 0.001 # n=0 n=2\n\n\n\nscore untuk \nTRUSTED\n di beri nilai negatif 3 agar domain-domain yang telah kita trusted di \n/opt/zimbra/conf/salocal.cf.in\n lebih diterima oleh amavisd dan spam assasin.\nsetelah itu restart services:\n\n\nzmantispamctl restart ; zmmtactl restart\n\n\n\nenjoy..\n\n\nresults:\n\n\nReturn-Path: xxxx\nReceived: from 192.168.2.1 (LHLO mail.abc.co.id) (192.168.2.1) by\n mail.abc.co.id with LMTP; Wed, 1 Apr 2015 07:44:13 +0700 (WIT)\nReceived: from localhost (localhost [127.0.0.1])\n    by mail.abc.co.id (Postfix) with ESMTP id 3CB204491BB6\n    for \nxxx@abc.co.id\n; Wed,  1 Apr 2015 07:44:13 +0700 (WIB)\nX-Virus-Scanned: amavisd-new at mail.abc.co.id\nX-Spam-Flag: NO\nX-Spam-Score: 5.699\nX-Spam-Level: *****\nX-Spam-Status: No, score=5.699 tagged_above=-10 required=6.6\n    tests=[BAYES_50=0.8, DKIM_SIGNED=0.1, DKIM_VALID=-0.1,\n    DKIM_VALID_AU=-0.1, DNS_FROM_AHBL_RHSBL=0.001,\n    RCVD_IN_BRBL_LASTEXT=1.449, RCVD_IN_MSPIKE_BL=0.01,\n    RCVD_IN_MSPIKE_ZBI=0.001, RCVD_IN_RP_RNBL=1.31,\n    RCVD_IN_SORBS_WEB=0.77, RDNS_NONE=0.793, SPF_SOFTFAIL=0.665]\n    autolearn=no\nAuthentication-Results: mail.abc.co.id (amavisd-new); dkim=pass (1024-bit key)\n    header.d=xxxx.domain; domainkeys=pass (1024-bit key)\n    header.from=nms@xxxx.domain header.sender=nms@xxxx.domain\n    header.d=xxxx.domain\nReceived: from mail.abc.co.id ([127.0.0.1])\n    by localhost (mail.abc.co.id [127.0.0.1]) (amavisd-new, port 10024)\n    with ESMTP id c4_Qro7nk9Yx for \ndian.prasetya@abc.co.id\n;\n    Wed,  1 Apr 2015 07:44:12 +0700 (WIB)\nReceived: from so254-9.mailgun.net (unknown [192.168.2.1])\n    by mail.abc.co.id (Postfix) with ESMTPS id AB87A4491BB4\n    for \ndian@abc.co.id\n; Wed,  1 Apr 2015 07:44:11 +0700 (WIB)\nDKIM-Signature: a=rsa-sha256; v=1; c=relaxed/relaxed; d=xxxx.domain; q=dns/txt;\n s=krs; t=1427849109; h=Sender: Message-Id: Date: Subject: To: From;\n bh=Li5XZ+kJiZbnYuk5YoF+LhsqlGXOMyf5sdYB8xmMNwM=; b=hfGJZm5pDwENJc8r+W5pj9wfiJQtQPonoqFxnoXK5fcF7A7KlGbs63ROqXJiL9I7g2fTyXY6\n XRx/b5rXM0sJG0Dh/exH4JXaRLnWftyDSLo9V4lKA3Buo8c9/u9GQfEwXVavSSPExiG85ud5\n fLWvW3pRQrb4Gt/xPtQMDA0s+wI=\nDomainKey-Signature: a=rsa-sha1; c=nofws; d=xxxx.domain; s=krs;\n q=dns; h=From: To: Subject: Date: Message-Id: Sender;\n b=UpHKEm/vm3gI4g2uz+KES77gmN1013aAy026GHwRTps+YpSkiXSKurenK0yJ6S7Oesq1xL\n aK9gdSPzOJbGeEywFUqRJcWS24rNI3HJamhqmqnONQJMjBn2wkXogC5X4cNbQR0PZuUebSwU\n hD4UT998Q8SYqzCJ9w3CLyd2EcBVc=\nReceived: from localhost (host-202-169-239-178.jogjamedianet.com\n [202.169.239.178]) by mxa.mailgun.org with ESMTP id\n 551b3f8e.7f18b4f9fae0-in6; Wed, 01 Apr 2015 00:45:02 -0000 (UTC)\nFrom: \nnms@xxxx.domain\n\nTo: \ndiana@abc.co.id\n\nSubject: OK: Zabbix unreachable poller processes more than 75% busy\nDate: Wed, 01 Apr 2015 07:44:58 +0700\nTrigger: Zabbix unreachable poller processes more than 75% busy\nMessage-Id: \n20150401004502.91366.42000@xxxx.domain\n\nX-Mailgun-Sid: WyI0ZDAxYiIsICJkaWFuLnByYXNldHlhQGsyNC5jby5pZCIsICJlZWMzYTUiXQ==\nSender: nms@xxxx.domain\n\nTrigger status: OK\nTrigger severity: Average\nTrigger URL:\n\nItem values:\n\n1. Zabbix busy unreachable poller processes, in % (Zabbix server:zabbix[process,unreachable poller,avg,busy]): 41.41 %\n\n\nOriginal event ID: 3975818", 
            "title": "Zimbra - DNS AHBL Scoring issue"
        }, 
        {
            "location": "/zimbra-poddle-attack/", 
            "text": "Mengamankan zimbra 8.0.4 di mail2.abc.co.id dari serangan CCS Injection Vulnerability dan Poddle Attack\n\n\nhasil cek di ssl labs:\n\n\n\n\n\n\nCCS Injection Vulnerability\n\n\nPoddle Attack\n\n\n\n\nsolusi:\n\n\n\n\nset TLSv1 TLSv1.1 TLSv1.2 pada koneksi https.\n\n\nDisable weak cipher TLS termasuk SSLv3.\n\n\nUpdate / Patch OpenSSL.\n\n\n\n\nPercobaan ini dilakukan di mail2.abc.co.id mengingat versi yang digunakan sama yaitu 8.0.4 dan mengingat pula server mail production tidak mungkin untuk dicoba-coba\n\n\ninstall zm proxy via installer dari versi zimbra yang running. untuk mengetahui zimbra version cukup ketikan perintah zmcontrol -v ( as zimbra user) .\nlalu execute installer:\n\n\n./install.sh\n\n\n\nikuti langkah dst:\n\n\nDo you agree with the terms of the software license agreement? [N] Y\n\nDo you agree with the terms of the software license agreement? [N] Y\n\nDo you want to verify message store database integrity? [Y] N\n\nDo you wish to upgrade? [Y] Y\n\nInstall zimbra-memcached [N] N\nInstall zimbra-proxy [N] Y\n\nThe system will be modified.  Continue? [N] Y\n\nNotify Zimbra of your installation? [Yes] Yes\nlog full:\nroot@mail2:/home/dhuka/zcs-8.0.4_GA_5737.UBUNTU12_64.20130524120036# ./install.sh \nOperations logged to /tmp/install.log.8895\nChecking for existing installation...\n    zimbra-ldap...FOUND zimbra-ldap-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-logger...FOUND zimbra-logger-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-mta...FOUND zimbra-mta-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-snmp...FOUND zimbra-snmp-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-store...FOUND zimbra-store-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-apache...FOUND zimbra-apache-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-spell...FOUND zimbra-spell-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-convertd...NOT FOUND\n    zimbra-memcached...NOT FOUND\n    zimbra-proxy...NOT FOUND\n    zimbra-archiving...NOT FOUND\n    zimbra-cluster...NOT FOUND\n    zimbra-core...FOUND zimbra-core-8.0.4.GA.5737.UBUNTU12.64\nZCS upgrade from 8.0.4 to 8.0.4 will be performed.\nSaving existing configuration file to /opt/zimbra/.saveconfig\n\nPLEASE READ THIS AGREEMENT CAREFULLY BEFORE USING THE SOFTWARE.\nZIMBRA, INC. (\"ZIMBRA\") WILL ONLY LICENSE THIS SOFTWARE TO YOU IF YOU\nFIRST ACCEPT THE TERMS OF THIS AGREEMENT. BY DOWNLOADING OR INSTALLING\nTHE SOFTWARE, OR USING THE PRODUCT, YOU ARE CONSENTING TO BE BOUND BY\nTHIS AGREEMENT. IF YOU DO NOT AGREE TO ALL OF THE TERMS OF THIS\nAGREEMENT, THEN DO NOT DOWNLOAD, INSTALL OR USE THE PRODUCT.\nLicense Terms for the Zimbra Collaboration Suite:\n  http://www.zimbra.com/license/zimbra_public_eula_2.1.html\nDo you agree with the terms of the software license agreement? [N] Y\n\nOracle Binary Code License Agreement for the Java SE Platform Products\nORACLE  AMERICA, INC. (\"ORACLE\"), FOR AND ON BEHALF OF ITSELF AND ITS SUBSIDIARIES AND AFFILIATES UNDER COMMON CONTROL, IS WILLING TO  LICENSE  THE SOFTWARE  TO YOU ONLY UPON THE CONDITION THAT YOU ACCEPT ALL OF THE TERMS  CONTAINED IN THIS BINARY CODE LICENSE AGREEMENT AND SUPPLEMENTAL  LICENSE TERMS (COLLECTIVELY \"AGREEMENT\").  PLEASE READ THE AGREEMENT  CAREFULLY.  BY SELECTING THE \"ACCEPT LICENSE AGREEMENT\" (OR THE EQUIVALENT) BUTTON AND/OR BY USING THE SOFTWARE YOU ACKNOWLEDGE THAT YOU HAVE READ THE TERMS AND AGREE TO THEM.  IF YOU ARE AGREEING TO THESE TERMS ON BEHALF OF A  COMPANY OR OTHER LEGAL ENTITY, YOU REPRESENT THAT YOU HAVE THE LEGAL  AUTHORITY TO BIND THE LEGAL ENTITY TO THESE TERMS.  IF YOU DO NOT HAVE SUCH  AUTHORITY, OR IF YOU DO NOT WISH TO BE BOUND BY THE TERMS, THEN SELECT THE \"DECLINE LICENSE AGREEMENT\" (OR THE EQUIVALENT) BUTTON AND YOU MUST NOT USE THE SOFTWARE ON THIS SITE OR ANY OTHER MEDIA ON WHICH THE SOFTWARE IS CONTAINED.\n|\n--8\n--SNIP--\n|\nRedwood Shores, California 94065, USA.\nLast updated May 17, 2011\n\nDo you agree with the terms of the software license agreement? [N] Y\nChecking for prerequisites...\n     FOUND: NPTL\n     FOUND: netcat-openbsd-1.89-4ubuntu1\n     FOUND: sudo-1.8.3p1-1ubuntu3.3\n     FOUND: libidn11-1.23-2\n     FOUND: libpcre3-8.12-4\n     FOUND: libgmp3c2-2:4.3.2+dfsg-2ubuntu1\n     FOUND: libexpat1-2.0.1-7.2ubuntu1.1\n     FOUND: libstdc++6-4.6.3-1ubuntu5\n     FOUND: libperl5.14-5.14.2-6ubuntu2.2\nChecking for suggested prerequisites...\n     FOUND: pax\n     FOUND: perl-5.14.2\n     FOUND: sysstat\n     FOUND: sqlite3\nPrerequisite check complete.\nChecking current number of databases...\nDo you want to verify message store database integrity? [Y] N\nChecking for installable packages\nFound zimbra-core\nFound zimbra-ldap\nFound zimbra-logger\nFound zimbra-mta\nFound zimbra-snmp\nFound zimbra-store\nFound zimbra-apache\nFound zimbra-spell\nFound zimbra-memcached\nFound zimbra-proxy\n\nThe Zimbra Collaboration Server appears already to be installed.\nIt can be upgraded with no effect on existing accounts,\nor the current installation can be completely removed prior\nto installation for a clean install.\nDo you wish to upgrade? [Y] Y\nSelect the packages to install\n    Upgrading zimbra-core\n    Upgrading zimbra-ldap\n    Upgrading zimbra-logger\n    Upgrading zimbra-mta\n    Upgrading zimbra-snmp\n    Upgrading zimbra-store\n    Upgrading zimbra-apache\n    Upgrading zimbra-spell\nInstall zimbra-memcached [N] N\nInstall zimbra-proxy [N] Y\nChecking required space for zimbra-core\nChecking space for zimbra-store\nInstalling:\n    zimbra-core\n    zimbra-ldap\n    zimbra-logger\n    zimbra-mta\n    zimbra-snmp\n    zimbra-store\n    zimbra-apache\n    zimbra-spell\n    zimbra-proxy\nThe system will be modified.  Continue? [N] Y\nShutting down zimbra mail\nBacking up the ldap database...done.\nRemoving existing packages\n   zimbra-ldap...done\n   zimbra-logger...done\n   zimbra-mta...done\n   zimbra-snmp...done\n   zimbra-store...done\n   zimbra-spell...done\n   zimbra-apache...done\n   zimbra-core...done\nRemoving deployed webapp directories\nInstalling packages\n    zimbra-core......zimbra-core_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-ldap......zimbra-ldap_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-logger......zimbra-logger_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-mta......zimbra-mta_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-snmp......zimbra-snmp_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-store......zimbra-store_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-apache......zimbra-apache_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-spell......zimbra-spell_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-proxy......zimbra-proxy_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\nSetting defaults from saved config in /opt/zimbra/.saveconfig/config.save\n   HOSTNAME=mail2.abc.co.id\n   LDAPHOST=mail2.abc.co.id\n   LDAPPORT=389\n   SNMPTRAPHOST=mail2.abc.co.id\n   SMTPSOURCE=admin@mail2.abc.co.id\n   SMTPDEST=admin@mail2.abc.co.id\n   SNMPNOTIFY=yes\n   SMTPNOTIFY=yes\n   LDAPROOTPW=GLcHa6eCA\n   LDAPZIMBRAPW=GLcHa6eCA\n   LDAPPOSTPW=GLcHa6eCA\n   LDAPREPPW=GLcHa6eCA\n   LDAPAMAVISPW=GLcHa6eCA\n   LDAPNGINXPW=GLcHa6eCA\nRestoring existing configuration file from /opt/zimbra/.saveconfig/localconfig.xml...done\nOperations logged to /tmp/zmsetup.04072015-090607.log\nRunning zmldapapplyldif...done.\nChecking ldap status....not running.\nStarting ldap...done.\nSetting defaults...done.\nSetting defaults from existing config...done.\nChecking for port conflicts\nSetting defaults from ldap...done.\nSaving config in /opt/zimbra/config.3638...done.\nOperations logged to /tmp/zmsetup.04072015-090607.log\nSetting local config values...done.\nInitializing core config...Setting up CA...done.\nDeploying CA to /opt/zimbra/conf/ca ...done.\nSetting replication password...done.\nSetting Postfix password...done.\nSetting amavis password...done.\nSetting nginx password...done.\nCreating server entry for mail2.abc.co.id...already exists.\nSetting Zimbra IP Mode...done.\nSaving CA in ldap ...done.\nSaving SSL Certificate in ldap ...done.\nSetting service ports on mail2.abc.co.id...done.\nAdding mail2.abc.co.id to zimbraMailHostPool in default COS...done.\nSetting Keyboard Shortcut Preferences...done.\nSetting zimbraFeatureTasksEnabled=TRUE...done.\nSetting zimbraFeatureBriefcasesEnabled=FALSE...done.\nSetting MTA auth host...done.\nSetting TimeZone Preference...done.\nInitializing mta config...done.\nSetting services on mail2.abc.co.id...done.\nCreating user spam.lacztdgpp@mail2.abc.co.id...already exists.\nCreating user ham.whtwh7nnri@mail2.abc.co.id...already exists.\nCreating user virus-quarantine.yldr5t3vht@mail2.abc.co.id...already exists.\nSetting spam training and Anti-virus quarantine accounts...done.\nConfiguring SNMP...done.\nSetting up syslog.conf...done.\nStarting servers...done.\nChecking for deprecated zimlets...done.\nChecking for network zimlets in LDAP...done.\nRemoving network zimlets...\nFinished removing network zimlets.\nInstalling common zimlets...\n    com_zimbra_srchhighlighter...done.\n    com_zimbra_url...done.\n    com_zimbra_webex...done.\n    com_zimbra_email...done.\n    com_zimbra_date...done.\n    com_zimbra_attachmail...done.\n    com_zimbra_viewmail...done.\n    com_zimbra_bulkprovision...done.\n    com_zimbra_proxy_config...done.\n    com_zimbra_tooltip...done.\n    com_zimbra_clientuploader...done.\n    com_zimbra_ymemoticons...done.\n    com_zimbra_attachcontacts...done.\n    com_zimbra_adminversioncheck...done.\n    com_zimbra_phone...done.\n    com_zimbra_cert_manager...done.\nFinished installing common zimlets.\nGetting list of all zimlets...done.\nUpdating non-standard zimlets...\nFinished updating non-standard zimlets.\nRestarting mailboxd...done.\nSkipping creation of default domain GAL sync account - existing install detected.\nYou have the option of notifying Zimbra of your installation.\nThis helps us to track the uptake of the Zimbra Collaboration Server.\nThe only information that will be transmitted is:\n    The VERSION of zcs installed (8.0.4_GA_5737_UBUNTU12_64)\n    The ADMIN EMAIL ADDRESS created (admin@abc.co.id)\nNotify Zimbra of your installation? [Yes] Yes\nNotifying Zimbra of installation via http://www.zimbra.com/cgi-bin/notify.cgi?VER=8.0.4_GA_5737_UBUNTU12_64\nMAIL=admin@abc.co.id\nNotification complete\nSetting up zimbra crontab...done.\n\nMoving /tmp/zmsetup.04072015-090607.log to /opt/zimbra/log\n\nConfiguration complete - press return to exit\n\nYou have new mail in /var/mail/root\nroot@mail2:/home/dhuka/zcs-8.0.4_GA_5737.UBUNTU12_64.20130524120036#\n\n\n\nlalu cek status zimbra proxy:\n\n\nroot@mail2:/home/dhuka/zcs-8.0.4_GA_5737.UBUNTU12_64.20130524120036# su - zimbra\nzimbra@mail2:~$ zmcontrol status\nHost mail2.abc.co.id\n    antispam                Running\n    antivirus               Running\n    ldap                    Running\n    logger                  Running\n    mailbox                 Running\n    mta                     Running\n    opendkim                Running\n    proxy                   Running\n    snmp                    Running\n    stats                   Running\n    zmconfigd               Running\nzimbra@mail2:~$\n\n\n\nKarena port proxy akan diset untuk menggantikan yang existing, maka port existing harus diset berbeda untuk menghindari konflik.\n\n\nzimbra@mail2:~$ zmprov ms `zmhostname` \\                                                 \n\n zimbraImapBindPort 6143 \\\n\n zimbraImapSSLBindPort 6993 \\\n\n zimbraPop3BindPort 6110 \\\n\n zimbraPop3SSLBindPort 6995 \\\n\n zimbraMailSSLPort 6443 \\\n\n zimbraMailPort 680\ncoba cek, apakah sudah diset sama dengan diatas:\n\nzimbra@mail2:~$ zmprov -l gs `zmhostname` | grep -i port\nzimbraAdminImapImportNumThreads: 20\nzimbraAdminPort: 7071\nzimbraAdminProxyPort: 9071\nzimbraBackupReportEmailSubjectPrefix: ZCS Backup Report\nzimbraImapBindPort: 6143\nzimbraImapProxyBindPort: 7143\nzimbraImapSSLBindPort: 6993\nzimbraImapSSLProxyBindPort: 7993\nzimbraLmtpBindPort: 7025\nzimbraMailPort: 680\nzimbraMailProxyPort: 8080\nzimbraMailSSLClientCertPort: 9443\nzimbraMailSSLPort: 6443\nzimbraMailSSLProxyClientCertPort: 3443\nzimbraMailSSLProxyPort: 8443\nzimbraMemcachedBindPort: 11211\nzimbraMessageChannelPort: 7285\nzimbraMilterBindPort: 7026\nzimbraNotifyBindPort: 7035\nzimbraNotifySSLBindPort: 7036\nzimbraPop3BindPort: 6110\nzimbraPop3ProxyBindPort: 7110\nzimbraPop3SSLBindPort: 6995\nzimbraPop3SSLProxyBindPort: 7995\nzimbraRemoteManagementPort: 22\nzimbraSmtpPort: 25\njika sudah, lalu restart zmcontrol:\nzimbra@mail2:~$ zmcontrol restart\nHost mail2.abc.co.id\n    Stopping vmware-ha...Done.\n    Stopping zmconfigd...Done.\n    Stopping stats...Done.\n    Stopping mta...Done.\n    Stopping spell...Done.\n    Stopping snmp...Done.\n    Stopping cbpolicyd...Done.\n    Stopping archiving...Done.\n    Stopping opendkim...Done.\n    Stopping antivirus...Done.\n    Stopping antispam...Done.\n    Stopping proxy...Done.\n    Stopping memcached...Done.\n    Stopping mailbox...Done.\n    Stopping logger...Done.\n    Stopping ldap...Done.\nHost mail2.abc.co.id\n    Starting ldap...Done.\n    Starting zmconfigd...Done.\n    Starting logger...Done.\n    Starting mailbox...Done.\n    Starting proxy...Done.\n    Starting antispam...Done.\n    Starting antivirus...Done.\n    Starting opendkim...Done.\n    Starting snmp...Done.\n    Starting mta...Done.\n    Starting stats...Done.\nzimbra@mail2:~$\n\n\n\nlalu set port yang benar dan restart zimbra:\n\n\nzimbra@mail2:~$ zmprov ms `zmhostname` \\\n\n zimbraImapBindPort 7143 \\\n\n zimbraImapProxyBindPort 143 \\\n\n zimbraImapSSLBindPort 7993 \\\n\n zimbraImapSSLProxyBindPort 993 \\\n\n zimbraPop3BindPort 7110 \\\n\n zimbraPop3ProxyBindPort 110 \\\n\n zimbraPop3SSLBindPort 7995 \\\n\n zimbraPop3SSLProxyBindPort 995 \\\n\n zimbraMailSSLPort 7443 \\\n\n zimbraMailSSLProxyPort 443 \\\n\n zimbraReverseProxyHttpEnabled TRUE \\\n\n zimbraMailProxyPort 80 \\\n\n zimbraMailPort 8080 \\\n\n zimbraMailMode https \\\n\n zimbraReverseProxyMailMode https \\\n\n zimbraReverseProxySSLToUpstreamEnabled TRUE\nYou have new mail in /var/mail/zimbra\nzimbra@mail2:~$ zmcontrol restart\nHost mail2.abc.co.id\n    Stopping vmware-ha...Done.\n    Stopping zmconfigd...Done.\n    Stopping stats...Done.\n    Stopping mta...Done.\n    Stopping spell...Done.\n    Stopping snmp...Done.\n    Stopping cbpolicyd...Done.\n    Stopping archiving...Done.\n    Stopping opendkim...Done.\n    Stopping antivirus...Done.\n    Stopping antispam...Done.\n    Stopping proxy...Done.\n    Stopping memcached...Done.\n    Stopping mailbox...Done.\n    Stopping logger...Done.\n    Stopping ldap...Done.\nHost mail2.abc.co.id\n    Starting ldap...Done.\n    Starting zmconfigd...Done.\n    Starting logger...Done.\n    Starting mailbox...Done.\n    Starting proxy...Done.\n    Starting antispam...Done.\n    Starting antivirus...Done.\n    Starting opendkim...Done.\n    Starting snmp...Done.\n    Starting mta...Done.\n    Starting stats...Done.\nzimbra@mail2:~$\n\n\n\nSetting SSL Config\n\n\nzimbra@mail2:~$ zmprov mcf zimbraReverseProxySSLCiphers 'EECDH:EDH:SHA256:SHA384:!RC4:HIGH:!aNULL:!MD5:!kEDH:!AD:!SSLv2:!NULL:!3DES'\n\n\n\nedit file-file berikut yang ada di /opt/zimbra/conf/nginx/templates/ . pastikan dibackup terlebih dahulu.\n\n\nnginx.conf.mail.imaps.default.template\nnginx.conf.mail.imaps.template\nnginx.conf.mail.imap.default.template (for starttls)\nnginx.conf.mail.imap.template (for starttls)\nnginx.conf.mail.pop3s.default.template\nnginx.conf.mail.pop3s.template\nnginx.conf.mail.pop3.default.template (for starttls)\nnginx.conf.mail.pop3.template (for starttls)\nnginx.conf.mail.template\nnginx.conf.web.admin.default.template\nnginx.conf.web.admin.template\nnginx.conf.web.https.default.template\nnginx.conf.web.https.template\nnginx.conf.web.sso.default.template\nnginx.conf.web.sso.template\n\n\n\ntambahkan setiap blok ssl dari setiap file diatas dengan opsi dibawah ini:\n\n\nssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n\n\n\nmisal awal blok ssl seperti ini:\n\n\n ssl                     on;\n ssl_prefer_server_ciphers ${web.ssl.preferserverciphers};\n ssl_ciphers             ${web.ssl.ciphers};\n ssl_certificate         ${ssl.crt.default};\n ssl_certificate_key     ${ssl.key.default};\n\n\n\nakan menjadi seperti:\n\n\n ssl                     on;\n ssl_prefer_server_ciphers ${web.ssl.preferserverciphers};\n ssl_ciphers             ${web.ssl.ciphers};\n ssl_certificate         ${ssl.crt.default};\n ssl_certificate_key     ${ssl.key.default};\n ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n\n\n\nkhusus untuk file \nnginx.conf.web.https.default.template\n dan \nnginx.conf.web.https.template\n tambahkan seperti dibawah ini:\n\n\nssl on; \nssl_prefer_server_ciphers ${web.ssl.preferserverciphers}; \n# Add extra items for A+ rating \nssl_protocols TLSv1 TLSv1.1 TLSv1.2; \nadd_header Strict-Transport-Security max-age=15768000; \nssl_ciphers ${web.ssl.ciphers};\n\n\n\nlalu restart zmproxy:\n\n\nzmproxyctl restart\n\n\n\n\n\nDisable Weak SSL/TLS Cipher mailbox\n\n\n\n\njalankan command dibawah ini:\n\n\nzimbra@mail2:~$ zmprov mcf +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_256_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites DHE-RSA-AES256-SHA  \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites DHE-RSA-AES256-SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_256_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_WITH_DES_CBC_SHA  \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_RSA_WITH_DES_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_DSS_WITH_DES_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_EXPORT_WITH_RC4_40_MD5 \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_DSS_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_128_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_128_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_DES_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_128_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_256_CBC_SHA256 \nzimbra@mail2:~$ zmproxyctl restart\nStopping nginx...done.\nStarting nginx...done.\nYou have new mail in /var/mail/zimbra\nzimbra@mail2:~$\n\n\n\nlalu restart mailbox:\n\n\nzimbra@mail2:~$ zmmailboxdctl restart\nStopping mailboxd...done.\nStarting mailboxd...done.\nzimbra@mail2:~$\n\n\n\n\n\nPatching OpenSSL\n\n\n\n\npindah directory ke \n/tmp/\n lalu download file \n\"http://files.zimbra.com/downloads/security/zmopenssl-updater.sh\"\n\n\nroot@mail2:/opt/zimbra/conf/nginx/templates# cd /tmp/\nroot@mail2:/tmp# wget -c \"http://files.zimbra.com/downloads/security/zmopenssl-updater.sh\"\n--2015-04-07 12:58:22--  http://files.zimbra.com/downloads/security/zmopenssl-updater.sh\nResolving files.zimbra.com (files.zimbra.com)... 54.230.159.200\nConnecting to files.zimbra.com (files.zimbra.com)|54.230.159.200|:80... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://files.zimbra.com/downloads/security/zmopenssl-updater.sh [following]\n--2015-04-07 12:58:26--  https://files.zimbra.com/downloads/security/zmopenssl-updater.sh\nConnecting to files.zimbra.com (files.zimbra.com)|54.230.159.200|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2788 (2.7K) [application/x-unknown-content-type]\nSaving to: `zmopenssl-updater.sh'\n100%[==============================================================================================================================\n] 2,788       --.-K/s   in 0s      \n2015-04-07 12:58:31 (697 MB/s) - `zmopenssl-updater.sh' saved [2788/2788]\n\nberi permission lalu eksekusi:\nroot@mail2:/tmp# chmod a+rx zmopenssl-updater.sh\nroot@mail2:/tmp# ./zmopenssl-updater.sh \nDownloading patched openssl\nValidating patched openssl: success\nBacking up old openssl: complete\nInstalling patched openssl: complete\nOpenSSL patch process complete.\nPlease restart Zimbra Collaboration Suite as the Zimbra user via zmcontrol restart\nroot@mail2:/tmp#\n\n\n\nrestart zimbra dengan zmcontrol lalu check versi openssl:\n\n\nzimbra@mail2:~$ zmcontrol restart\nHost mail2.abc.co.id\n    Stopping vmware-ha...Done.\n    Stopping zmconfigd...Done.\n    Stopping stats...Done.\n    Stopping mta...Done.\n    Stopping spell...Done.\n    Stopping snmp...Done.\n    Stopping cbpolicyd...Done.\n    Stopping archiving...Done.\n    Stopping opendkim...Done.\n    Stopping antivirus...Done.\n    Stopping antispam...Done.\n    Stopping proxy...Done.\n    Stopping memcached...Done.\n    Stopping mailbox...Done.\n    Stopping logger...Done.\n    Stopping ldap...Done.\nHost mail2.abc.co.id\n    Starting ldap...Done.\n    Starting zmconfigd...Done.\n    Starting logger...Done.\n    Starting mailbox...Done.\n    Starting proxy...Done.\n    Starting antispam...Done.\n    Starting antivirus...Done.\n    Starting opendkim...Done.\n    Starting snmp...Done.\n    Starting mta...Done.\n    Starting stats...Done.\nzimbra@mail2:~$ openssl version\nOpenSSL 1.0.1h 5 Jun 2014\nYou have new mail in /var/mail/zimbra\nzimbra@mail2:~$\n\n\n\nTesting\n\nuntuk testing:\n\n\nroot@mail2:/opt/zimbra/conf/nginx/templates# openssl s_time -connect localhost:443 -new -cipher AES256-SHA\nCollecting connection statistics for 30 seconds\nERROR\n140543357974176:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1247:SSL alert number 40\nroot@mail2:/opt/zimbra/conf/nginx/templates#\n\n\n\ndengan for loop\n\n\nzimbra@mail2:~$ for p in 993 995 443 ; do echo Port $p ; timeout 3 openssl s_client -connect `zmhostname`:$p -ssl3 |grep failure ; done\nPort 993\n140567794857632:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1275:SSL alert number 40\n140567794857632:error:1409E0E5:SSL routines:SSL3_WRITE_BYTES:ssl handshake failure:s3_pkt.c:598:\nPort 995\n140486668211872:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1275:SSL alert number 40\n140486668211872:error:1409E0E5:SSL routines:SSL3_WRITE_BYTES:ssl handshake failure:s3_pkt.c:598:\nPort 443\n140321034884768:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1275:SSL alert number 40\n140321034884768:error:1409E0E5:SSL routines:SSL3_WRITE_BYTES:ssl handshake failure:s3_pkt.c:598:\nYou have new mail in /var/mail/zimbra\n\n\n\natau bisa via ssl labs\n\n\n\n\nselesai\n\n\nref:\n 1. http://blog.capitar.com/getting-a-better-zimbra-ssl-labs-rating/\n 2. https://wiki.zimbra.com/wiki/How_to_disable_SSLv3\n 3. http://wiki.zimbra.com/wiki/ShanxT-Removing-Insecure-SSL-Ciphers\n 4. http://forums.zimbra.com/announcements/73677-20140606-zimbra-security-advisory-cve-2014-0224-ccs-injection-vulnerability.html", 
            "title": "Zimbra - Mengamankan serangan Poddle Attack dan Vulnerability SSL"
        }, 
        {
            "location": "/zimbra-poddle-attack/#mengamankan-zimbra-804-di-mail2abccoid-dari-serangan-ccs-injection-vulnerability-dan-poddle-attack", 
            "text": "hasil cek di ssl labs:    CCS Injection Vulnerability  Poddle Attack   solusi:   set TLSv1 TLSv1.1 TLSv1.2 pada koneksi https.  Disable weak cipher TLS termasuk SSLv3.  Update / Patch OpenSSL.   Percobaan ini dilakukan di mail2.abc.co.id mengingat versi yang digunakan sama yaitu 8.0.4 dan mengingat pula server mail production tidak mungkin untuk dicoba-coba  install zm proxy via installer dari versi zimbra yang running. untuk mengetahui zimbra version cukup ketikan perintah zmcontrol -v ( as zimbra user) .\nlalu execute installer:  ./install.sh  ikuti langkah dst:  Do you agree with the terms of the software license agreement? [N] Y\n\nDo you agree with the terms of the software license agreement? [N] Y\n\nDo you want to verify message store database integrity? [Y] N\n\nDo you wish to upgrade? [Y] Y\n\nInstall zimbra-memcached [N] N\nInstall zimbra-proxy [N] Y\n\nThe system will be modified.  Continue? [N] Y\n\nNotify Zimbra of your installation? [Yes] Yes\nlog full:\nroot@mail2:/home/dhuka/zcs-8.0.4_GA_5737.UBUNTU12_64.20130524120036# ./install.sh \nOperations logged to /tmp/install.log.8895\nChecking for existing installation...\n    zimbra-ldap...FOUND zimbra-ldap-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-logger...FOUND zimbra-logger-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-mta...FOUND zimbra-mta-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-snmp...FOUND zimbra-snmp-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-store...FOUND zimbra-store-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-apache...FOUND zimbra-apache-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-spell...FOUND zimbra-spell-8.0.4.GA.5737.UBUNTU12.64\n    zimbra-convertd...NOT FOUND\n    zimbra-memcached...NOT FOUND\n    zimbra-proxy...NOT FOUND\n    zimbra-archiving...NOT FOUND\n    zimbra-cluster...NOT FOUND\n    zimbra-core...FOUND zimbra-core-8.0.4.GA.5737.UBUNTU12.64\nZCS upgrade from 8.0.4 to 8.0.4 will be performed.\nSaving existing configuration file to /opt/zimbra/.saveconfig\n\nPLEASE READ THIS AGREEMENT CAREFULLY BEFORE USING THE SOFTWARE.\nZIMBRA, INC. (\"ZIMBRA\") WILL ONLY LICENSE THIS SOFTWARE TO YOU IF YOU\nFIRST ACCEPT THE TERMS OF THIS AGREEMENT. BY DOWNLOADING OR INSTALLING\nTHE SOFTWARE, OR USING THE PRODUCT, YOU ARE CONSENTING TO BE BOUND BY\nTHIS AGREEMENT. IF YOU DO NOT AGREE TO ALL OF THE TERMS OF THIS\nAGREEMENT, THEN DO NOT DOWNLOAD, INSTALL OR USE THE PRODUCT.\nLicense Terms for the Zimbra Collaboration Suite:\n  http://www.zimbra.com/license/zimbra_public_eula_2.1.html\nDo you agree with the terms of the software license agreement? [N] Y\n\nOracle Binary Code License Agreement for the Java SE Platform Products\nORACLE  AMERICA, INC. (\"ORACLE\"), FOR AND ON BEHALF OF ITSELF AND ITS SUBSIDIARIES AND AFFILIATES UNDER COMMON CONTROL, IS WILLING TO  LICENSE  THE SOFTWARE  TO YOU ONLY UPON THE CONDITION THAT YOU ACCEPT ALL OF THE TERMS  CONTAINED IN THIS BINARY CODE LICENSE AGREEMENT AND SUPPLEMENTAL  LICENSE TERMS (COLLECTIVELY \"AGREEMENT\").  PLEASE READ THE AGREEMENT  CAREFULLY.  BY SELECTING THE \"ACCEPT LICENSE AGREEMENT\" (OR THE EQUIVALENT) BUTTON AND/OR BY USING THE SOFTWARE YOU ACKNOWLEDGE THAT YOU HAVE READ THE TERMS AND AGREE TO THEM.  IF YOU ARE AGREEING TO THESE TERMS ON BEHALF OF A  COMPANY OR OTHER LEGAL ENTITY, YOU REPRESENT THAT YOU HAVE THE LEGAL  AUTHORITY TO BIND THE LEGAL ENTITY TO THESE TERMS.  IF YOU DO NOT HAVE SUCH  AUTHORITY, OR IF YOU DO NOT WISH TO BE BOUND BY THE TERMS, THEN SELECT THE \"DECLINE LICENSE AGREEMENT\" (OR THE EQUIVALENT) BUTTON AND YOU MUST NOT USE THE SOFTWARE ON THIS SITE OR ANY OTHER MEDIA ON WHICH THE SOFTWARE IS CONTAINED.\n|\n--8 --SNIP--\n|\nRedwood Shores, California 94065, USA.\nLast updated May 17, 2011\n\nDo you agree with the terms of the software license agreement? [N] Y\nChecking for prerequisites...\n     FOUND: NPTL\n     FOUND: netcat-openbsd-1.89-4ubuntu1\n     FOUND: sudo-1.8.3p1-1ubuntu3.3\n     FOUND: libidn11-1.23-2\n     FOUND: libpcre3-8.12-4\n     FOUND: libgmp3c2-2:4.3.2+dfsg-2ubuntu1\n     FOUND: libexpat1-2.0.1-7.2ubuntu1.1\n     FOUND: libstdc++6-4.6.3-1ubuntu5\n     FOUND: libperl5.14-5.14.2-6ubuntu2.2\nChecking for suggested prerequisites...\n     FOUND: pax\n     FOUND: perl-5.14.2\n     FOUND: sysstat\n     FOUND: sqlite3\nPrerequisite check complete.\nChecking current number of databases...\nDo you want to verify message store database integrity? [Y] N\nChecking for installable packages\nFound zimbra-core\nFound zimbra-ldap\nFound zimbra-logger\nFound zimbra-mta\nFound zimbra-snmp\nFound zimbra-store\nFound zimbra-apache\nFound zimbra-spell\nFound zimbra-memcached\nFound zimbra-proxy\n\nThe Zimbra Collaboration Server appears already to be installed.\nIt can be upgraded with no effect on existing accounts,\nor the current installation can be completely removed prior\nto installation for a clean install.\nDo you wish to upgrade? [Y] Y\nSelect the packages to install\n    Upgrading zimbra-core\n    Upgrading zimbra-ldap\n    Upgrading zimbra-logger\n    Upgrading zimbra-mta\n    Upgrading zimbra-snmp\n    Upgrading zimbra-store\n    Upgrading zimbra-apache\n    Upgrading zimbra-spell\nInstall zimbra-memcached [N] N\nInstall zimbra-proxy [N] Y\nChecking required space for zimbra-core\nChecking space for zimbra-store\nInstalling:\n    zimbra-core\n    zimbra-ldap\n    zimbra-logger\n    zimbra-mta\n    zimbra-snmp\n    zimbra-store\n    zimbra-apache\n    zimbra-spell\n    zimbra-proxy\nThe system will be modified.  Continue? [N] Y\nShutting down zimbra mail\nBacking up the ldap database...done.\nRemoving existing packages\n   zimbra-ldap...done\n   zimbra-logger...done\n   zimbra-mta...done\n   zimbra-snmp...done\n   zimbra-store...done\n   zimbra-spell...done\n   zimbra-apache...done\n   zimbra-core...done\nRemoving deployed webapp directories\nInstalling packages\n    zimbra-core......zimbra-core_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-ldap......zimbra-ldap_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-logger......zimbra-logger_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-mta......zimbra-mta_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-snmp......zimbra-snmp_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-store......zimbra-store_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-apache......zimbra-apache_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-spell......zimbra-spell_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\n    zimbra-proxy......zimbra-proxy_8.0.4.GA.5737.UBUNTU12.64_amd64.deb...done\nSetting defaults from saved config in /opt/zimbra/.saveconfig/config.save\n   HOSTNAME=mail2.abc.co.id\n   LDAPHOST=mail2.abc.co.id\n   LDAPPORT=389\n   SNMPTRAPHOST=mail2.abc.co.id\n   SMTPSOURCE=admin@mail2.abc.co.id\n   SMTPDEST=admin@mail2.abc.co.id\n   SNMPNOTIFY=yes\n   SMTPNOTIFY=yes\n   LDAPROOTPW=GLcHa6eCA\n   LDAPZIMBRAPW=GLcHa6eCA\n   LDAPPOSTPW=GLcHa6eCA\n   LDAPREPPW=GLcHa6eCA\n   LDAPAMAVISPW=GLcHa6eCA\n   LDAPNGINXPW=GLcHa6eCA\nRestoring existing configuration file from /opt/zimbra/.saveconfig/localconfig.xml...done\nOperations logged to /tmp/zmsetup.04072015-090607.log\nRunning zmldapapplyldif...done.\nChecking ldap status....not running.\nStarting ldap...done.\nSetting defaults...done.\nSetting defaults from existing config...done.\nChecking for port conflicts\nSetting defaults from ldap...done.\nSaving config in /opt/zimbra/config.3638...done.\nOperations logged to /tmp/zmsetup.04072015-090607.log\nSetting local config values...done.\nInitializing core config...Setting up CA...done.\nDeploying CA to /opt/zimbra/conf/ca ...done.\nSetting replication password...done.\nSetting Postfix password...done.\nSetting amavis password...done.\nSetting nginx password...done.\nCreating server entry for mail2.abc.co.id...already exists.\nSetting Zimbra IP Mode...done.\nSaving CA in ldap ...done.\nSaving SSL Certificate in ldap ...done.\nSetting service ports on mail2.abc.co.id...done.\nAdding mail2.abc.co.id to zimbraMailHostPool in default COS...done.\nSetting Keyboard Shortcut Preferences...done.\nSetting zimbraFeatureTasksEnabled=TRUE...done.\nSetting zimbraFeatureBriefcasesEnabled=FALSE...done.\nSetting MTA auth host...done.\nSetting TimeZone Preference...done.\nInitializing mta config...done.\nSetting services on mail2.abc.co.id...done.\nCreating user spam.lacztdgpp@mail2.abc.co.id...already exists.\nCreating user ham.whtwh7nnri@mail2.abc.co.id...already exists.\nCreating user virus-quarantine.yldr5t3vht@mail2.abc.co.id...already exists.\nSetting spam training and Anti-virus quarantine accounts...done.\nConfiguring SNMP...done.\nSetting up syslog.conf...done.\nStarting servers...done.\nChecking for deprecated zimlets...done.\nChecking for network zimlets in LDAP...done.\nRemoving network zimlets...\nFinished removing network zimlets.\nInstalling common zimlets...\n    com_zimbra_srchhighlighter...done.\n    com_zimbra_url...done.\n    com_zimbra_webex...done.\n    com_zimbra_email...done.\n    com_zimbra_date...done.\n    com_zimbra_attachmail...done.\n    com_zimbra_viewmail...done.\n    com_zimbra_bulkprovision...done.\n    com_zimbra_proxy_config...done.\n    com_zimbra_tooltip...done.\n    com_zimbra_clientuploader...done.\n    com_zimbra_ymemoticons...done.\n    com_zimbra_attachcontacts...done.\n    com_zimbra_adminversioncheck...done.\n    com_zimbra_phone...done.\n    com_zimbra_cert_manager...done.\nFinished installing common zimlets.\nGetting list of all zimlets...done.\nUpdating non-standard zimlets...\nFinished updating non-standard zimlets.\nRestarting mailboxd...done.\nSkipping creation of default domain GAL sync account - existing install detected.\nYou have the option of notifying Zimbra of your installation.\nThis helps us to track the uptake of the Zimbra Collaboration Server.\nThe only information that will be transmitted is:\n    The VERSION of zcs installed (8.0.4_GA_5737_UBUNTU12_64)\n    The ADMIN EMAIL ADDRESS created (admin@abc.co.id)\nNotify Zimbra of your installation? [Yes] Yes\nNotifying Zimbra of installation via http://www.zimbra.com/cgi-bin/notify.cgi?VER=8.0.4_GA_5737_UBUNTU12_64 MAIL=admin@abc.co.id\nNotification complete\nSetting up zimbra crontab...done.\n\nMoving /tmp/zmsetup.04072015-090607.log to /opt/zimbra/log\n\nConfiguration complete - press return to exit\n\nYou have new mail in /var/mail/root\nroot@mail2:/home/dhuka/zcs-8.0.4_GA_5737.UBUNTU12_64.20130524120036#  lalu cek status zimbra proxy:  root@mail2:/home/dhuka/zcs-8.0.4_GA_5737.UBUNTU12_64.20130524120036# su - zimbra\nzimbra@mail2:~$ zmcontrol status\nHost mail2.abc.co.id\n    antispam                Running\n    antivirus               Running\n    ldap                    Running\n    logger                  Running\n    mailbox                 Running\n    mta                     Running\n    opendkim                Running\n    proxy                   Running\n    snmp                    Running\n    stats                   Running\n    zmconfigd               Running\nzimbra@mail2:~$  Karena port proxy akan diset untuk menggantikan yang existing, maka port existing harus diset berbeda untuk menghindari konflik.  zimbra@mail2:~$ zmprov ms `zmhostname` \\                                                   zimbraImapBindPort 6143 \\  zimbraImapSSLBindPort 6993 \\  zimbraPop3BindPort 6110 \\  zimbraPop3SSLBindPort 6995 \\  zimbraMailSSLPort 6443 \\  zimbraMailPort 680\ncoba cek, apakah sudah diset sama dengan diatas:\n\nzimbra@mail2:~$ zmprov -l gs `zmhostname` | grep -i port\nzimbraAdminImapImportNumThreads: 20\nzimbraAdminPort: 7071\nzimbraAdminProxyPort: 9071\nzimbraBackupReportEmailSubjectPrefix: ZCS Backup Report\nzimbraImapBindPort: 6143\nzimbraImapProxyBindPort: 7143\nzimbraImapSSLBindPort: 6993\nzimbraImapSSLProxyBindPort: 7993\nzimbraLmtpBindPort: 7025\nzimbraMailPort: 680\nzimbraMailProxyPort: 8080\nzimbraMailSSLClientCertPort: 9443\nzimbraMailSSLPort: 6443\nzimbraMailSSLProxyClientCertPort: 3443\nzimbraMailSSLProxyPort: 8443\nzimbraMemcachedBindPort: 11211\nzimbraMessageChannelPort: 7285\nzimbraMilterBindPort: 7026\nzimbraNotifyBindPort: 7035\nzimbraNotifySSLBindPort: 7036\nzimbraPop3BindPort: 6110\nzimbraPop3ProxyBindPort: 7110\nzimbraPop3SSLBindPort: 6995\nzimbraPop3SSLProxyBindPort: 7995\nzimbraRemoteManagementPort: 22\nzimbraSmtpPort: 25\njika sudah, lalu restart zmcontrol:\nzimbra@mail2:~$ zmcontrol restart\nHost mail2.abc.co.id\n    Stopping vmware-ha...Done.\n    Stopping zmconfigd...Done.\n    Stopping stats...Done.\n    Stopping mta...Done.\n    Stopping spell...Done.\n    Stopping snmp...Done.\n    Stopping cbpolicyd...Done.\n    Stopping archiving...Done.\n    Stopping opendkim...Done.\n    Stopping antivirus...Done.\n    Stopping antispam...Done.\n    Stopping proxy...Done.\n    Stopping memcached...Done.\n    Stopping mailbox...Done.\n    Stopping logger...Done.\n    Stopping ldap...Done.\nHost mail2.abc.co.id\n    Starting ldap...Done.\n    Starting zmconfigd...Done.\n    Starting logger...Done.\n    Starting mailbox...Done.\n    Starting proxy...Done.\n    Starting antispam...Done.\n    Starting antivirus...Done.\n    Starting opendkim...Done.\n    Starting snmp...Done.\n    Starting mta...Done.\n    Starting stats...Done.\nzimbra@mail2:~$  lalu set port yang benar dan restart zimbra:  zimbra@mail2:~$ zmprov ms `zmhostname` \\  zimbraImapBindPort 7143 \\  zimbraImapProxyBindPort 143 \\  zimbraImapSSLBindPort 7993 \\  zimbraImapSSLProxyBindPort 993 \\  zimbraPop3BindPort 7110 \\  zimbraPop3ProxyBindPort 110 \\  zimbraPop3SSLBindPort 7995 \\  zimbraPop3SSLProxyBindPort 995 \\  zimbraMailSSLPort 7443 \\  zimbraMailSSLProxyPort 443 \\  zimbraReverseProxyHttpEnabled TRUE \\  zimbraMailProxyPort 80 \\  zimbraMailPort 8080 \\  zimbraMailMode https \\  zimbraReverseProxyMailMode https \\  zimbraReverseProxySSLToUpstreamEnabled TRUE\nYou have new mail in /var/mail/zimbra\nzimbra@mail2:~$ zmcontrol restart\nHost mail2.abc.co.id\n    Stopping vmware-ha...Done.\n    Stopping zmconfigd...Done.\n    Stopping stats...Done.\n    Stopping mta...Done.\n    Stopping spell...Done.\n    Stopping snmp...Done.\n    Stopping cbpolicyd...Done.\n    Stopping archiving...Done.\n    Stopping opendkim...Done.\n    Stopping antivirus...Done.\n    Stopping antispam...Done.\n    Stopping proxy...Done.\n    Stopping memcached...Done.\n    Stopping mailbox...Done.\n    Stopping logger...Done.\n    Stopping ldap...Done.\nHost mail2.abc.co.id\n    Starting ldap...Done.\n    Starting zmconfigd...Done.\n    Starting logger...Done.\n    Starting mailbox...Done.\n    Starting proxy...Done.\n    Starting antispam...Done.\n    Starting antivirus...Done.\n    Starting opendkim...Done.\n    Starting snmp...Done.\n    Starting mta...Done.\n    Starting stats...Done.\nzimbra@mail2:~$  Setting SSL Config  zimbra@mail2:~$ zmprov mcf zimbraReverseProxySSLCiphers 'EECDH:EDH:SHA256:SHA384:!RC4:HIGH:!aNULL:!MD5:!kEDH:!AD:!SSLv2:!NULL:!3DES'  edit file-file berikut yang ada di /opt/zimbra/conf/nginx/templates/ . pastikan dibackup terlebih dahulu.  nginx.conf.mail.imaps.default.template\nnginx.conf.mail.imaps.template\nnginx.conf.mail.imap.default.template (for starttls)\nnginx.conf.mail.imap.template (for starttls)\nnginx.conf.mail.pop3s.default.template\nnginx.conf.mail.pop3s.template\nnginx.conf.mail.pop3.default.template (for starttls)\nnginx.conf.mail.pop3.template (for starttls)\nnginx.conf.mail.template\nnginx.conf.web.admin.default.template\nnginx.conf.web.admin.template\nnginx.conf.web.https.default.template\nnginx.conf.web.https.template\nnginx.conf.web.sso.default.template\nnginx.conf.web.sso.template  tambahkan setiap blok ssl dari setiap file diatas dengan opsi dibawah ini:  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;  misal awal blok ssl seperti ini:   ssl                     on;\n ssl_prefer_server_ciphers ${web.ssl.preferserverciphers};\n ssl_ciphers             ${web.ssl.ciphers};\n ssl_certificate         ${ssl.crt.default};\n ssl_certificate_key     ${ssl.key.default};  akan menjadi seperti:   ssl                     on;\n ssl_prefer_server_ciphers ${web.ssl.preferserverciphers};\n ssl_ciphers             ${web.ssl.ciphers};\n ssl_certificate         ${ssl.crt.default};\n ssl_certificate_key     ${ssl.key.default};\n ssl_protocols TLSv1 TLSv1.1 TLSv1.2;  khusus untuk file  nginx.conf.web.https.default.template  dan  nginx.conf.web.https.template  tambahkan seperti dibawah ini:  ssl on; \nssl_prefer_server_ciphers ${web.ssl.preferserverciphers}; \n# Add extra items for A+ rating \nssl_protocols TLSv1 TLSv1.1 TLSv1.2; \nadd_header Strict-Transport-Security max-age=15768000; \nssl_ciphers ${web.ssl.ciphers};  lalu restart zmproxy:  zmproxyctl restart   Disable Weak SSL/TLS Cipher mailbox   jalankan command dibawah ini:  zimbra@mail2:~$ zmprov mcf +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_256_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites DHE-RSA-AES256-SHA  \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites DHE-RSA-AES256-SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_256_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_WITH_DES_CBC_SHA  \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_RSA_WITH_DES_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_DSS_WITH_DES_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_EXPORT_WITH_RC4_40_MD5 \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_DSS_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_128_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_128_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_EXPORT_WITH_DES40_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_DES_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_128_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \\\n +zimbraSSLExcludeCipherSuites TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA \\\n +zimbraSSLExcludeCipherSuites TLS_RSA_WITH_AES_256_CBC_SHA256 \nzimbra@mail2:~$ zmproxyctl restart\nStopping nginx...done.\nStarting nginx...done.\nYou have new mail in /var/mail/zimbra\nzimbra@mail2:~$  lalu restart mailbox:  zimbra@mail2:~$ zmmailboxdctl restart\nStopping mailboxd...done.\nStarting mailboxd...done.\nzimbra@mail2:~$   Patching OpenSSL   pindah directory ke  /tmp/  lalu download file  \"http://files.zimbra.com/downloads/security/zmopenssl-updater.sh\"  root@mail2:/opt/zimbra/conf/nginx/templates# cd /tmp/\nroot@mail2:/tmp# wget -c \"http://files.zimbra.com/downloads/security/zmopenssl-updater.sh\"\n--2015-04-07 12:58:22--  http://files.zimbra.com/downloads/security/zmopenssl-updater.sh\nResolving files.zimbra.com (files.zimbra.com)... 54.230.159.200\nConnecting to files.zimbra.com (files.zimbra.com)|54.230.159.200|:80... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://files.zimbra.com/downloads/security/zmopenssl-updater.sh [following]\n--2015-04-07 12:58:26--  https://files.zimbra.com/downloads/security/zmopenssl-updater.sh\nConnecting to files.zimbra.com (files.zimbra.com)|54.230.159.200|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2788 (2.7K) [application/x-unknown-content-type]\nSaving to: `zmopenssl-updater.sh'\n100%[============================================================================================================================== ] 2,788       --.-K/s   in 0s      \n2015-04-07 12:58:31 (697 MB/s) - `zmopenssl-updater.sh' saved [2788/2788]\n\nberi permission lalu eksekusi:\nroot@mail2:/tmp# chmod a+rx zmopenssl-updater.sh\nroot@mail2:/tmp# ./zmopenssl-updater.sh \nDownloading patched openssl\nValidating patched openssl: success\nBacking up old openssl: complete\nInstalling patched openssl: complete\nOpenSSL patch process complete.\nPlease restart Zimbra Collaboration Suite as the Zimbra user via zmcontrol restart\nroot@mail2:/tmp#  restart zimbra dengan zmcontrol lalu check versi openssl:  zimbra@mail2:~$ zmcontrol restart\nHost mail2.abc.co.id\n    Stopping vmware-ha...Done.\n    Stopping zmconfigd...Done.\n    Stopping stats...Done.\n    Stopping mta...Done.\n    Stopping spell...Done.\n    Stopping snmp...Done.\n    Stopping cbpolicyd...Done.\n    Stopping archiving...Done.\n    Stopping opendkim...Done.\n    Stopping antivirus...Done.\n    Stopping antispam...Done.\n    Stopping proxy...Done.\n    Stopping memcached...Done.\n    Stopping mailbox...Done.\n    Stopping logger...Done.\n    Stopping ldap...Done.\nHost mail2.abc.co.id\n    Starting ldap...Done.\n    Starting zmconfigd...Done.\n    Starting logger...Done.\n    Starting mailbox...Done.\n    Starting proxy...Done.\n    Starting antispam...Done.\n    Starting antivirus...Done.\n    Starting opendkim...Done.\n    Starting snmp...Done.\n    Starting mta...Done.\n    Starting stats...Done.\nzimbra@mail2:~$ openssl version\nOpenSSL 1.0.1h 5 Jun 2014\nYou have new mail in /var/mail/zimbra\nzimbra@mail2:~$  Testing \nuntuk testing:  root@mail2:/opt/zimbra/conf/nginx/templates# openssl s_time -connect localhost:443 -new -cipher AES256-SHA\nCollecting connection statistics for 30 seconds\nERROR\n140543357974176:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1247:SSL alert number 40\nroot@mail2:/opt/zimbra/conf/nginx/templates#  dengan for loop  zimbra@mail2:~$ for p in 993 995 443 ; do echo Port $p ; timeout 3 openssl s_client -connect `zmhostname`:$p -ssl3 |grep failure ; done\nPort 993\n140567794857632:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1275:SSL alert number 40\n140567794857632:error:1409E0E5:SSL routines:SSL3_WRITE_BYTES:ssl handshake failure:s3_pkt.c:598:\nPort 995\n140486668211872:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1275:SSL alert number 40\n140486668211872:error:1409E0E5:SSL routines:SSL3_WRITE_BYTES:ssl handshake failure:s3_pkt.c:598:\nPort 443\n140321034884768:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:s3_pkt.c:1275:SSL alert number 40\n140321034884768:error:1409E0E5:SSL routines:SSL3_WRITE_BYTES:ssl handshake failure:s3_pkt.c:598:\nYou have new mail in /var/mail/zimbra  atau bisa via ssl labs   selesai  ref:\n 1. http://blog.capitar.com/getting-a-better-zimbra-ssl-labs-rating/\n 2. https://wiki.zimbra.com/wiki/How_to_disable_SSLv3\n 3. http://wiki.zimbra.com/wiki/ShanxT-Removing-Insecure-SSL-Ciphers\n 4. http://forums.zimbra.com/announcements/73677-20140606-zimbra-security-advisory-cve-2014-0224-ccs-injection-vulnerability.html", 
            "title": "Mengamankan zimbra 8.0.4 di mail2.abc.co.id dari serangan CCS Injection Vulnerability dan Poddle Attack"
        }, 
        {
            "location": "/zimbra-mailbox-usages-report/", 
            "text": "Zimbra Mailbox Usages Report\n\n\nLogin sebagai user zimbra terus pindah directory ke \n/opt/zimbra/backup/scripts\n\n\n# su - zimbra\n$ cd /opt/zimbra/backup/scripts\n\n\n\ncreate file gqu.sh\n\n\n$ vim gqu.sh\n\n#!/bin/bash\noutput=\"/tmp/accountusage.txt\"\ndomain=\"abc.co.id\"\nSendTo=\"it@abc.co.id\"\n#SendTo=\"dgprasetya@abc.co.id\"\n\nrm -f $output\ntouch $output\n\nserver=`hostname`\n/opt/zimbra/bin/zmprov gqu $server|grep $domain|awk {'print $1\" \"$3\" \"$2'}|sort|while read line\ndo\nusage=`echo $line|cut -f2 -d \" \"`\nquota=`echo $line|cut -f3 -d \" \"`\nuser=`echo $line|cut -f1 -d \" \"`\n\nusageMB=`expr $usage / 1024 / 1024`\nquotaMB=`expr $quota / 1024 / 1024`\n\npercentUsage=`echo \"scale=2; $usageMB / $quotaMB * 100\" | bc | awk -F \\. '{print $1}'`\n\nstatus=`/opt/zimbra/bin/zmprov ga $user | grep  ^zimbraAccountStatus | cut -f2 -d \" \"`\n#echo -e \"$user\\t\\t\\t`expr $usage / 1024 / 1024`Mb\\t\\t\\t`expr $quota / 1024 / 1024`Mb\\t\\t($status account)\" \n $output\n\n\n#if [ $(echo \"$percentUsage \n 90\" | bc -l ) -eq 1 ]; then\n    echo -e \"$user\\t\\t\\t${usageMB}Mb\\t\\t\\t${quotaMB}Mb\\t\\t($status account)\\t\\t${percentUsage}%\" \n $output\n    #echo \"yes\"\n#else\n#    echo \"no\" \n#fi\n\ndone\n\n#cat $output | mail @SendTo -s\"Mailbox Usages for $domain\"\n#echo | mutt -s \"Zimbra Mailbox Usages for $domain\" $SendTo -a $output  \n $output\n\n##sort tampilan berdasarkan persentase\n##http://stackoverflow.com/questions/1037365/unix-sort-with-tab-delimiter\nsortfile=\"/tmp/sortfilegqu.txt\"\ncat $output | sort -t$'\\t' -k11 -n -r \n $sortfile\n\n##merapikan tampilan\n## http://www.unix.com/showthread.php?t=117543\nawkfile=\"/tmp/awkfilegqu.txt\"\nawk '{ x = $2\"\\t\"$3\"\\t\"$4\"\\t\"$5\"\\t\"$6; printf \"%-40s %-10s\\n\", $1, x}' $sortfile \n $awkfile\n\n##kalo file report kosong, email tidak akan dikirim\nif [ $(wc -l $awkfile | awk '{print $1}') -eq 0 ]; then\necho \"not send\";\nelse\n\n##kirim email\n#(echo \"Subject: Zimbra Mailbox Usages for $domain\";cat $awkfile ) | /opt/zimbra/postfix/sbin/sendmail $SendTo\n(echo \"Subject: Zimbra Mailbox Usages for $domain\";echo \"Content-Type: text/html\";echo \"MIME-Version: 1.0\";echo \"\npre\n`cat $awkfile`\n/pre\n\" ) | /opt/zimbra/postfix/sbin/sendmail $SendTo\n\nfi\n\n\n\nset crontab:\n\n\n20 3 * * * bash -x /opt/zimbra/backup/scripts/gqu.sh 2\n1 | tee /opt/zimbra/backup/scripts/logs/zimbra-gqu-`date +\\%F`.txt\n\n\n\nRef: \nwiki zimbra dengan perubahan", 
            "title": "Zimbra - Mailbox Usages Report"
        }, 
        {
            "location": "/zimbra-mailbox-usages-report/#zimbra-mailbox-usages-report", 
            "text": "Login sebagai user zimbra terus pindah directory ke  /opt/zimbra/backup/scripts  # su - zimbra\n$ cd /opt/zimbra/backup/scripts  create file gqu.sh  $ vim gqu.sh\n\n#!/bin/bash\noutput=\"/tmp/accountusage.txt\"\ndomain=\"abc.co.id\"\nSendTo=\"it@abc.co.id\"\n#SendTo=\"dgprasetya@abc.co.id\"\n\nrm -f $output\ntouch $output\n\nserver=`hostname`\n/opt/zimbra/bin/zmprov gqu $server|grep $domain|awk {'print $1\" \"$3\" \"$2'}|sort|while read line\ndo\nusage=`echo $line|cut -f2 -d \" \"`\nquota=`echo $line|cut -f3 -d \" \"`\nuser=`echo $line|cut -f1 -d \" \"`\n\nusageMB=`expr $usage / 1024 / 1024`\nquotaMB=`expr $quota / 1024 / 1024`\n\npercentUsage=`echo \"scale=2; $usageMB / $quotaMB * 100\" | bc | awk -F \\. '{print $1}'`\n\nstatus=`/opt/zimbra/bin/zmprov ga $user | grep  ^zimbraAccountStatus | cut -f2 -d \" \"`\n#echo -e \"$user\\t\\t\\t`expr $usage / 1024 / 1024`Mb\\t\\t\\t`expr $quota / 1024 / 1024`Mb\\t\\t($status account)\"   $output\n\n\n#if [ $(echo \"$percentUsage   90\" | bc -l ) -eq 1 ]; then\n    echo -e \"$user\\t\\t\\t${usageMB}Mb\\t\\t\\t${quotaMB}Mb\\t\\t($status account)\\t\\t${percentUsage}%\"   $output\n    #echo \"yes\"\n#else\n#    echo \"no\" \n#fi\n\ndone\n\n#cat $output | mail @SendTo -s\"Mailbox Usages for $domain\"\n#echo | mutt -s \"Zimbra Mailbox Usages for $domain\" $SendTo -a $output    $output\n\n##sort tampilan berdasarkan persentase\n##http://stackoverflow.com/questions/1037365/unix-sort-with-tab-delimiter\nsortfile=\"/tmp/sortfilegqu.txt\"\ncat $output | sort -t$'\\t' -k11 -n -r   $sortfile\n\n##merapikan tampilan\n## http://www.unix.com/showthread.php?t=117543\nawkfile=\"/tmp/awkfilegqu.txt\"\nawk '{ x = $2\"\\t\"$3\"\\t\"$4\"\\t\"$5\"\\t\"$6; printf \"%-40s %-10s\\n\", $1, x}' $sortfile   $awkfile\n\n##kalo file report kosong, email tidak akan dikirim\nif [ $(wc -l $awkfile | awk '{print $1}') -eq 0 ]; then\necho \"not send\";\nelse\n\n##kirim email\n#(echo \"Subject: Zimbra Mailbox Usages for $domain\";cat $awkfile ) | /opt/zimbra/postfix/sbin/sendmail $SendTo\n(echo \"Subject: Zimbra Mailbox Usages for $domain\";echo \"Content-Type: text/html\";echo \"MIME-Version: 1.0\";echo \" pre `cat $awkfile` /pre \" ) | /opt/zimbra/postfix/sbin/sendmail $SendTo\n\nfi  set crontab:  20 3 * * * bash -x /opt/zimbra/backup/scripts/gqu.sh 2 1 | tee /opt/zimbra/backup/scripts/logs/zimbra-gqu-`date +\\%F`.txt  Ref:  wiki zimbra dengan perubahan", 
            "title": "Zimbra Mailbox Usages Report"
        }, 
        {
            "location": "/zimbra-trusted-domain-zimbra/", 
            "text": "Menambahkan Trusted Domain di Zimbra\n\n\nada kalanya domain domain.co.id atau gmail.com masuk junk atau dianggap spam.\nnah untuk mengantisipasi agar tidak dianggap spam adalah memasukkan daftar domain ke dalam antispam rule didalam file \n/opt/zimbra/conf/salocal.cf.in\n. Jangan lupa backup terlebuh dahulu sebelum merubah file konfig, dan tambahkan white list berikut:\n\n\n#trusted domain.co.id\ndef_whitelist_from_rcvd *@domain.co.id domain.co.id\ndef_whitelist_from_rcvd *@gmail.com gmail.com\n\n\n\nconfig akhir \nsalocal.cf.in\n\n\n# This is the right place to customize your installation of SpamAssassin.\n#\n# See 'perldoc Mail::SpamAssassin::Conf' for details of what can be\n# tweaked.\n#\n###########################################################################\n#\n# rewrite_header Subject *****SPAM*****\n# report_safe 1\n# trusted_networks 212.17.35.\n# lock_method flock\n\nheader DSPAM_SPAM X-DSPAM-Result =~ /^Spam$/\ndescribe DSPAM_SPAM DSPAM claims it is spam\nscore DSPAM_SPAM 1.5\n\nheader DSPAM_HAM X-DSPAM-Result =~ /^Innocent$/\ndescribe DSPAM_HAM DSPAM claims it is ham\nscore DSPAM_HAM -0.5\n\n%%uncomment VAR:zimbraMtaMyNetworks%%trusted_networks %%zimbraMtaMyNetworks%%\n%%uncomment VAR:zimbraMtaAntiSpamLockMethod%%lock_method %%zimbraMtaAntiSpamLockMethod%%\n\n# accept email from zimbra support and forumns\ndef_whitelist_from_rcvd noreply@zimbra.com zimbra.com\ndef_whitelist_from_rcvd support@zimbra.com zimbra.com\n\n#trusted domain.co.id\ndef_whitelist_from_rcvd *@domain.co.id domain.co.id\ndef_whitelist_from_rcvd *@gmail.com gmail.com\n\nrewrite_header Subject *SPAM* _STARS(*)_\nbayes_auto_learn 1\nbayes_min_spam_num 60\nbayes_min_ham_num 60\n\n\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_store_module              Mail::SpamAssassin::BayesStore::MySQL\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_sql_dsn                   DBI:mysql:zimbra_antispam:host=@@antispam_mysql_host@@:port=@@antispam_mysql_port@@\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_sql_username              @@antispam_mysql_user@@\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_sql_password              @@antispam_mysql_password@@\n\nclear_headers\nadd_header spam Flag _YESNOCAPS_\nadd_header all Status _YESNO_, score=_SCORE_ required=_REQD_ tests=_TESTS_ autolearn=_AUTOLEARN_ version=_VERSION_\nadd_header all Level _STARS(*)_\nadd_header all Checker-Version SpamAssassin _VERSION_ (_SUBVERSION_) on _HOSTNAME_\n\n\n\nlalu restart :\n\n\n# zmmtactl restart\n# zmamavisdctl restart\n\n\n\njika sudah, saatnya sekarang mencoba apakah antispam nya sudah berjalan atau belum. maka kita harus mengirim dengan cara spamming`\n\n\ncaranya, telnet ke mail server lain:\n\n\n[user@host ~]$ telnet localhost 25\n\n\n\nlalu akan muncul reply:\n\n\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\n220 htserv1.unixtel.co ESMTP Sendmail 8.14.4/8.14.4; Thu, 27 Feb 2014 10:09:51 +0700\n\n\n\nketik:\n\n\nhelo local.domain.com\n\n\n\nlalu akan muncul reply:\n\n\n250 htserv1.unixtel.co Hello localhost.localdomain [127.0.0.1], pleased to meet you\n\n\n\nketik command berikut untuk email pengirim:\n\n\nmail from: CIA@gmail.com\n\n\n\nlalu akan muncul reply:\n\n\n250 2.1.0 CIA@gmail.com... Sender ok\n\n\n\nketik command berikut untuk email tujuan:\n\n\nrcpt to: dian.prasetya@domain.co.id\n\n\n\nlalu akan muncul reply:\n\n\n250 2.1.5 dian.prasetya@domain.co.id... Recipient ok\n\n\n\nuntuk mengirim \nsubject\n dan \nisi\n email ketik DATA\n\n\nDATA\n\n\n\nlalu akan muncul reply:\n\n\n354 Enter mail, end with \".\" on a line by itself\n\n\n\nketik \nSubject: blablabla\n untuk mengirim subject lalu enter dan akhiri tanda . (titik) untuk mengakhiri isi / body email... lalu terakhir tekan enter\n\n\nSubject: test aja\nyou are under arrest.\n.\n\n\n\nlalu akan muncul reply:\n    250 2.0.0 s1R39pgF018074 Message accepted for delivery\n\n\nketik quit untuk keluar dari telnet..\n\n\nlalu cek inbox email corporate dan bisa kita lihat di \nheader email\n bahwa email \ngmail.com\n tidak dianggap spam (lihat bagian cetak tebal) padahal kita sudah melakukan spamming (big grin)(smile)\n\n\nReturn-Path: CIA@gmail.com\nReceived: from mail2.domain.co.id (LHLO mail2.domain.co.id) (192.168.2.2) by\n mail2.domain.co.id with LMTP; Thu, 27 Feb 2014 10:11:19 +0700 (WIT)\nReceived: from localhost (localhost [127.0.0.1])\n    by mail2.domain.co.id (Postfix) with ESMTP id A5D244788D4\n    for \ndian.prasetya@domain.co.id\n; Thu, 27 Feb 2014 10:11:19 +0700 (WIT)\nX-Virus-Scanned: amavisd-new at mail2.domain.co.id\nX-Spam-Flag: NO\nX-Spam-Score: 3.516\nX-Spam-Level: ***\nX-Spam-Status: No, score=3.516 tagged_above=-10 required=6.6\n    tests=[BAYES_50=0.8, DKIM_ADSP_CUSTOM_MED=0.001, FREEMAIL_FROM=0.001,\n    MISSING_HEADERS=1.021, NML_ADSP_CUSTOM_MED=0.9, RDNS_NONE=0.793]\n    autolearn=no\nReceived: from mail2.domain.co.id ([127.0.0.1])\n    by localhost (mail2.domain.co.id [127.0.0.1]) (amavisd-new, port 10024)\n    with ESMTP id aVRG7-NA-brs for \ndian.prasetya@domain.co.id\n;\n    Thu, 27 Feb 2014 10:11:08 +0700 (WIT)\nReceived: from htserv1.unixtel.me (unknown [192.73.235.136])\n    by mail2.domain.co.id (Postfix) with ESMTPS id 2A1A84788C0\n    for \ndian.prasetya@domain.co.id\n; Thu, 27 Feb 2014 10:11:00 +0700 (WIT)\nReceived: from local.domain.com (localhost.localdomain [127.0.0.1])\n    by htserv1.unixtel.me (8.14.4/8.14.4) with SMTP id s1R39pgF018074\n    for dian.prasetya@domain.co.id; Thu, 27 Feb 2014 10:11:08 +0700\nDate: Thu, 27 Feb 2014 10:09:51 +0700\nFrom: CIA@gmail.com\nMessage-Id: \n201402270311.s1R39pgF018074@htserv1.unixtel.me\n\nSubject: test aja\n\nyou are under arrest.\n\n\n\nref: \nzimbra wiki", 
            "title": "Zimbra - Menambahkan Trusted Domain"
        }, 
        {
            "location": "/zimbra-trusted-domain-zimbra/#menambahkan-trusted-domain-di-zimbra", 
            "text": "ada kalanya domain domain.co.id atau gmail.com masuk junk atau dianggap spam.\nnah untuk mengantisipasi agar tidak dianggap spam adalah memasukkan daftar domain ke dalam antispam rule didalam file  /opt/zimbra/conf/salocal.cf.in . Jangan lupa backup terlebuh dahulu sebelum merubah file konfig, dan tambahkan white list berikut:  #trusted domain.co.id\ndef_whitelist_from_rcvd *@domain.co.id domain.co.id\ndef_whitelist_from_rcvd *@gmail.com gmail.com  config akhir  salocal.cf.in  # This is the right place to customize your installation of SpamAssassin.\n#\n# See 'perldoc Mail::SpamAssassin::Conf' for details of what can be\n# tweaked.\n#\n###########################################################################\n#\n# rewrite_header Subject *****SPAM*****\n# report_safe 1\n# trusted_networks 212.17.35.\n# lock_method flock\n\nheader DSPAM_SPAM X-DSPAM-Result =~ /^Spam$/\ndescribe DSPAM_SPAM DSPAM claims it is spam\nscore DSPAM_SPAM 1.5\n\nheader DSPAM_HAM X-DSPAM-Result =~ /^Innocent$/\ndescribe DSPAM_HAM DSPAM claims it is ham\nscore DSPAM_HAM -0.5\n\n%%uncomment VAR:zimbraMtaMyNetworks%%trusted_networks %%zimbraMtaMyNetworks%%\n%%uncomment VAR:zimbraMtaAntiSpamLockMethod%%lock_method %%zimbraMtaAntiSpamLockMethod%%\n\n# accept email from zimbra support and forumns\ndef_whitelist_from_rcvd noreply@zimbra.com zimbra.com\ndef_whitelist_from_rcvd support@zimbra.com zimbra.com\n\n#trusted domain.co.id\ndef_whitelist_from_rcvd *@domain.co.id domain.co.id\ndef_whitelist_from_rcvd *@gmail.com gmail.com\n\nrewrite_header Subject *SPAM* _STARS(*)_\nbayes_auto_learn 1\nbayes_min_spam_num 60\nbayes_min_ham_num 60\n\n\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_store_module              Mail::SpamAssassin::BayesStore::MySQL\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_sql_dsn                   DBI:mysql:zimbra_antispam:host=@@antispam_mysql_host@@:port=@@antispam_mysql_port@@\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_sql_username              @@antispam_mysql_user@@\n%%uncomment LOCAL:antispam_mysql_enabled%%bayes_sql_password              @@antispam_mysql_password@@\n\nclear_headers\nadd_header spam Flag _YESNOCAPS_\nadd_header all Status _YESNO_, score=_SCORE_ required=_REQD_ tests=_TESTS_ autolearn=_AUTOLEARN_ version=_VERSION_\nadd_header all Level _STARS(*)_\nadd_header all Checker-Version SpamAssassin _VERSION_ (_SUBVERSION_) on _HOSTNAME_  lalu restart :  # zmmtactl restart\n# zmamavisdctl restart  jika sudah, saatnya sekarang mencoba apakah antispam nya sudah berjalan atau belum. maka kita harus mengirim dengan cara spamming`  caranya, telnet ke mail server lain:  [user@host ~]$ telnet localhost 25  lalu akan muncul reply:  Trying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\n220 htserv1.unixtel.co ESMTP Sendmail 8.14.4/8.14.4; Thu, 27 Feb 2014 10:09:51 +0700  ketik:  helo local.domain.com  lalu akan muncul reply:  250 htserv1.unixtel.co Hello localhost.localdomain [127.0.0.1], pleased to meet you  ketik command berikut untuk email pengirim:  mail from: CIA@gmail.com  lalu akan muncul reply:  250 2.1.0 CIA@gmail.com... Sender ok  ketik command berikut untuk email tujuan:  rcpt to: dian.prasetya@domain.co.id  lalu akan muncul reply:  250 2.1.5 dian.prasetya@domain.co.id... Recipient ok  untuk mengirim  subject  dan  isi  email ketik DATA  DATA  lalu akan muncul reply:  354 Enter mail, end with \".\" on a line by itself  ketik  Subject: blablabla  untuk mengirim subject lalu enter dan akhiri tanda . (titik) untuk mengakhiri isi / body email... lalu terakhir tekan enter  Subject: test aja\nyou are under arrest.\n.  lalu akan muncul reply:\n    250 2.0.0 s1R39pgF018074 Message accepted for delivery  ketik quit untuk keluar dari telnet..  lalu cek inbox email corporate dan bisa kita lihat di  header email  bahwa email  gmail.com  tidak dianggap spam (lihat bagian cetak tebal) padahal kita sudah melakukan spamming (big grin)(smile)  Return-Path: CIA@gmail.com\nReceived: from mail2.domain.co.id (LHLO mail2.domain.co.id) (192.168.2.2) by\n mail2.domain.co.id with LMTP; Thu, 27 Feb 2014 10:11:19 +0700 (WIT)\nReceived: from localhost (localhost [127.0.0.1])\n    by mail2.domain.co.id (Postfix) with ESMTP id A5D244788D4\n    for  dian.prasetya@domain.co.id ; Thu, 27 Feb 2014 10:11:19 +0700 (WIT)\nX-Virus-Scanned: amavisd-new at mail2.domain.co.id\nX-Spam-Flag: NO\nX-Spam-Score: 3.516\nX-Spam-Level: ***\nX-Spam-Status: No, score=3.516 tagged_above=-10 required=6.6\n    tests=[BAYES_50=0.8, DKIM_ADSP_CUSTOM_MED=0.001, FREEMAIL_FROM=0.001,\n    MISSING_HEADERS=1.021, NML_ADSP_CUSTOM_MED=0.9, RDNS_NONE=0.793]\n    autolearn=no\nReceived: from mail2.domain.co.id ([127.0.0.1])\n    by localhost (mail2.domain.co.id [127.0.0.1]) (amavisd-new, port 10024)\n    with ESMTP id aVRG7-NA-brs for  dian.prasetya@domain.co.id ;\n    Thu, 27 Feb 2014 10:11:08 +0700 (WIT)\nReceived: from htserv1.unixtel.me (unknown [192.73.235.136])\n    by mail2.domain.co.id (Postfix) with ESMTPS id 2A1A84788C0\n    for  dian.prasetya@domain.co.id ; Thu, 27 Feb 2014 10:11:00 +0700 (WIT)\nReceived: from local.domain.com (localhost.localdomain [127.0.0.1])\n    by htserv1.unixtel.me (8.14.4/8.14.4) with SMTP id s1R39pgF018074\n    for dian.prasetya@domain.co.id; Thu, 27 Feb 2014 10:11:08 +0700\nDate: Thu, 27 Feb 2014 10:09:51 +0700\nFrom: CIA@gmail.com\nMessage-Id:  201402270311.s1R39pgF018074@htserv1.unixtel.me \nSubject: test aja\n\nyou are under arrest.  ref:  zimbra wiki", 
            "title": "Menambahkan Trusted Domain di Zimbra"
        }, 
        {
            "location": "/zimbra-unusual-login-activity/", 
            "text": "zimbra - unusual login activity\n\n\nUnusual login activity alert ke it-infra@abc.co.id, ketika ada user yang mengakses zimbra dengan IP Public dari luar Indonesia baik lewat imap, pop3, maupun web based.\n\n\ncreate monitorip.sh\n\n\n#!/bin/bash\ntanggal=`date +%F`\ndatenow=`date +%F_%H%M`\nauditlog=\"/opt/zimbra/log/audit.log\"\nDir=\"/opt/zimbra/backup/scripts/MonIP\"\nDirLog=\"$Dir/logs\"\n[ -d $DirLog/$tanggal ] \n echo \"found, next\" || mkdir -p $DirLog/$tanggal\nDirLog=\"$DirLog/$tanggal\"\nfiledatenow=\"$DirLog/audit-$datenow.log\"\n#datenow=\"2015-10-22_1058\"\ncp -a $auditlog $filedatenow\n\ndateLLAgo=`date --date=\"-60 minutes\" +%F_%H%M`\n#dateLimolasAgo=\"2015-10-22_1057\"\nfileLLAgo=\"$DirLog/audit-$dateLLAgo.log\"\nrawIPnow=\"$DirLog/raw-$datenow.raw\"\nIPnow=\"$DirLog/IPnow-$datenow.txt\"\nfilemail=\"$DirLog/sendmail.$datenow.txt\"\nif [ -f \"$fileLLAgo\" ];then\ndiff $fileLLAgo $filedatenow \n $rawIPnow;\ntail -n +2 $rawIPnow \n $IPnow; \necho \"WARNING: Unusual login activity detected\" \n $filemail\necho \"-----------------------------------------\" \n $filemail\n        cat $IPnow | while read line;\n        do\n#               echo $line;\n        #ip=`tail -f $testlog -n 1`\n        ip=`echo $line | sed 's/.\\+oip\\=//' | cut -d \\; -f 1`\n        emailaddress=`echo $line | grep -EiEio '\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\\b'`\n        echo $ip | grep \"\\@\" \n /dev/null\n        if [ \"$?\" == \"0\" ];then\n        #  echo \"tidak ada ip: $ip\"\n          continue;\n        else\n        cc=`/usr/bin/geoiplookup -f $Dir/GeoIP.dat $ip | cut -d \\, -f 2`\n        echo $cc | grep \"IP Address not found\\|hostname\" \n /dev/null\n                if [ \"$?\" == \"0\" ];then\n                      continue;\n                else\n                          cc=`echo $cc | sed 's/ //g'`\n                          if [ \"$cc\" != \"Indonesia\" ] \n                                then\n                #                       echo \"-----------------------------------------\" \n $filemail\n                                        echo \"\" \n $filemail\n                                        echo \"email account: $emailaddress\" \n $filemail\n                                        echo \"ip:            $ip\" \n $filemail\n                                        echo \"country:       $cc\" \n $filemail\n#                                       echo \"-----------------------------------------\" \n $filemail\n                                        echo \"$line \" \n $filemail\n                                        echo \"\" \n $filemail\n                                        echo \"\" \n $filemail\n                                        #echo \"-----------------------------------------\" \n $filemail\n                                #     \nsend email notification\n\n                          fi\n                fi\n        fi\n        done\n        #awk '{ x = $2\"\"$3\"\\t\"$4; printf \"%-10s %-10s\\n\", $1, x}' ${filemail} \n ${filemail}.raw\n        #mv ${filemail}.raw ${filemail}\n                                /usr/bin/sendemail -f it-infra@abc.co.id -u \"Warning: Zimbra Login Activity\" -t it-infra@abc.co.id -o message-content-type=text -o message-file=$filemail -xu user -xp pass -s 192.168.2.2:587 -o tls=no\nfi\n\n\n\ntambahkan ke crontab, jalankan setiap satu jam.\n\n\n0 * * * * /bin/bash -x /opt/zimbra/backup/scripts/MonIP/monitorip.sh 2\n1 | tee /opt/zimbra/backup/scripts/MonIP/logs/debug-cron`date +\\%F_\\%H\\%M`.txt\n\n\n\nresults:", 
            "title": "Zimbra - Unusual Login Activity"
        }, 
        {
            "location": "/zimbra-unusual-login-activity/#zimbra-unusual-login-activity", 
            "text": "Unusual login activity alert ke it-infra@abc.co.id, ketika ada user yang mengakses zimbra dengan IP Public dari luar Indonesia baik lewat imap, pop3, maupun web based.", 
            "title": "zimbra - unusual login activity"
        }, 
        {
            "location": "/zimbra-unusual-login-activity/#create-monitoripsh", 
            "text": "#!/bin/bash\ntanggal=`date +%F`\ndatenow=`date +%F_%H%M`\nauditlog=\"/opt/zimbra/log/audit.log\"\nDir=\"/opt/zimbra/backup/scripts/MonIP\"\nDirLog=\"$Dir/logs\"\n[ -d $DirLog/$tanggal ]   echo \"found, next\" || mkdir -p $DirLog/$tanggal\nDirLog=\"$DirLog/$tanggal\"\nfiledatenow=\"$DirLog/audit-$datenow.log\"\n#datenow=\"2015-10-22_1058\"\ncp -a $auditlog $filedatenow\n\ndateLLAgo=`date --date=\"-60 minutes\" +%F_%H%M`\n#dateLimolasAgo=\"2015-10-22_1057\"\nfileLLAgo=\"$DirLog/audit-$dateLLAgo.log\"\nrawIPnow=\"$DirLog/raw-$datenow.raw\"\nIPnow=\"$DirLog/IPnow-$datenow.txt\"\nfilemail=\"$DirLog/sendmail.$datenow.txt\"\nif [ -f \"$fileLLAgo\" ];then\ndiff $fileLLAgo $filedatenow   $rawIPnow;\ntail -n +2 $rawIPnow   $IPnow; \necho \"WARNING: Unusual login activity detected\"   $filemail\necho \"-----------------------------------------\"   $filemail\n        cat $IPnow | while read line;\n        do\n#               echo $line;\n        #ip=`tail -f $testlog -n 1`\n        ip=`echo $line | sed 's/.\\+oip\\=//' | cut -d \\; -f 1`\n        emailaddress=`echo $line | grep -EiEio '\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\\b'`\n        echo $ip | grep \"\\@\"   /dev/null\n        if [ \"$?\" == \"0\" ];then\n        #  echo \"tidak ada ip: $ip\"\n          continue;\n        else\n        cc=`/usr/bin/geoiplookup -f $Dir/GeoIP.dat $ip | cut -d \\, -f 2`\n        echo $cc | grep \"IP Address not found\\|hostname\"   /dev/null\n                if [ \"$?\" == \"0\" ];then\n                      continue;\n                else\n                          cc=`echo $cc | sed 's/ //g'`\n                          if [ \"$cc\" != \"Indonesia\" ] \n                                then\n                #                       echo \"-----------------------------------------\"   $filemail\n                                        echo \"\"   $filemail\n                                        echo \"email account: $emailaddress\"   $filemail\n                                        echo \"ip:            $ip\"   $filemail\n                                        echo \"country:       $cc\"   $filemail\n#                                       echo \"-----------------------------------------\"   $filemail\n                                        echo \"$line \"   $filemail\n                                        echo \"\"   $filemail\n                                        echo \"\"   $filemail\n                                        #echo \"-----------------------------------------\"   $filemail\n                                #      send email notification \n                          fi\n                fi\n        fi\n        done\n        #awk '{ x = $2\"\"$3\"\\t\"$4; printf \"%-10s %-10s\\n\", $1, x}' ${filemail}   ${filemail}.raw\n        #mv ${filemail}.raw ${filemail}\n                                /usr/bin/sendemail -f it-infra@abc.co.id -u \"Warning: Zimbra Login Activity\" -t it-infra@abc.co.id -o message-content-type=text -o message-file=$filemail -xu user -xp pass -s 192.168.2.2:587 -o tls=no\nfi  tambahkan ke crontab, jalankan setiap satu jam.  0 * * * * /bin/bash -x /opt/zimbra/backup/scripts/MonIP/monitorip.sh 2 1 | tee /opt/zimbra/backup/scripts/MonIP/logs/debug-cron`date +\\%F_\\%H\\%M`.txt  results:", 
            "title": "create monitorip.sh"
        }, 
        {
            "location": "/zimbra-milter-reject/", 
            "text": "Zimbra - message milter-reject: END-OF-MESSAGE\n\n\nGot resolved wiht the following. Check the value of \nmilter_default_action\n\n\n    su - zimbra\n    postconf milter_default_action\n\n\n\nIf it returns as -- \nmilter_default_action = tempfail\n\n\nRun the following commands (as the zimbra user) to change the value:-\n\n\n    postconf -e milter_default_action=accept\n    zmconfigdctl restart\n    zmmilterctl restart\n    zmmtactl restart", 
            "title": "Zimbra - message milter-reject: END-OF-MESSAGE"
        }, 
        {
            "location": "/zimbra-milter-reject/#zimbra-message-milter-reject-end-of-message", 
            "text": "Got resolved wiht the following. Check the value of  milter_default_action      su - zimbra\n    postconf milter_default_action  If it returns as --  milter_default_action = tempfail  Run the following commands (as the zimbra user) to change the value:-      postconf -e milter_default_action=accept\n    zmconfigdctl restart\n    zmmilterctl restart\n    zmmtactl restart", 
            "title": "Zimbra - message milter-reject: END-OF-MESSAGE"
        }, 
        {
            "location": "/zimbra-filter-sender-dl/", 
            "text": "Zimbra - filter sender distribution list\n\n\nPembatasan pengirim email ke distribution list bisa dilakukan dengan meng-enable-kan milter server melalui Zimbra admin interface pada Configure-\nGlobal Settings-\nMTA, sebagaimana bisa dilihat pada gambar berikut:\n\n\n\n\nsetelah itu start milter server:\n\n\nzmmilterctl start\n\n\nKemudian, setelah kita aktifkan Milter Server nya, langkah selanjut nya adalah grant akses kepada semua account domain terpilih untuk mengirim ke distribution list (detil bisa dilihat di sini).  Perintah pemberian grantt ini, saat ini hanya bisa dilakukan dari server terminal console. Dan bila kita hanya memberikan akses kepada domain, sebagai contoh, domain.co.id, maka kita bisa menjalankan zmprov dengan perintah grantRight / grr. Syntaxnya adalah:\n\n\n`zmprov grr dl \ndlname@example.com\n dom \nexample.com\n sendToDistList`\n\n\n\ncontoh:\n\n\n`zmprov grr dl wifi@domain.co.id dom domain.co.id sendToDistList`\n\n\n\nlalu reload milter nya:\n\n\n`zmmtactl reload`\n\n\n\nlalu test send email dari luar (gmail misal) ke distribution list \nwifi@domain.co.id\n misal . semestinya hasilnya \nundelivered mail\n.\n\n\nAda kalanya, kita mempunyai banyak distribution list dan akan menjalankan pembatasan itu, maka kita bisa membuat shell script sederhana yang berisi baris-baris sebagai berikut:\n\n\n#!/bin/bash\nfor dl in `zmprov gadl domain.co.id`; \n    do zmprov grr dl $dl dom domain.co.id sendToDistList; \ndone\n\n\n\nartinya setiap distribution list yang ada di domain.co.id hanya dapat dikirim oleh sender dari domain domain.co.id. setelah itu reload milter nya.\n\n\nReferensi:\n\n\n\n\nmas toyo\n\n\nzimbra docs\n\n\n\n\nIMPROVEMENT\n\n\nKetika Milter Zimbra diaktifkan, secara default distribution list akan mengijinkan semua sender untuk mengirim email ke distribution list tersebut dengan grant type pub\n\n\nMenambahkan hak akses sender user external domain ke semua distribtion list domain domain.co.id :\n\n\n#!/bin/bash\nfor ceo in \"a@gmail.com\" \"b@gmail.com\";\ndo \n        for dl in `zmprov gadl domain.co.id`; \n            do\n            zmprov grr dl $dl gst $ceo \"\" sendToDistList\n        done;\ndone\n\n\n\nUser a@gmail.com dan b@gmail.com diberikan hak akses untuk mengirim ke semua distribution list yang ada di domain domain.co.id . Lalu bagaimana jika hal tersebut diberlakukan untuk distribution list yang ada di semua domain di server zimbra ? . ikuti langkah 2. \n\n\nMenambahkan hak akses sender external user domain ke semua distribution list dari semua domain di mail server zimbra.\n\n\n#!/bin/bash\n    for ceo in \"a@gmail.com\" \"b@gmail.com\";do \n            for domain in `zmprov gad`;do\n                for dl in `zmprov gadl $domain`; do\n                    zmprov grr dl $dl gst $ceo \"\" sendToDistList\n                done;\n            done\n    done\n\n\n\nMemberikan hak akses sender semua internal user domain yang ada di mail zimbra ke semua distribution list dari semua domain di mail server zimbra\n\n\n#!/bin/bash\nfor domain in `zmprov gad`;\n    do\n            for dl in `zmprov gadl $domain`; \n                do\n            zmprov grr dl $dl all sendToDistList\n        done;\ndone", 
            "title": "Zimbra - filter sender distribution list"
        }, 
        {
            "location": "/zimbra-filter-sender-dl/#zimbra-filter-sender-distribution-list", 
            "text": "Pembatasan pengirim email ke distribution list bisa dilakukan dengan meng-enable-kan milter server melalui Zimbra admin interface pada Configure- Global Settings- MTA, sebagaimana bisa dilihat pada gambar berikut:   setelah itu start milter server:  zmmilterctl start  Kemudian, setelah kita aktifkan Milter Server nya, langkah selanjut nya adalah grant akses kepada semua account domain terpilih untuk mengirim ke distribution list (detil bisa dilihat di sini).  Perintah pemberian grantt ini, saat ini hanya bisa dilakukan dari server terminal console. Dan bila kita hanya memberikan akses kepada domain, sebagai contoh, domain.co.id, maka kita bisa menjalankan zmprov dengan perintah grantRight / grr. Syntaxnya adalah:  `zmprov grr dl  dlname@example.com  dom  example.com  sendToDistList`  contoh:  `zmprov grr dl wifi@domain.co.id dom domain.co.id sendToDistList`  lalu reload milter nya:  `zmmtactl reload`  lalu test send email dari luar (gmail misal) ke distribution list  wifi@domain.co.id  misal . semestinya hasilnya  undelivered mail .  Ada kalanya, kita mempunyai banyak distribution list dan akan menjalankan pembatasan itu, maka kita bisa membuat shell script sederhana yang berisi baris-baris sebagai berikut:  #!/bin/bash\nfor dl in `zmprov gadl domain.co.id`; \n    do zmprov grr dl $dl dom domain.co.id sendToDistList; \ndone  artinya setiap distribution list yang ada di domain.co.id hanya dapat dikirim oleh sender dari domain domain.co.id. setelah itu reload milter nya.  Referensi:   mas toyo  zimbra docs   IMPROVEMENT  Ketika Milter Zimbra diaktifkan, secara default distribution list akan mengijinkan semua sender untuk mengirim email ke distribution list tersebut dengan grant type pub  Menambahkan hak akses sender user external domain ke semua distribtion list domain domain.co.id :  #!/bin/bash\nfor ceo in \"a@gmail.com\" \"b@gmail.com\";\ndo \n        for dl in `zmprov gadl domain.co.id`; \n            do\n            zmprov grr dl $dl gst $ceo \"\" sendToDistList\n        done;\ndone  User a@gmail.com dan b@gmail.com diberikan hak akses untuk mengirim ke semua distribution list yang ada di domain domain.co.id . Lalu bagaimana jika hal tersebut diberlakukan untuk distribution list yang ada di semua domain di server zimbra ? . ikuti langkah 2.   Menambahkan hak akses sender external user domain ke semua distribution list dari semua domain di mail server zimbra.  #!/bin/bash\n    for ceo in \"a@gmail.com\" \"b@gmail.com\";do \n            for domain in `zmprov gad`;do\n                for dl in `zmprov gadl $domain`; do\n                    zmprov grr dl $dl gst $ceo \"\" sendToDistList\n                done;\n            done\n    done  Memberikan hak akses sender semua internal user domain yang ada di mail zimbra ke semua distribution list dari semua domain di mail server zimbra  #!/bin/bash\nfor domain in `zmprov gad`;\n    do\n            for dl in `zmprov gadl $domain`; \n                do\n            zmprov grr dl $dl all sendToDistList\n        done;\ndone", 
            "title": "Zimbra - filter sender distribution list"
        }, 
        {
            "location": "/zimbra-cara-reset-password-ldap-admin/", 
            "text": "Zimbra - Reset Password zimbra ldap admin\n\n\nUntuk mereset password zimbra ldap admin gunakan perintah berikut:\n\n\nzmldappasswd password_baru\n\n\n\n.. warning::\n\n\nOnly one of a, l, p, or r can be specified. If options are not included, the zimbra_ldap_password is changed.\n\n\n\nJika password lebih dari 16 karakter (misal 32), pastikan aplikasi ketiga (third party apps) tersebut dapat menerima 32 karakter password.\n\n\nref: \nzimbra docs", 
            "title": "Zimbra - Reset Password zimbra ldap admin"
        }, 
        {
            "location": "/zimbra-cara-reset-password-ldap-admin/#zimbra-reset-password-zimbra-ldap-admin", 
            "text": "Untuk mereset password zimbra ldap admin gunakan perintah berikut:  zmldappasswd password_baru  .. warning::  Only one of a, l, p, or r can be specified. If options are not included, the zimbra_ldap_password is changed.  Jika password lebih dari 16 karakter (misal 32), pastikan aplikasi ketiga (third party apps) tersebut dapat menerima 32 karakter password.  ref:  zimbra docs", 
            "title": "Zimbra - Reset Password zimbra ldap admin"
        }, 
        {
            "location": "/zimbra-cara-update-ssl-non-wilcard-ke-wildcard/", 
            "text": "Cara update ssl non wildcard ke wildcard di zimbra\n\n\n\n\ncopy file /tmp/comm.tar di mail2 ke mail.abc.co.id .\n\n\npindah direktory /opt/zimbra/ssl/zimbra/commercial . \n\n\nbackup / pindah semua file di sini, misal di folder /opt/zimbra/ssl/zimbra/commercial/old/ .\n\n\nekstrak file /tmp/comm.tar\nhasil extract\nroot@mail3://opt/zimbra/ssl/zimbra/commercial# ls -al\ntotal 116\ndrwxr----- 3 root root  4096 Apr 30 15:22 .\ndrwxr----- 5 root root  4096 Apr 30 13:04 ..\n-rwxr----- 1 root root  4211 Apr 30 15:22 ca_chain.crt\n-rwxr----- 1 root root  2714 Dec  2 10:17 ca.crt\n-rwxr----- 1 root root  1497 Dec  2 10:15 ca_intermiediary.crt\n-rwxr----- 1 root root  4211 Apr 30 15:22 commercial_ca.crt\n-rw-r--r-- 1 root root 10098 Apr 30 15:22 commercial.crt\n-rwxr----- 1 root root  1123 Dec  2 09:57 commercial.csr\n-rwxr----- 1 root root  1704 Dec  2 08:55 commercial.key\n-rw-r--r-- 1 root root 61440 Apr 30 15:20 comm.tar\ndrwxr----- 2 root root  4096 Dec  2 09:57 old\nroot@mail3://opt/zimbra/ssl/zimbra/commercial#\n\n\n\n\n\n\n\nKetik command berikut:\n\n\nroot@mail3:/opt/zimbra/ssl/zimbra/commercial# /opt/zimbra/openssl/bin/openssl verify -CAfile `pwd`/ca_chain.crt `pwd`/commercial.crt\n/opt/zimbra/ssl/zimbra/commercial/commercial.crt: OK\n\n\n\nlalu deploy:\n\n\nroot@mail3:/opt/zimbra/ssl/zimbra/commercial# /opt/zimbra/bin/zmcertmgr deploycrt comm `pwd`/commercial.crt `pwd`/ca_chain.crt\n** Verifying /opt/zimbra/ssl/zimbra/commercial/commercial.crt against /opt/zimbra/ssl/zimbra/commercial/commercial.key\nCertificate (/opt/zimbra/ssl/zimbra/commercial/commercial.crt) and private key (/opt/zimbra/ssl/zimbra/commercial/commercial.key) match.\nValid Certificate: /opt/zimbra/ssl/zimbra/commercial/commercial.crt: OK\n** Copying /opt/zimbra/ssl/zimbra/commercial/commercial.crt to /opt/zimbra/ssl/zimbra/commercial/commercial.crt\ncp: `/opt/zimbra/ssl/zimbra/commercial/commercial.crt' and `/opt/zimbra/ssl/zimbra/commercial/commercial.crt' are the same file\n** Appending ca chain /opt/zimbra/ssl/zimbra/commercial/ca_chain.crt to /opt/zimbra/ssl/zimbra/commercial/commercial.crt\n** Importing certificate /opt/zimbra/ssl/zimbra/commercial/commercial_ca.crt to CACERTS as zcs-user-commercial_ca...done.\n** NOTE: mailboxd must be restarted in order to use the imported certificate.\n** Saving server config key zimbraSSLCertificate...done.\n** Saving server config key zimbraSSLPrivateKey...done.\n** Installing mta certificate and key...done.\n** Installing slapd certificate and key...done.\n** Installing proxy certificate and key...done.\n** Creating pkcs12 file /opt/zimbra/ssl/zimbra/jetty.pkcs12...done.\n** Creating keystore file /opt/zimbra/mailboxd/etc/keystore...done.\n** Installing CA to /opt/zimbra/conf/ca...done.\nroot@mail3:/opt/zimbra/ssl/zimbra/commercial#\n\n\n\nterus restart: \n\n\nzmcontrol restart\n\n\n\nhasil test ssl labs:\n\n\nsslmailfinal.png\n\n\n\ncertificate information:\n\n\ncertinfo.png\n\n\n\nTerlihat CN sudah memakai wildcard (*.abc.co.id)\n\n\nNote:\n\n\nSSL.key = commercial.key\n\n\nca_intermiediary.crt = INTERMEDIATE CA dari email\n\n\nca.crt = INTERMEDIATE CA dari email + GeoTrust_Global_CA.pem\n\n\nca_chain.crt = cat ca.crt ca_intermiediary.crt \n ca_chain.crt\n\n\ncommercial.crt = Web Server CERTIFICATE + INTERMEDIATE CA dari email + GeoTrust_Global_CA.pem + INTERMEDIATE CA dari email", 
            "title": "Zimbra - Update ssl non wildcard ke wildcard"
        }, 
        {
            "location": "/zimbra-cara-update-ssl-non-wilcard-ke-wildcard/#cara-update-ssl-non-wildcard-ke-wildcard-di-zimbra", 
            "text": "copy file /tmp/comm.tar di mail2 ke mail.abc.co.id .  pindah direktory /opt/zimbra/ssl/zimbra/commercial .   backup / pindah semua file di sini, misal di folder /opt/zimbra/ssl/zimbra/commercial/old/ .  ekstrak file /tmp/comm.tar\nhasil extract root@mail3://opt/zimbra/ssl/zimbra/commercial# ls -al\ntotal 116\ndrwxr----- 3 root root  4096 Apr 30 15:22 .\ndrwxr----- 5 root root  4096 Apr 30 13:04 ..\n-rwxr----- 1 root root  4211 Apr 30 15:22 ca_chain.crt\n-rwxr----- 1 root root  2714 Dec  2 10:17 ca.crt\n-rwxr----- 1 root root  1497 Dec  2 10:15 ca_intermiediary.crt\n-rwxr----- 1 root root  4211 Apr 30 15:22 commercial_ca.crt\n-rw-r--r-- 1 root root 10098 Apr 30 15:22 commercial.crt\n-rwxr----- 1 root root  1123 Dec  2 09:57 commercial.csr\n-rwxr----- 1 root root  1704 Dec  2 08:55 commercial.key\n-rw-r--r-- 1 root root 61440 Apr 30 15:20 comm.tar\ndrwxr----- 2 root root  4096 Dec  2 09:57 old\nroot@mail3://opt/zimbra/ssl/zimbra/commercial#    Ketik command berikut:  root@mail3:/opt/zimbra/ssl/zimbra/commercial# /opt/zimbra/openssl/bin/openssl verify -CAfile `pwd`/ca_chain.crt `pwd`/commercial.crt\n/opt/zimbra/ssl/zimbra/commercial/commercial.crt: OK  lalu deploy:  root@mail3:/opt/zimbra/ssl/zimbra/commercial# /opt/zimbra/bin/zmcertmgr deploycrt comm `pwd`/commercial.crt `pwd`/ca_chain.crt\n** Verifying /opt/zimbra/ssl/zimbra/commercial/commercial.crt against /opt/zimbra/ssl/zimbra/commercial/commercial.key\nCertificate (/opt/zimbra/ssl/zimbra/commercial/commercial.crt) and private key (/opt/zimbra/ssl/zimbra/commercial/commercial.key) match.\nValid Certificate: /opt/zimbra/ssl/zimbra/commercial/commercial.crt: OK\n** Copying /opt/zimbra/ssl/zimbra/commercial/commercial.crt to /opt/zimbra/ssl/zimbra/commercial/commercial.crt\ncp: `/opt/zimbra/ssl/zimbra/commercial/commercial.crt' and `/opt/zimbra/ssl/zimbra/commercial/commercial.crt' are the same file\n** Appending ca chain /opt/zimbra/ssl/zimbra/commercial/ca_chain.crt to /opt/zimbra/ssl/zimbra/commercial/commercial.crt\n** Importing certificate /opt/zimbra/ssl/zimbra/commercial/commercial_ca.crt to CACERTS as zcs-user-commercial_ca...done.\n** NOTE: mailboxd must be restarted in order to use the imported certificate.\n** Saving server config key zimbraSSLCertificate...done.\n** Saving server config key zimbraSSLPrivateKey...done.\n** Installing mta certificate and key...done.\n** Installing slapd certificate and key...done.\n** Installing proxy certificate and key...done.\n** Creating pkcs12 file /opt/zimbra/ssl/zimbra/jetty.pkcs12...done.\n** Creating keystore file /opt/zimbra/mailboxd/etc/keystore...done.\n** Installing CA to /opt/zimbra/conf/ca...done.\nroot@mail3:/opt/zimbra/ssl/zimbra/commercial#  terus restart:   zmcontrol restart  hasil test ssl labs:  sslmailfinal.png  certificate information:  certinfo.png  Terlihat CN sudah memakai wildcard (*.abc.co.id)  Note:  SSL.key = commercial.key  ca_intermiediary.crt = INTERMEDIATE CA dari email  ca.crt = INTERMEDIATE CA dari email + GeoTrust_Global_CA.pem  ca_chain.crt = cat ca.crt ca_intermiediary.crt   ca_chain.crt  commercial.crt = Web Server CERTIFICATE + INTERMEDIATE CA dari email + GeoTrust_Global_CA.pem + INTERMEDIATE CA dari email", 
            "title": "Cara update ssl non wildcard ke wildcard di zimbra"
        }, 
        {
            "location": "/zimbra-send-as-distribution-list/", 
            "text": "Zimbra - send as distribution list\n\n\nFormat.\n\n\n    zmprov grr dl list@example.tld usr user@example.tld sendAsDistList\n\n\n\nPoC:\n\n\n    dian@mail2:~$ sudo su - zimbra\n    zimbra@mail2:~$ zmprov grr dl l@domain usr k.pusat@domain sendAsDistList\n\n\n\nuntuk revoke.\n\n\n    zimbra@mail2:~$ zmprov rvr dl l@domain usr k.pusat@domain sendAsDistList\n\n\n\nref: \nzimbra docs forum", 
            "title": "Zimbra - send as distribution list"
        }, 
        {
            "location": "/zimbra-send-as-distribution-list/#zimbra-send-as-distribution-list", 
            "text": "Format.      zmprov grr dl list@example.tld usr user@example.tld sendAsDistList  PoC:      dian@mail2:~$ sudo su - zimbra\n    zimbra@mail2:~$ zmprov grr dl l@domain usr k.pusat@domain sendAsDistList  untuk revoke.      zimbra@mail2:~$ zmprov rvr dl l@domain usr k.pusat@domain sendAsDistList  ref:  zimbra docs forum", 
            "title": "Zimbra - send as distribution list"
        }, 
        {
            "location": "/zimbra-create-mass-account-mail-via-CLI/", 
            "text": "Zimbra - Create mass Account Mail via CLI\n\n\nBuat file buat.sh misal\n\n\n   #!/bin/bash\n\n   cat user.txt | while read line\n\n   do\n\n   emailid=`echo $line | awk -F \\, '{print $1}'`\n   firstname=`echo $line | awk -F \\, '{print $2}'`\n   lastname=`echo $line | awk -F \\, '{print $3}'`\n   password=`\n /dev/urandom tr -dc A-Za-z0-9 | head -c8 ; echo`\n   ## bikin user\n   /opt/zimbra/bin/zmprov createAccount $emailid $password zimbraPasswordMustChange TRUE displayName \"$firstname $lastname\" givenName \"${firstname}\" sn \"${lastname}\"\n   ## set user ke dalam COS enforce_passpol_v1\n   /opt/zimbra/bin/zmprov setAccountCos $emailid enforce_passpol_v1\n\n   ## simpan user yang sudah dibuat ke file fix.acc.txt\n   echo \"${emailid}:${password}\" \n fix.acc.txt\n\n   done\n\n\n\nmasih dalam satu folder, buat file user.txt yang berisi informasi user domain, first name , last name dengan format:\n\n\n   user@domain,first_name,last_name\n\n\n\nlalu jalankan \n\n\n   zimbra@mail:~$ bash buat.sh", 
            "title": "Zimbra - Create mass Account Mail via CLI"
        }, 
        {
            "location": "/zimbra-create-mass-account-mail-via-CLI/#zimbra-create-mass-account-mail-via-cli", 
            "text": "Buat file buat.sh misal     #!/bin/bash\n\n   cat user.txt | while read line\n\n   do\n\n   emailid=`echo $line | awk -F \\, '{print $1}'`\n   firstname=`echo $line | awk -F \\, '{print $2}'`\n   lastname=`echo $line | awk -F \\, '{print $3}'`\n   password=`  /dev/urandom tr -dc A-Za-z0-9 | head -c8 ; echo`\n   ## bikin user\n   /opt/zimbra/bin/zmprov createAccount $emailid $password zimbraPasswordMustChange TRUE displayName \"$firstname $lastname\" givenName \"${firstname}\" sn \"${lastname}\"\n   ## set user ke dalam COS enforce_passpol_v1\n   /opt/zimbra/bin/zmprov setAccountCos $emailid enforce_passpol_v1\n\n   ## simpan user yang sudah dibuat ke file fix.acc.txt\n   echo \"${emailid}:${password}\"   fix.acc.txt\n\n   done  masih dalam satu folder, buat file user.txt yang berisi informasi user domain, first name , last name dengan format:     user@domain,first_name,last_name  lalu jalankan      zimbra@mail:~$ bash buat.sh", 
            "title": "Zimbra - Create mass Account Mail via CLI"
        }, 
        {
            "location": "/zimbra-relay-certain-domain-to-exim/", 
            "text": "Zimbra - Relay certain domain to Exim via auth ESMTP\n\n\nAda beberapa domain yang ada di zimbra agar menggunakan IP bersih dari \nupstreamrelay.host\n dengan menggunakan authentikasi via \nESMTP\n.\n\n\nKonfigurasi postfix zimbra\n\n\ntambahkan di \n/opt/zimbra/postfix/conf/main.cf\n\n\nsmtp_sender_dependent_authentication = yes\nsender_dependent_relayhost_maps = lmdb:/etc/postfix/sender_relay\n\n\n\ntambahkan juga via terminal:\n\n\nzmprov ms localmail.host zimbraMtaSmtpSaslAuthEnable yes\nzmprov ms localmail.host zimbraMtaSmtpSaslPasswordMaps lmdb:/etc/postfix/sasl_passwd\n\n\n\ncreate sender relay, misal semua domain.abc.id akan menggunakan IP dari \nupstreamrelay.host\n:\n\n\nvim /etc/postfix/sender_relay\n\n\n@domain.abc.d      upstreamrelay.host:587\n\n\n\ndefine user passwordnya:\n\n\nvim /etc/postfix/sasl_passwd\n\n\n@domain.abc.d      user@upstreamrelay.host:password\n\n\n\ncreate postfix table lookup:\n\n\n/opt/zimbra/postfix-2.11.1.2z/sbin/postmap /etc/postfix/sender_relay\n/opt/zimbra/postfix-2.11.1.2z/sbin/postmap /etc/postfix/sasl_passwd\n\n\n\ndisable noplaintext security dari postfix:\n\n\nzmprov ms localhost.mail zimbraMtaSmtpSaslSecurityOptions noanonymous\n\n\n\nreload postfix\n:\n\n\nzmmtactl reload\n\n\n\nRef:\n\n\n\n\nhttp://imanudin.net/2014/12/26/relay-tips-based-on-userdomain-sender-on-zimbra-8-5-8-6/\n\n\nhttps://wiki.zimbra.com/wiki/Outgoing_SMTP_Authentication\n\n\nhttp://serverfault.com/questions/443652/using-postfix-to-relay-via-multiple-google-apps-accounts", 
            "title": "Zimbra - Relay certain domain to Exim via ESMTP"
        }, 
        {
            "location": "/zimbra-relay-certain-domain-to-exim/#zimbra-relay-certain-domain-to-exim-via-auth-esmtp", 
            "text": "Ada beberapa domain yang ada di zimbra agar menggunakan IP bersih dari  upstreamrelay.host  dengan menggunakan authentikasi via  ESMTP .", 
            "title": "Zimbra - Relay certain domain to Exim via auth ESMTP"
        }, 
        {
            "location": "/zimbra-relay-certain-domain-to-exim/#konfigurasi-postfix-zimbra", 
            "text": "tambahkan di  /opt/zimbra/postfix/conf/main.cf  smtp_sender_dependent_authentication = yes\nsender_dependent_relayhost_maps = lmdb:/etc/postfix/sender_relay  tambahkan juga via terminal:  zmprov ms localmail.host zimbraMtaSmtpSaslAuthEnable yes\nzmprov ms localmail.host zimbraMtaSmtpSaslPasswordMaps lmdb:/etc/postfix/sasl_passwd  create sender relay, misal semua domain.abc.id akan menggunakan IP dari  upstreamrelay.host :  vim /etc/postfix/sender_relay  @domain.abc.d      upstreamrelay.host:587  define user passwordnya:  vim /etc/postfix/sasl_passwd  @domain.abc.d      user@upstreamrelay.host:password  create postfix table lookup:  /opt/zimbra/postfix-2.11.1.2z/sbin/postmap /etc/postfix/sender_relay\n/opt/zimbra/postfix-2.11.1.2z/sbin/postmap /etc/postfix/sasl_passwd  disable noplaintext security dari postfix:  zmprov ms localhost.mail zimbraMtaSmtpSaslSecurityOptions noanonymous  reload postfix :  zmmtactl reload  Ref:   http://imanudin.net/2014/12/26/relay-tips-based-on-userdomain-sender-on-zimbra-8-5-8-6/  https://wiki.zimbra.com/wiki/Outgoing_SMTP_Authentication  http://serverfault.com/questions/443652/using-postfix-to-relay-via-multiple-google-apps-accounts", 
            "title": "Konfigurasi postfix zimbra"
        }, 
        {
            "location": "/gammu-install/", 
            "text": "Untuk installasi gammu, pastikan kernel sudah mendeteksi modem sebagai USB atau device lainnya.\ndalam contoh kali ini terdeteksi sebagai usb.\n\n\n\n\n\nUntuk install gammu cukup dengan perintah:\n\n\napt-get install gammu\n\n\n\ncek dengan perintah gammu-detect, maka akan terlihat seperti berikut:\n\n\n\n\n\ncreate file .gammurc7 misalnya di /root/ :\n\n\n\n\n\nsesuaikan device ttyUSB7 dengan nomor simcard yang dipasang. dalam contoh kali ini nomor simcard 8 yang akan dicoba.\nketik perintah gammu -c .gammurc7 identify , maka akan terlihat seperti berikut:\n\n\n\n\n\nUntuk test cek pulsa:\n\n\n\n\ndone.", 
            "title": "Gammu - Installation"
        }, 
        {
            "location": "/gammu-install-configure-playsms/", 
            "text": "Install dan Configure PlaySMS Web Interface Gammu\n\n\nRequirements:\n\n\n\n\nNginx \n PHP-FPM yang sudah terinstall dengan baik, terutama dengan koneksi PHP MySQL.\n\n\nMySQL server sebagai database server.\n\n\nGit Client\n\n\n\n\nInstall Gammu SMS Daemon\n\n\nGammu SMS Daemon is a program that periodically scans GSM modem for received messages, \nstores them in defined storage and also sends messages enqueued in this storage. \nIt is perfect tool for managing big amounts of received or sent messages and automatically process them.\n\n\ninstall dengan perintah:\n\n\napt-get install gammu-smsd\n\n\n\nlalu create directory:\n\n\nmkdir -p /var/spool/gammu/{inbox,outbox,sent,error}\nchown gammu.gammu -Rf /var/spool/gammu/\n\n\n\ncreate file /etc/gammu-smsdrc\n\n\n\n\n\nstart service:\n\n\nroot@infra:/srv/playsms# /etc/init.d/gammu-smsd start\n * gammu-smsd is running\nroot@infra:/srv/playsms#\n\n\n\natau\n\n\ngammu-smsd -c /etc/gammu-smsdrc\n\n\n\nInstall PlaySMS\n\n\nplaySMS is a free and open source SMS management software. \nA flexible Web-based mobile portal system that it can be made to fit to various services \nsuch as an SMS gateway, bulk SMS provider, personal messaging system, corporate and group communication tools\n\n\nPlaySMS digunakan sebagai interface untuk mengirim dan menerima sms dari Gammu.\nDalam percobaan kali ini hanya menggunakan 1 modem saja.\n\n\nunduh source code PlaySMS \n extract\n\n\nwget -c \"https://github.com/antonraharja/playSMS/archive/master.zip\" \n unzip master.zip\n\n\n\npindah directory lalu copy install.conf.dist ke install.conf\n\n\ncd playSMS-master/;\ncp install.conf.dist install.conf;\n\n\n\nlalu edit install.conf . sesuaikan dengan kondisi.\n\n\n\n\n\nuntuk path public directory application akan disimpan di /srv/playsms .\nsetelah itu jalankan:\n\n\n./install-playsms.sh\n\n\n\nsetelah terinstall dengan baik dan tidak ada error bisa dicek dengan perintah:\n\n\nplaysmsd /etc/playsmsd.conf status\n\n\n\njika belum running jalankan dengan perintah:\n\n\nplaysmsd /etc/playsmsd.conf start\n\n\n\ncek lagi dengan perintah status:\n\n\nroot@infra:/srv/playsms# playsmsd /etc/playsmsd.conf status\nplaysmsd is running\nschedule at pid 1393\nratesmsd at pid 1395\ndlrssmsd at pid 1398\nrecvsmsd at pid 1401\nsendsmsd at pid 1404\n\n\n\nKonfigurasi di PlaySMS:\n\n\n\n\nSetting Gateway \n SMSC\n\n\n\n\nKlik Setting -\n Manage gateway and SMSC, lalu isi seperti berikut:\n\n\n\n\n2 Setting Outgoing SMS\nKlik Setting -\n Route SMS outgoing, lalu isi seperti berikut:\n\n\n    \n\n\n\n\nSetting Incoming SMS:\n\n\n\n\nKlik Setting -\n Route Incoming SMS,\nIsi dengan 'no' pada semua dropdown select, kecuali seperti pada gambar berikut:\n\n\n\n\nKlik Save lalu test kirim sms ke nomor modem dari nomor lain, dan kirim sms dari nomor modem ke nomor lain.\n\n\nResults:\n\n\n\n\nReport sent SMS\n\n\n\nReport inbox SMS \n\n\ndone.", 
            "title": "Gammu - Install dan Configure PlaySMS Web Interface"
        }, 
        {
            "location": "/gammu-install-configure-playsms/#install-dan-configure-playsms-web-interface-gammu", 
            "text": "Requirements:   Nginx   PHP-FPM yang sudah terinstall dengan baik, terutama dengan koneksi PHP MySQL.  MySQL server sebagai database server.  Git Client", 
            "title": "Install dan Configure PlaySMS Web Interface Gammu"
        }, 
        {
            "location": "/gammu-install-configure-playsms/#install-gammu-sms-daemon", 
            "text": "Gammu SMS Daemon is a program that periodically scans GSM modem for received messages, \nstores them in defined storage and also sends messages enqueued in this storage. \nIt is perfect tool for managing big amounts of received or sent messages and automatically process them.  install dengan perintah:  apt-get install gammu-smsd  lalu create directory:  mkdir -p /var/spool/gammu/{inbox,outbox,sent,error}\nchown gammu.gammu -Rf /var/spool/gammu/  create file /etc/gammu-smsdrc   start service:  root@infra:/srv/playsms# /etc/init.d/gammu-smsd start\n * gammu-smsd is running\nroot@infra:/srv/playsms#  atau  gammu-smsd -c /etc/gammu-smsdrc", 
            "title": "Install Gammu SMS Daemon"
        }, 
        {
            "location": "/gammu-install-configure-playsms/#install-playsms", 
            "text": "playSMS is a free and open source SMS management software. \nA flexible Web-based mobile portal system that it can be made to fit to various services \nsuch as an SMS gateway, bulk SMS provider, personal messaging system, corporate and group communication tools  PlaySMS digunakan sebagai interface untuk mengirim dan menerima sms dari Gammu.\nDalam percobaan kali ini hanya menggunakan 1 modem saja.  unduh source code PlaySMS   extract  wget -c \"https://github.com/antonraharja/playSMS/archive/master.zip\"   unzip master.zip  pindah directory lalu copy install.conf.dist ke install.conf  cd playSMS-master/;\ncp install.conf.dist install.conf;  lalu edit install.conf . sesuaikan dengan kondisi.   untuk path public directory application akan disimpan di /srv/playsms .\nsetelah itu jalankan:  ./install-playsms.sh  setelah terinstall dengan baik dan tidak ada error bisa dicek dengan perintah:  playsmsd /etc/playsmsd.conf status  jika belum running jalankan dengan perintah:  playsmsd /etc/playsmsd.conf start  cek lagi dengan perintah status:  root@infra:/srv/playsms# playsmsd /etc/playsmsd.conf status\nplaysmsd is running\nschedule at pid 1393\nratesmsd at pid 1395\ndlrssmsd at pid 1398\nrecvsmsd at pid 1401\nsendsmsd at pid 1404  Konfigurasi di PlaySMS:   Setting Gateway   SMSC   Klik Setting -  Manage gateway and SMSC, lalu isi seperti berikut:   2 Setting Outgoing SMS\nKlik Setting -  Route SMS outgoing, lalu isi seperti berikut:         Setting Incoming SMS:   Klik Setting -  Route Incoming SMS,\nIsi dengan 'no' pada semua dropdown select, kecuali seperti pada gambar berikut:   Klik Save lalu test kirim sms ke nomor modem dari nomor lain, dan kirim sms dari nomor modem ke nomor lain.", 
            "title": "Install PlaySMS"
        }, 
        {
            "location": "/gammu-install-configure-playsms/#results", 
            "text": "Report sent SMS  \nReport inbox SMS   done.", 
            "title": "Results:"
        }, 
        {
            "location": "/gammu-configure-multiple-modem-playsms/", 
            "text": "How to configure multiple modem PlaySMS Gammu\n\n\nSetelah kita bisa membangun \nSMS Gateway dengan 1 modem beserta Webui PlaySMS\n, \nselanjutnya kita bisa menggunakan PlaySMS tersebut dengan multiple Modem. \n\n\nKali ini kita dengan modem 8 pool, namun pada saat test hanya digunakan 2 buah modem karena keterbatasan SIM Card.\n\n\nRequirement: \n\n\n\n\nSMS3 Tools\n\n\nShell script\n\n\n\n\nSMS Tools 3\n\n\nSMS Tools 3 digunakan sebagai daemon yang akan menghandle 8 pool daripada modem.\n\n\nInstall SMS Tools 3:\n\n\ncd /usr/local/src\nwget -c http://smstools3.kekekasvi.com/packages/smstools3-3.1.16beta.tar.gz\ntar -xvf smstools3-3.1.16beta.tar.gz \ncd smstools3/\n./install.sh \nmake\nmake install\n\n\n\ncreate directory:\n\n\nmkdir -p /var/spool/sms/{modem6,modem7}\n\n\n\nlalu create file \n/etc/smsd.conf\n seperti berikut:\n\n\n\n\n\nlalu ubah rc.script /etc/init.d/sms3 menjadi seperti berikut:\n\n\n\n\n\nlalu start sms3 dan cek daemonnya apakah sudah running atau belum:\n\n\noot@infra:/usr/local/src# /etc/init.d/sms3 start\nStarting SMS Daemon: smsd.\nplaysmsd has been started\nschedule at pid 22834\nratesmsd at pid 22836\ndlrssmsd at pid 22838\nrecvsmsd at pid 22840\nsendsmsd at pid 22844\nroot@infra:/usr/local/src# ps aux | grep smsd\nroot     22692  0.0  0.2   5988  5028 ?        Ss   09:19   0:00 /usr/local/bin/smsd -n MAINPROCESS -p/var/run/smsd.pid -i/var/run/smsd.working -l/var/log/smsd.log\nroot     22694  0.1  0.2   6028  4936 ?        S    09:19   0:00 /usr/local/bin/smsd -n modem6_____ -p/var/run/smsd.pid -i/var/run/smsd.working -l/var/log/smsd.log\nroot     22695  0.1  0.2   6028  4936 ?        S    09:19   0:00 /usr/local/bin/smsd -n modem7_____ -p/var/run/smsd.pid -i/var/run/smsd.working -l/var/log/smsd.log\nroot     22834  0.5  0.9  44264 17776 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf schedule\nroot     22836  0.4  0.9  44264 17700 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf ratesmsd\nroot     22838  0.9  0.9  44268 17856 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf dlrssmsd\nroot     22840  0.6  0.9  44264 17792 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf recvsmsd\nroot     22844  0.4  0.9  44164 17760 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf sendsmsd\nroot     22965  0.0  0.1   4692  2136 pts/3    S+   09:21   0:00 grep --color=auto smsd\n\n\n\n\n\nTerlihat daemon sudah running dengan baik, \nmodem6\n \n \nmodem7\n.\n\n\nShell Script\n\n\nthese are ways to works with outgoing sms (sent reports) and incoming sms (inbox reports) with multiple modem on PlaySMS\n\n\ncreate file seperti berikut:\n\n\n\n\n\nsave as \n/root/bin/convert2gammu.sh\n\n\nlalu create file \n/root/bin/runc2g.sh\n\n\n\n\n\nberi semua file tersebut \nbit x permission\n lalu tambahkan di \n/etc/rc.local\n:\n\n\n/root/bin/runc2g.sh\n\n\n\nSetting PlaySMS agar bisa menggunakan SMS3 daemon\n\n\nKlik Setting -\n Route outgoing SMS\n\n\n\n\nKonfigurasi seperti diatas.\n\n\nLalu Setting Gateway dan SMSC, Klik Setting -\n Manage Gateway \n SMSC\n\n\n\n\nlalu test kirim sms untuk outgoing dan incoming.\n\n\nResults\n\n\n\n\nSent Messages.\n\n\n\n\nInbox Messages", 
            "title": "Gammu - How to configure multiple modem PlaySMS Gammu"
        }, 
        {
            "location": "/gammu-configure-multiple-modem-playsms/#how-to-configure-multiple-modem-playsms-gammu", 
            "text": "Setelah kita bisa membangun  SMS Gateway dengan 1 modem beserta Webui PlaySMS , \nselanjutnya kita bisa menggunakan PlaySMS tersebut dengan multiple Modem.   Kali ini kita dengan modem 8 pool, namun pada saat test hanya digunakan 2 buah modem karena keterbatasan SIM Card.  Requirement:    SMS3 Tools  Shell script", 
            "title": "How to configure multiple modem PlaySMS Gammu"
        }, 
        {
            "location": "/gammu-configure-multiple-modem-playsms/#sms-tools-3", 
            "text": "SMS Tools 3 digunakan sebagai daemon yang akan menghandle 8 pool daripada modem.  Install SMS Tools 3:  cd /usr/local/src\nwget -c http://smstools3.kekekasvi.com/packages/smstools3-3.1.16beta.tar.gz\ntar -xvf smstools3-3.1.16beta.tar.gz \ncd smstools3/\n./install.sh \nmake\nmake install  create directory:  mkdir -p /var/spool/sms/{modem6,modem7}  lalu create file  /etc/smsd.conf  seperti berikut:   lalu ubah rc.script /etc/init.d/sms3 menjadi seperti berikut:   lalu start sms3 dan cek daemonnya apakah sudah running atau belum:  oot@infra:/usr/local/src# /etc/init.d/sms3 start\nStarting SMS Daemon: smsd.\nplaysmsd has been started\nschedule at pid 22834\nratesmsd at pid 22836\ndlrssmsd at pid 22838\nrecvsmsd at pid 22840\nsendsmsd at pid 22844\nroot@infra:/usr/local/src# ps aux | grep smsd\nroot     22692  0.0  0.2   5988  5028 ?        Ss   09:19   0:00 /usr/local/bin/smsd -n MAINPROCESS -p/var/run/smsd.pid -i/var/run/smsd.working -l/var/log/smsd.log\nroot     22694  0.1  0.2   6028  4936 ?        S    09:19   0:00 /usr/local/bin/smsd -n modem6_____ -p/var/run/smsd.pid -i/var/run/smsd.working -l/var/log/smsd.log\nroot     22695  0.1  0.2   6028  4936 ?        S    09:19   0:00 /usr/local/bin/smsd -n modem7_____ -p/var/run/smsd.pid -i/var/run/smsd.working -l/var/log/smsd.log\nroot     22834  0.5  0.9  44264 17776 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf schedule\nroot     22836  0.4  0.9  44264 17700 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf ratesmsd\nroot     22838  0.9  0.9  44268 17856 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf dlrssmsd\nroot     22840  0.6  0.9  44264 17792 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf recvsmsd\nroot     22844  0.4  0.9  44164 17760 pts/3    S    09:19   0:00 /usr/bin/php -q /usr/local/bin/playsmsd /etc/playsmsd.conf sendsmsd\nroot     22965  0.0  0.1   4692  2136 pts/3    S+   09:21   0:00 grep --color=auto smsd   Terlihat daemon sudah running dengan baik,  modem6     modem7 .", 
            "title": "SMS Tools 3"
        }, 
        {
            "location": "/gammu-configure-multiple-modem-playsms/#shell-script", 
            "text": "these are ways to works with outgoing sms (sent reports) and incoming sms (inbox reports) with multiple modem on PlaySMS  create file seperti berikut:   save as  /root/bin/convert2gammu.sh  lalu create file  /root/bin/runc2g.sh   beri semua file tersebut  bit x permission  lalu tambahkan di  /etc/rc.local :  /root/bin/runc2g.sh  Setting PlaySMS agar bisa menggunakan SMS3 daemon  Klik Setting -  Route outgoing SMS   Konfigurasi seperti diatas.  Lalu Setting Gateway dan SMSC, Klik Setting -  Manage Gateway   SMSC   lalu test kirim sms untuk outgoing dan incoming.", 
            "title": "Shell Script"
        }, 
        {
            "location": "/gammu-configure-multiple-modem-playsms/#results", 
            "text": "Sent Messages.   Inbox Messages", 
            "title": "Results"
        }, 
        {
            "location": "/cpanel-force-ssl-username/", 
            "text": "How to force generate autossl for the user CPanel\n\n\nTo force generate autossl for the user CPanel, simply run:\n\n\n/usr/local/cpanel/bin/autossl_check_cpstore_queue\n\n\n\nfor certain user:\n\n\n/usr/local/cpanel/bin/autossl_check --user=username", 
            "title": "CPanel - How to force generate autossl for the user CPanel"
        }, 
        {
            "location": "/cpanel-force-ssl-username/#how-to-force-generate-autossl-for-the-user-cpanel", 
            "text": "To force generate autossl for the user CPanel, simply run:  /usr/local/cpanel/bin/autossl_check_cpstore_queue  for certain user:  /usr/local/cpanel/bin/autossl_check --user=username", 
            "title": "How to force generate autossl for the user CPanel"
        }, 
        {
            "location": "/nginx-osticket/", 
            "text": "Nginx Osticket\n\n\nNginx config untuk Osticket 1.7.x dan 1.8.x. Sudah ditest di osticket versi 1.7.x dan 1.8 tidak ada masalah::\n\n\nserver {\n\n    listen   80; ## listen for ipv4; this line is default and implied\n    root  /var/www/ldaphelpdesk;\n    index index.php;\n\n    client_max_body_size 20M;\n    server_name aa.bb.cc.co.id; \n    server_name_in_redirect off;\n\n    access_log /var/log/nginx/osticket/ldap_access_ldap_helpdesk.log;\n    error_log /var/log/nginx/osticket/ldap_error_ldap_helpdesk.log warn;\n\n    location / {\n            index  index.php index.html index.htm;\n            try_files $uri $uri/ index.php;\n            proxy_read_timeout 300;\n    }\n    error_page 404 /404.html;\n    error_page 403 500 502 503 504 /50x.html;\n    location = /50x.html {\n            root html;\n    }\n    set $path_info \"\";\n\n    location ~ /include {\n        deny all;\n        return 403;\n    }\n\n    if ($request_uri ~ \"^/api(/[^\\?]+)\") {\n        set $path_info $1;\n    }\n\n    location ~ ^/api/(?:tickets|tasks).*$ {\n        try_files $uri $uri/ /api/http.php?$query_string;\n    }\n\n    if ($request_uri ~ \"^/scp/.*\\.php(/[^\\?]+)\") {\n        set $path_info $1;\n    }\n\n    location ~ ^/scp/ajax.php/.*$ {\n        try_files $uri $uri/ /scp/ajax.php?$query_string;\n    }\n\n    location ~ ^/ajax.php/.*$ {\n        try_files $uri $uri/ /ajax.php?$query_string;\n    }\n\n\n    location ~ \\.php$ {\n        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n        include        fastcgi_params;\n        fastcgi_param  PATH_INFO    $path_info;\n        fastcgi_pass   127.0.0.1:9000;\n    }\n    # deny access to .htaccess files, if Apache's document root\n    # concurs with nginx's one\n    #\n    location ~ /\\.ht {\n            deny all;\n    }\n}", 
            "title": "Nginx - Osticket"
        }, 
        {
            "location": "/nginx-osticket/#nginx-osticket", 
            "text": "Nginx config untuk Osticket 1.7.x dan 1.8.x. Sudah ditest di osticket versi 1.7.x dan 1.8 tidak ada masalah::  server {\n\n    listen   80; ## listen for ipv4; this line is default and implied\n    root  /var/www/ldaphelpdesk;\n    index index.php;\n\n    client_max_body_size 20M;\n    server_name aa.bb.cc.co.id; \n    server_name_in_redirect off;\n\n    access_log /var/log/nginx/osticket/ldap_access_ldap_helpdesk.log;\n    error_log /var/log/nginx/osticket/ldap_error_ldap_helpdesk.log warn;\n\n    location / {\n            index  index.php index.html index.htm;\n            try_files $uri $uri/ index.php;\n            proxy_read_timeout 300;\n    }\n    error_page 404 /404.html;\n    error_page 403 500 502 503 504 /50x.html;\n    location = /50x.html {\n            root html;\n    }\n    set $path_info \"\";\n\n    location ~ /include {\n        deny all;\n        return 403;\n    }\n\n    if ($request_uri ~ \"^/api(/[^\\?]+)\") {\n        set $path_info $1;\n    }\n\n    location ~ ^/api/(?:tickets|tasks).*$ {\n        try_files $uri $uri/ /api/http.php?$query_string;\n    }\n\n    if ($request_uri ~ \"^/scp/.*\\.php(/[^\\?]+)\") {\n        set $path_info $1;\n    }\n\n    location ~ ^/scp/ajax.php/.*$ {\n        try_files $uri $uri/ /scp/ajax.php?$query_string;\n    }\n\n    location ~ ^/ajax.php/.*$ {\n        try_files $uri $uri/ /ajax.php?$query_string;\n    }\n\n\n    location ~ \\.php$ {\n        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n        include        fastcgi_params;\n        fastcgi_param  PATH_INFO    $path_info;\n        fastcgi_pass   127.0.0.1:9000;\n    }\n    # deny access to .htaccess files, if Apache's document root\n    # concurs with nginx's one\n    #\n    location ~ /\\.ht {\n            deny all;\n    }\n}", 
            "title": "Nginx Osticket"
        }, 
        {
            "location": "/nginx-PageSpeed-module/", 
            "text": "Build PageSpeed Module for Nginx di Centos\n\n\nPageSpeed speeds up your site and reduces page load time. This open-source webserver module automatically applies web performance best practices to pages and associated assets (CSS, JavaScript, images) without requiring that you modify your existing content or workflow\n\n\ninstall paket dependencies:\nyum install gcc-c++ zip unzip wget openssl pcre-dev pcre-devel zlib-devel make openssl-devel\n\n\n\nlalu pindah ke directory \n/usr/src\n untuk kompile nginx:\n\n\ncd /usr/src/\n\n\n\nset version NPS:\n\n\nNPS_VERSION=1.9.32.3\n\n\n\nunduh nginx module pagespeed, extract, lalu masuk ke directory tsb:\n\n\nwget https://github.com/pagespeed/ngx_pagespeed/archive/release-${NPS_VERSION}-beta.zip\nunzip release-1.9.32.3-beta.zip \ncd ngx_pagespeed-release-1.9.32.3-beta/\n\n\n\nunduh page-speed module, lalu extract:\n\n\nwget --no-check-certificate https://dl.google.com/dl/page-speed/psol/${NPS_VERSION}.tar.gz\ntar -xvf 1.9.32.3.tar.gz\n\n\n\npindah ke directory /usr/src untuk kompile nginx. lalu unduh nginx (sesuaikan versi yg terbaru/yg mau dipilih). extract, setelah itu masuk ke directory tsb.\n\n\ncd /usr/src/\nwget -c http://nginx.org/download/nginx-1.7.9.tar.gz\ntar -xvf nginx-1.7.9.tar.gz \ncd nginx-1.7.9\n\n\n\nkonfig source nginx dengan perintah berikut:\n\n\n\n\n./configure --prefix=/usr/local/nginx --add-module=/usr/src/ngx_pagespeed-release-1.9.32.3-beta --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-http_auth_request_module --with-mail --with-mail_ssl_module --with-file-aio --with-ipv6 --with-cc-opt='-O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'\n\n\n\n\nuntuk opsi configure perintah diatas, sesuaikan dengan opsi config  yang sudah dipakai nginx di production. untuk melihat opsi config nginx dari repository bisa dilakukan dengan perintah:\n\n\n    [root@FE02 src]# nginx -V\n    nginx version: nginx/1.4.4\n    built by gcc 4.4.7 20120313 (Red Hat 4.4.7-3) (GCC) \n    TLS SNI support enabled\n\n\n\n\n\nconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-mail --with-mail_ssl_module --with-file-aio --with-ipv6 --with-cc-opt='-O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'\n[root@FE02- src]#\n\n\n\n\nsetelah konfigurasi tidak ada error/masalah. bisa dilanjutkan dengan make lalu make install:\n\n\nmake\nuntuk install:\nmake install\n\n\n\nnginx versi 1.7.9 sudah terinstall di \n/usr/local/nginx/\n dengan supported page module speed.\n\n\n    [root@FE02- src]# /usr/local/nginx/sbin/nginx -V\n    nginx version: nginx/1.7.9\n    built by gcc 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) \n    TLS SNI support enabled\n\n\n\n\n\nconfigure arguments: --prefix=/usr/local/nginx --add-module=/usr/src/ngx_pagespeed-release-1.9.32.3-beta --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-http_auth_request_module --with-mail --with-mail_ssl_module --with-file-aio --with-ipv6 --with-cc-opt='-O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'\n[root@FE02- src]#\n\n\n\n\nlangkah selanjutnya mengkonfigurasi service startup nginx\n\n\nmkdir /usr/local/etc/rc.d\nvim /usr/local/etc/rc.d/nginx\n\n\n\nisikan startup nginx service dengan berikut:\n\n\n#!/bin/sh\n#\n# nginx - this script starts and stops the nginx daemon\n#\n# chkconfig:   - 85 15 \n# description:  Nginx is an HTTP(S) server, HTTP(S) reverse \\\n#               proxy and IMAP/POP3 proxy server\n# processname: nginx\n# config:      /etc/nginx/nginx.conf\n# config:      /etc/sysconfig/nginx\n# pidfile:     /var/run/nginx.pid\n# Source function library.\n. /etc/rc.d/init.d/functions\n# Source networking configuration.\n. /etc/sysconfig/network\n# Check that networking is up.\n[ \"$NETWORKING\" = \"no\" ] \n exit 0\nnginx=\"/usr/local/nginx/sbin/nginx\"\nprog=$(basename $nginx)\nNGINX_CONF_FILE=\"/etc/nginx/nginx.conf\"\n[ -f /etc/sysconfig/nginx ] \n . /etc/sysconfig/nginx\nlockfile=/var/lock/subsys/nginx\nmake_dirs() {\n   # make required directories\n   user=`$nginx -V 2\n1 | grep \"configure arguments:\" | sed 's/[^*]*--user=\\([^ ]*\\).*/\\1/g' -`\n   if [ -z \"`grep $user /etc/passwd`\" ]; then\n       useradd -M -s /bin/nologin $user\n   fi\n   options=`$nginx -V 2\n1 | grep 'configure arguments:'`\n   for opt in $options; do\n       if [ `echo $opt | grep '.*-temp-path'` ]; then\n           value=`echo $opt | cut -d \"=\" -f 2`\n           if [ ! -d \"$value\" ]; then\n               # echo \"creating\" $value\n               mkdir -p $value \n chown -R $user $value\n           fi\n       fi\n   done\n}\nstart() {\n    [ -x $nginx ] || exit 5\n    [ -f $NGINX_CONF_FILE ] || exit 6\n    make_dirs\n    echo -n $\"Starting $prog: \"\n    daemon $nginx -c $NGINX_CONF_FILE\n    retval=$?\n    echo\n    [ $retval -eq 0 ] \n touch $lockfile\n    return $retval\n}\nstop() {\n    echo -n $\"Stopping $prog: \"\n    killproc $prog -QUIT\n    retval=$?\n    echo\n    [ $retval -eq 0 ] \n rm -f $lockfile\n    return $retval\n}\nrestart() {\n    configtest || return $?\n    stop\n    sleep 1\n    start\n}\nreload() {\n    configtest || return $?\n    echo -n $\"Reloading $prog: \"\n    killproc $nginx -HUP\n    RETVAL=$?\n    echo\n}\nforce_reload() {\n    restart\n}\nconfigtest() {\n  $nginx -t -c $NGINX_CONF_FILE\n}\nrh_status() {\n    status $prog\n}\nrh_status_q() {\n    rh_status \n/dev/null 2\n1\n}\ncase \"$1\" in\n    start)\n        rh_status_q \n exit 0\n        $1\n        ;;\n    stop)\n        rh_status_q || exit 0\n        $1\n        ;;\n    restart|configtest)\n        $1\n        ;;\n    reload)\n        rh_status_q || exit 7\n        $1\n        ;;\n    force-reload)\n        force_reload\n        ;;\n    status)\n        rh_status\n        ;;\n    condrestart|try-restart)\n        rh_status_q || exit 0\n            ;;\n    *)\n        echo $\"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}\"\n        exit 2\nesac\n\n\n\nberikan execution permission:\n\n\nchmod a+x /usr/local/etc/rc.d/nginx\n\n\n\nuntuk start bisa dengan perintah:\n\n\n/usr/local/etc/rc.d/nginx start\n\n\n\nuntuk reload, stop, dll tinggal menyesuaikan.\n\n\nuntuk praktis dengan perintah \nservice nginx {stop,reload,start}\n rename \n/etc/init.d/nginx\n ke old_file lalu symlink ke \n/usr/local/etc/rc.d/nginx\n\n\ncd /etc/init.d/\nmv nginx nginx.old\nln -s /usr/local/etc/rc.d/nginx ./\n\n\n\nEnable Module di Vhost domain:\nUntuk enable module di domain setiap vhost bisa menambahkan di vhost nginx:\n\n\n# enable ngx_pagespeed\npagespeed on;\npagespeed FileCachePath /var/ngx_pagespeed_cache;\n\n\n\nlalu set-up pagespeed filecachepath directory\n\n\n# mkdir /var/ngx_pagespeed_cache\n# chown nginx: /var/ngx_pagespeed_cache\n\n\n\nlalu restart nginx:\n\n\nservice nginx restart\n\n\n\nlalu test:\n\n\ndian@infra ~ $ curl -s -I www.domain.com | grep ^X-Page-Speed\nX-Page-Speed: 1.9.32.3-4448\ndian@infra ~ $\n\n\n\nref:\n 1. \nofficial docs\n\n 2. \nrosehosting", 
            "title": "Nginx - Build PageSpeed Module for Nginx di Centos"
        }, 
        {
            "location": "/nginx-PageSpeed-module/#build-pagespeed-module-for-nginx-di-centos", 
            "text": "PageSpeed speeds up your site and reduces page load time. This open-source webserver module automatically applies web performance best practices to pages and associated assets (CSS, JavaScript, images) without requiring that you modify your existing content or workflow  install paket dependencies:\nyum install gcc-c++ zip unzip wget openssl pcre-dev pcre-devel zlib-devel make openssl-devel  lalu pindah ke directory  /usr/src  untuk kompile nginx:  cd /usr/src/  set version NPS:  NPS_VERSION=1.9.32.3  unduh nginx module pagespeed, extract, lalu masuk ke directory tsb:  wget https://github.com/pagespeed/ngx_pagespeed/archive/release-${NPS_VERSION}-beta.zip\nunzip release-1.9.32.3-beta.zip \ncd ngx_pagespeed-release-1.9.32.3-beta/  unduh page-speed module, lalu extract:  wget --no-check-certificate https://dl.google.com/dl/page-speed/psol/${NPS_VERSION}.tar.gz\ntar -xvf 1.9.32.3.tar.gz  pindah ke directory /usr/src untuk kompile nginx. lalu unduh nginx (sesuaikan versi yg terbaru/yg mau dipilih). extract, setelah itu masuk ke directory tsb.  cd /usr/src/\nwget -c http://nginx.org/download/nginx-1.7.9.tar.gz\ntar -xvf nginx-1.7.9.tar.gz \ncd nginx-1.7.9  konfig source nginx dengan perintah berikut:   ./configure --prefix=/usr/local/nginx --add-module=/usr/src/ngx_pagespeed-release-1.9.32.3-beta --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-http_auth_request_module --with-mail --with-mail_ssl_module --with-file-aio --with-ipv6 --with-cc-opt='-O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'   untuk opsi configure perintah diatas, sesuaikan dengan opsi config  yang sudah dipakai nginx di production. untuk melihat opsi config nginx dari repository bisa dilakukan dengan perintah:      [root@FE02 src]# nginx -V\n    nginx version: nginx/1.4.4\n    built by gcc 4.4.7 20120313 (Red Hat 4.4.7-3) (GCC) \n    TLS SNI support enabled   configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-mail --with-mail_ssl_module --with-file-aio --with-ipv6 --with-cc-opt='-O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'\n[root@FE02- src]#   setelah konfigurasi tidak ada error/masalah. bisa dilanjutkan dengan make lalu make install:  make\nuntuk install:\nmake install  nginx versi 1.7.9 sudah terinstall di  /usr/local/nginx/  dengan supported page module speed.      [root@FE02- src]# /usr/local/nginx/sbin/nginx -V\n    nginx version: nginx/1.7.9\n    built by gcc 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) \n    TLS SNI support enabled   configure arguments: --prefix=/usr/local/nginx --add-module=/usr/src/ngx_pagespeed-release-1.9.32.3-beta --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-http_auth_request_module --with-mail --with-mail_ssl_module --with-file-aio --with-ipv6 --with-cc-opt='-O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'\n[root@FE02- src]#   langkah selanjutnya mengkonfigurasi service startup nginx  mkdir /usr/local/etc/rc.d\nvim /usr/local/etc/rc.d/nginx  isikan startup nginx service dengan berikut:  #!/bin/sh\n#\n# nginx - this script starts and stops the nginx daemon\n#\n# chkconfig:   - 85 15 \n# description:  Nginx is an HTTP(S) server, HTTP(S) reverse \\\n#               proxy and IMAP/POP3 proxy server\n# processname: nginx\n# config:      /etc/nginx/nginx.conf\n# config:      /etc/sysconfig/nginx\n# pidfile:     /var/run/nginx.pid\n# Source function library.\n. /etc/rc.d/init.d/functions\n# Source networking configuration.\n. /etc/sysconfig/network\n# Check that networking is up.\n[ \"$NETWORKING\" = \"no\" ]   exit 0\nnginx=\"/usr/local/nginx/sbin/nginx\"\nprog=$(basename $nginx)\nNGINX_CONF_FILE=\"/etc/nginx/nginx.conf\"\n[ -f /etc/sysconfig/nginx ]   . /etc/sysconfig/nginx\nlockfile=/var/lock/subsys/nginx\nmake_dirs() {\n   # make required directories\n   user=`$nginx -V 2 1 | grep \"configure arguments:\" | sed 's/[^*]*--user=\\([^ ]*\\).*/\\1/g' -`\n   if [ -z \"`grep $user /etc/passwd`\" ]; then\n       useradd -M -s /bin/nologin $user\n   fi\n   options=`$nginx -V 2 1 | grep 'configure arguments:'`\n   for opt in $options; do\n       if [ `echo $opt | grep '.*-temp-path'` ]; then\n           value=`echo $opt | cut -d \"=\" -f 2`\n           if [ ! -d \"$value\" ]; then\n               # echo \"creating\" $value\n               mkdir -p $value   chown -R $user $value\n           fi\n       fi\n   done\n}\nstart() {\n    [ -x $nginx ] || exit 5\n    [ -f $NGINX_CONF_FILE ] || exit 6\n    make_dirs\n    echo -n $\"Starting $prog: \"\n    daemon $nginx -c $NGINX_CONF_FILE\n    retval=$?\n    echo\n    [ $retval -eq 0 ]   touch $lockfile\n    return $retval\n}\nstop() {\n    echo -n $\"Stopping $prog: \"\n    killproc $prog -QUIT\n    retval=$?\n    echo\n    [ $retval -eq 0 ]   rm -f $lockfile\n    return $retval\n}\nrestart() {\n    configtest || return $?\n    stop\n    sleep 1\n    start\n}\nreload() {\n    configtest || return $?\n    echo -n $\"Reloading $prog: \"\n    killproc $nginx -HUP\n    RETVAL=$?\n    echo\n}\nforce_reload() {\n    restart\n}\nconfigtest() {\n  $nginx -t -c $NGINX_CONF_FILE\n}\nrh_status() {\n    status $prog\n}\nrh_status_q() {\n    rh_status  /dev/null 2 1\n}\ncase \"$1\" in\n    start)\n        rh_status_q   exit 0\n        $1\n        ;;\n    stop)\n        rh_status_q || exit 0\n        $1\n        ;;\n    restart|configtest)\n        $1\n        ;;\n    reload)\n        rh_status_q || exit 7\n        $1\n        ;;\n    force-reload)\n        force_reload\n        ;;\n    status)\n        rh_status\n        ;;\n    condrestart|try-restart)\n        rh_status_q || exit 0\n            ;;\n    *)\n        echo $\"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}\"\n        exit 2\nesac  berikan execution permission:  chmod a+x /usr/local/etc/rc.d/nginx  untuk start bisa dengan perintah:  /usr/local/etc/rc.d/nginx start  untuk reload, stop, dll tinggal menyesuaikan.  untuk praktis dengan perintah  service nginx {stop,reload,start}  rename  /etc/init.d/nginx  ke old_file lalu symlink ke  /usr/local/etc/rc.d/nginx  cd /etc/init.d/\nmv nginx nginx.old\nln -s /usr/local/etc/rc.d/nginx ./  Enable Module di Vhost domain:\nUntuk enable module di domain setiap vhost bisa menambahkan di vhost nginx:  # enable ngx_pagespeed\npagespeed on;\npagespeed FileCachePath /var/ngx_pagespeed_cache;  lalu set-up pagespeed filecachepath directory  # mkdir /var/ngx_pagespeed_cache\n# chown nginx: /var/ngx_pagespeed_cache  lalu restart nginx:  service nginx restart  lalu test:  dian@infra ~ $ curl -s -I www.domain.com | grep ^X-Page-Speed\nX-Page-Speed: 1.9.32.3-4448\ndian@infra ~ $  ref:\n 1.  official docs \n 2.  rosehosting", 
            "title": "Build PageSpeed Module for Nginx di Centos"
        }, 
        {
            "location": "/nginx-conf-dan-server-xml-tomcat-SSL-Jira/", 
            "text": "nginx conf dan server.xml tomcat SSL Jira\n\n\nnginx.conf\n\n\nserver {\n    listen       80;\n    server_name  abc.co.id;\n\n    access_log  /var/log/nginx/log/jira-access.log  main;\n    error_log  /var/log/nginx/log/jira.error.log;\n    root   /opt/atlassian/jira/atlassian-jira;\n    index  index.jsp index.html index.htm;\n\n\n    error_page   403  /it-infra.html;\n    location = /it-infra.html {\n        root   /usr/share/nginx/html;\n    }\n    ## send request back to apache1 ##\n    location / {\n                allow someip;\n                deny all;\n\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header Host $http_host;\n                proxy_set_header X-NginX-Proxy true;\n                proxy_pass http://localhost:4444/;\n                proxy_redirect http://localhost:4444/ https://$server_name/;\n   }\n}\n\n\nserver {\n    listen       443;\n    server_name  abc.co.id;\n\n    access_log  /var/log/nginx/log/jira-ssl-access.log  main;\n    error_log  /var/log/nginx/log/jira-ssl.error.log;\n    index  index.jsp index.html index.htm;\n\n        ssl                  on;\n        ssl_certificate /opt/certificate/SSL.crt;\n        ssl_certificate_key /opt/certificate/SSL.key;\n        ssl_session_timeout  5m;\n        ssl_protocols  SSLv2 TLSv1;\n        ssl_ciphers  HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers   on;\n    error_page   403  /it-infra.html;\n    location = /it-infra.html {\n        root   /usr/share/nginx/html;\n    }\n\n\n    ## send request back to apache1 ##\n    location / {\n                allow someip;\n                deny all;\n\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-Proto https;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass http://127.0.0.1:4444/;\n   }\n}\n\n\n\nserver.xml tomcat\n\n\n    \nConnector acceptCount=\"100\" connectionTimeout=\"20000\" disableUploadTimeout=\"true\" enableLookups=\"false\" maxHttpHeaderSize=\"8192\" maxThreads=\"150\" minSpareThreads=\"25\" port=\"4444\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" useBodyEncodingForURI=\"true\" scheme=\"https\" proxyName=\"abc.co.id\" proxyPort=\"443\"/", 
            "title": "Nginx - conf dan server.xml tomcat SSL Jira"
        }, 
        {
            "location": "/nginx-conf-dan-server-xml-tomcat-SSL-Jira/#nginx-conf-dan-serverxml-tomcat-ssl-jira", 
            "text": "nginx.conf  server {\n    listen       80;\n    server_name  abc.co.id;\n\n    access_log  /var/log/nginx/log/jira-access.log  main;\n    error_log  /var/log/nginx/log/jira.error.log;\n    root   /opt/atlassian/jira/atlassian-jira;\n    index  index.jsp index.html index.htm;\n\n\n    error_page   403  /it-infra.html;\n    location = /it-infra.html {\n        root   /usr/share/nginx/html;\n    }\n    ## send request back to apache1 ##\n    location / {\n                allow someip;\n                deny all;\n\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header Host $http_host;\n                proxy_set_header X-NginX-Proxy true;\n                proxy_pass http://localhost:4444/;\n                proxy_redirect http://localhost:4444/ https://$server_name/;\n   }\n}\n\n\nserver {\n    listen       443;\n    server_name  abc.co.id;\n\n    access_log  /var/log/nginx/log/jira-ssl-access.log  main;\n    error_log  /var/log/nginx/log/jira-ssl.error.log;\n    index  index.jsp index.html index.htm;\n\n        ssl                  on;\n        ssl_certificate /opt/certificate/SSL.crt;\n        ssl_certificate_key /opt/certificate/SSL.key;\n        ssl_session_timeout  5m;\n        ssl_protocols  SSLv2 TLSv1;\n        ssl_ciphers  HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers   on;\n    error_page   403  /it-infra.html;\n    location = /it-infra.html {\n        root   /usr/share/nginx/html;\n    }\n\n\n    ## send request back to apache1 ##\n    location / {\n                allow someip;\n                deny all;\n\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-Proto https;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass http://127.0.0.1:4444/;\n   }\n}  server.xml tomcat       Connector acceptCount=\"100\" connectionTimeout=\"20000\" disableUploadTimeout=\"true\" enableLookups=\"false\" maxHttpHeaderSize=\"8192\" maxThreads=\"150\" minSpareThreads=\"25\" port=\"4444\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" useBodyEncodingForURI=\"true\" scheme=\"https\" proxyName=\"abc.co.id\" proxyPort=\"443\"/", 
            "title": "nginx conf dan server.xml tomcat SSL Jira"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/", 
            "text": "Wazuh - Monitoring dan Log Management\n\n\nupdate \n install repo\n\n\nyum update -y\nrpm --import https://packages.wazuh.com/key/GPG-KEY-WAZUH\ncat \n /etc/yum.repos.d/wazuh.repo \n\\EOF\n[wazuh_repo]\ngpgcheck=1\ngpgkey=https://packages.wazuh.com/key/GPG-KEY-WAZUH\nenabled=1\nname=Wazuh repository\nbaseurl=https://packages.wazuh.com/3.x/yum/\nprotect=1\nEOF\n\n\n\ninstall nodejs\n\n\ncurl --silent --location https://rpm.nodesource.com/setup_10.x | bash -\nyum install nodejs\n\n\n\ninstall wazuh-api\n\n\nyum install wazuh-api\n\n\n\ninstall wazuh manager\n\n\nyum install wazuh-manager\nsystemctl status wazuh-manager\nsystemctl enable wazuh-manager\n\n\n\ninstall filebeat\n\n\nyum install filebeat-7.6.0\n\n\n\nsetting config filebeat\n\n\ncurl -so /etc/filebeat/filebeat.yml https://raw.githubusercontent.com/wazuh/wazuh/v3.11.4/extensions/filebeat/7.x/filebeat.yml\nchmod go+r /etc/filebeat/filebeat.yml\ncurl -so /etc/filebeat/wazuh-template.json https://raw.githubusercontent.com/wazuh/wazuh/v3.11.4/extensions/elasticsearch/7.x/wazuh-template.json\nchmod go+r /etc/filebeat/wazuh-template.json\ncurl -s https://packages.wazuh.com/3.x/filebeat/wazuh-filebeat-0.1.tar.gz | sudo tar -xvz -C /usr/share/filebeat/module\n\n\n\nfilebeat config\n\n\n# Wazuh - Filebeat configuration file\nfilebeat.modules:\n  - module: wazuh\n    alerts:\n      enabled: true\n    archives:\n      enabled: false\n\nsetup.template.json.enabled: true\nsetup.template.json.path: '/etc/filebeat/wazuh-template.json'\nsetup.template.json.name: 'wazuh'\nsetup.template.overwrite: true\nsetup.ilm.enabled: false\n\noutput.elasticsearch.hosts: ['http://10.148.0.9:9200']\n\n\n\nrestart filebeat service\n\n\nsystemctl daemon-reload\nsystemctl enable filebeat.service\nsystemctl start filebeat.service\n\n\n\ninstall elastic repo\n\n\ncat \n /etc/yum.repos.d/elastic.repo \n EOF\n\n\n\n[elasticsearch-7.x]\n   name=Elasticsearch repository for 7.x packages\n   baseurl=https://artifacts.elastic.co/packages/7.x/yum\n   gpgcheck=1\n   gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\n   enabled=1\n   autorefresh=1\n   type=rpm-md\n   EOF\n\n\ninstall elastic search\n\n\nyum install elasticsearch-7.6.0\n\n\n\nkonfigurasi elasticsearch.yml\n\n\nnode.name: wazuh-node-1\npath.data: /var/lib/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: 10.148.0.9\ncluster.initial_master_nodes: [\"wazuh-node-1\"]\n\n\n\nenable services elastic\n\n\nsystemctl daemon-reload\n   systemctl enable elasticsearch.service\n   systemctl start elasticsearch.service\n\n\nfilebeat setup\n\n\nfilebeat setup --index-management -E setup.template.json.enabled=false\n\n\n\ninstall kibana\n\n\nyum install kibana-7.6.0\n\n\nkonfig kibana\n\n\nnano /etc/kibana/kibana.yml\nserver.host: \"0.0.0.0\"\nelasticsearch.hosts: [\"http://10.148.0.9:9200\"]\n\n\n\nenable service kibana\n\n\nsystemctl daemon-reload\nsystemctl enable kibana.service\nsystemctl start kibana.service\nsudo -u kibana bin/kibana-plugin install https://packages.wazuh.com/wazuhapp/wazuhapp-3.11.4_7.6.0.zip\nsystemctl restart kibana\n\n\n\ninstall elastalert\n\n\ncd /usr/local/etc/\ngit clone https://github.com/Yelp/elastalert.git\n\n\n\nvim config.yml\n\n\nrules_folder: rules\nrun_every:\n  minutes: 1\nbuffer_time:\n  minutes: 15\nes_host: 10.148.0.9\nes_port: 9200\nwriteback_index: elastalert_status\nwriteback_alias: elastalert_alerts\nalert_time_limit:\n  days: 2\nuse_local_time: true\n\n\n\ncustom /lib/systemd/system/elastalert.service\n\n\n[Unit]\nDescription=Severe_logalerts\nAfter=elasticsearch.service\n\n[Service]\nType=simple\nWorkingDirectory=/usr/local/etc/elastalert\nExecStart=/usr/local/bin/elastalert --verbose --config /usr/local/etc/elastalert/config.yaml\n\n[Install]\nWantedBy=multi-user.target\n\n\n\nstart enable services\n\n\nsystemctl start elastalert.service\nsystemctl enable elastalert.service", 
            "title": "Wazuh - Monitoring dan Log Management"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#wazuh-monitoring-dan-log-management", 
            "text": "", 
            "title": "Wazuh - Monitoring dan Log Management"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#update-install-repo", 
            "text": "yum update -y\nrpm --import https://packages.wazuh.com/key/GPG-KEY-WAZUH\ncat   /etc/yum.repos.d/wazuh.repo  \\EOF\n[wazuh_repo]\ngpgcheck=1\ngpgkey=https://packages.wazuh.com/key/GPG-KEY-WAZUH\nenabled=1\nname=Wazuh repository\nbaseurl=https://packages.wazuh.com/3.x/yum/\nprotect=1\nEOF", 
            "title": "update &amp; install repo"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-nodejs", 
            "text": "curl --silent --location https://rpm.nodesource.com/setup_10.x | bash -\nyum install nodejs", 
            "title": "install nodejs"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-wazuh-api", 
            "text": "yum install wazuh-api", 
            "title": "install wazuh-api"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-wazuh-manager", 
            "text": "yum install wazuh-manager\nsystemctl status wazuh-manager\nsystemctl enable wazuh-manager", 
            "title": "install wazuh manager"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-filebeat", 
            "text": "yum install filebeat-7.6.0", 
            "title": "install filebeat"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#setting-config-filebeat", 
            "text": "curl -so /etc/filebeat/filebeat.yml https://raw.githubusercontent.com/wazuh/wazuh/v3.11.4/extensions/filebeat/7.x/filebeat.yml\nchmod go+r /etc/filebeat/filebeat.yml\ncurl -so /etc/filebeat/wazuh-template.json https://raw.githubusercontent.com/wazuh/wazuh/v3.11.4/extensions/elasticsearch/7.x/wazuh-template.json\nchmod go+r /etc/filebeat/wazuh-template.json\ncurl -s https://packages.wazuh.com/3.x/filebeat/wazuh-filebeat-0.1.tar.gz | sudo tar -xvz -C /usr/share/filebeat/module", 
            "title": "setting config filebeat"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#filebeat-config", 
            "text": "# Wazuh - Filebeat configuration file\nfilebeat.modules:\n  - module: wazuh\n    alerts:\n      enabled: true\n    archives:\n      enabled: false\n\nsetup.template.json.enabled: true\nsetup.template.json.path: '/etc/filebeat/wazuh-template.json'\nsetup.template.json.name: 'wazuh'\nsetup.template.overwrite: true\nsetup.ilm.enabled: false\n\noutput.elasticsearch.hosts: ['http://10.148.0.9:9200']", 
            "title": "filebeat config"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#restart-filebeat-service", 
            "text": "systemctl daemon-reload\nsystemctl enable filebeat.service\nsystemctl start filebeat.service", 
            "title": "restart filebeat service"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-elastic-repo", 
            "text": "cat   /etc/yum.repos.d/elastic.repo   EOF  [elasticsearch-7.x]\n   name=Elasticsearch repository for 7.x packages\n   baseurl=https://artifacts.elastic.co/packages/7.x/yum\n   gpgcheck=1\n   gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\n   enabled=1\n   autorefresh=1\n   type=rpm-md\n   EOF", 
            "title": "install elastic repo"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-elastic-search", 
            "text": "yum install elasticsearch-7.6.0", 
            "title": "install elastic search"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#konfigurasi-elasticsearchyml", 
            "text": "node.name: wazuh-node-1\npath.data: /var/lib/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: 10.148.0.9\ncluster.initial_master_nodes: [\"wazuh-node-1\"]", 
            "title": "konfigurasi elasticsearch.yml"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#enable-services-elastic", 
            "text": "systemctl daemon-reload\n   systemctl enable elasticsearch.service\n   systemctl start elasticsearch.service", 
            "title": "enable services elastic"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#filebeat-setup", 
            "text": "filebeat setup --index-management -E setup.template.json.enabled=false", 
            "title": "filebeat setup"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-kibana", 
            "text": "yum install kibana-7.6.0", 
            "title": "install kibana"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#konfig-kibana", 
            "text": "nano /etc/kibana/kibana.yml\nserver.host: \"0.0.0.0\"\nelasticsearch.hosts: [\"http://10.148.0.9:9200\"]", 
            "title": "konfig kibana"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#enable-service-kibana", 
            "text": "systemctl daemon-reload\nsystemctl enable kibana.service\nsystemctl start kibana.service\nsudo -u kibana bin/kibana-plugin install https://packages.wazuh.com/wazuhapp/wazuhapp-3.11.4_7.6.0.zip\nsystemctl restart kibana", 
            "title": "enable service kibana"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#install-elastalert", 
            "text": "cd /usr/local/etc/\ngit clone https://github.com/Yelp/elastalert.git", 
            "title": "install elastalert"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#vim-configyml", 
            "text": "rules_folder: rules\nrun_every:\n  minutes: 1\nbuffer_time:\n  minutes: 15\nes_host: 10.148.0.9\nes_port: 9200\nwriteback_index: elastalert_status\nwriteback_alias: elastalert_alerts\nalert_time_limit:\n  days: 2\nuse_local_time: true", 
            "title": "vim config.yml"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#custom-libsystemdsystemelastalertservice", 
            "text": "[Unit]\nDescription=Severe_logalerts\nAfter=elasticsearch.service\n\n[Service]\nType=simple\nWorkingDirectory=/usr/local/etc/elastalert\nExecStart=/usr/local/bin/elastalert --verbose --config /usr/local/etc/elastalert/config.yaml\n\n[Install]\nWantedBy=multi-user.target", 
            "title": "custom /lib/systemd/system/elastalert.service"
        }, 
        {
            "location": "/wazuh-monitoring-log-management/#start-enable-services", 
            "text": "systemctl start elastalert.service\nsystemctl enable elastalert.service", 
            "title": "start enable services"
        }
    ]
}